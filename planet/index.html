
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Planet HTCondor - HTCondor Project</title>
  <meta name="author" content="HTCondor Project">

  
  <meta name="description" content="Background
In the not-so-distant past, enterprise data centers would create silos for specific services to gaurentee some metric of performance, or “ &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://htcondor.github.com/planet/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/planet/atom.xml" rel="alternate" title="HTCondor Project" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">HTCondor Project</a></h1>
  
    <h2>The website and blog for the HTCondor project on github.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/planet/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:htcondor.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/planet">Planet HTCondor</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      

<br>
<h1 align="center"><u> Planet HTCondor </u></h1>

<div class=\"blog-index\">

  <article>
    <header>
      <h1 class="entry-title"><a href="http://timothysc.github.com/blog/2013/06/14/systemd-cgroup-sla/">Leveraging systemd cgroup integration to provide SLAs on Fedora 18 & 19</a></h1>
      <p class="meta">
        <time datetime="2013-06-14T15:00:00Z" pubdate data-updated="true">Jun 14<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Timothy St. Clair</time>
      </p>
    </header>
    <div class="entry-content"><h2 id="background">Background</h2>
<p>In the not-so-distant past, enterprise data centers would create silos for specific 
services to gaurentee some metric of performance, or “Service Level Agreement” (SLA).  However,
this approach can be costly to create and maintain.</p>

<p>Enter the modern era of cloud computing, and one might wonder, “Why not just put it in VM?”.  For 
some use cases this might work just fine, because the metrics are “good-enough”.   Despite this flexibility, 
there are many cases where this approach simply won’t meet some measure of performance.  I won’t elaborate 
on the details, but it doesn’t take Schrödinger math to figure this out, because sometimes the cat 
is dead even before you peak into the box. ;-) </p>

<p>Thus, in this post we will explore leveraging systemd cgroup integration to provide SLAs on Fedora. </p>

<hr />

<h2 id="references">References</h2>

<ul>
  <li><a href="http://searchitchannel.techtarget.com/definition/service-level-agreement">Definition SLA</a></li>
  <li><a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/">Redhat Cgroup Documentation</a></li>
  <li><a href="http://0pointer.de/blog/projects/resources.html">Resource Management with Systemd</a></li>
  <li><a href="http://0pointer.de/public/systemd-man/systemd.directives.html">Systemd Service Directives</a></li>
</ul>

<hr />

<h2 id="prerequisites">Prerequisites</h2>

<ul>
  <li>Fedora 18 or 19 box(es).</li>
  <li>Make certain you’ve read the references, as I may gloss over some details in this post.</li>
</ul>

<hr />

<h2 id="getting-started">Getting Started</h2>
<p>First you will need to choose a service which has been integrated with systemd that you can plan on tuning.
In this example I will use ‘condor’, but you could use any service that you desire.</p>

<pre><code> sudo yum install condor
</code></pre>

<p><strong>NOTE:</strong> You could do this with raw cgroups, but it becomes difficult to gaurentee performance unless 
every service is in a group.  So systemd does a lot of the heavy lifting for us. </p>

<p>Next you will need to determine the metrics of performance that you want to provide for that service.  For the 
purposes of simplicity, lets say we want to carve off 50% of the CPU for condor.  You can 
also play with disk-io-bandwidth and network settings too, but I think I will leave that for another post
as this can be complicated enough.</p>

<p>In order to divide up your machine you will first need to determine the existing 
shares on your machine.  This can be done by dumping the current cgroup settings to a file which 
can then be analyzed to determine the new settings. </p>

<pre><code>cgsnapshot -s &gt; cgroup_snap.conf 
</code></pre>

<p>If you have a fairly basic setup you will notice the following pattern </p>

<pre><code># Configuration file generated by cgsnapshot
mount {
    cpuset = /sys/fs/cgroup/cpuset;
    cpu = /sys/fs/cgroup/cpu,cpuacct;
    cpuacct = /sys/fs/cgroup/cpu,cpuacct;
    memory = /sys/fs/cgroup/memory;
    devices = /sys/fs/cgroup/devices;
    freezer = /sys/fs/cgroup/freezer;
    net_cls = /sys/fs/cgroup/net_cls;
    blkio = /sys/fs/cgroup/blkio;
    perf_event = /sys/fs/cgroup/perf_event;
}

group system {
    cpu {
            cpu.rt_period_us="1000000";
            cpu.rt_runtime_us="0";
            cpu.cfs_period_us="100000";
            cpu.cfs_quota_us="-1";
            cpu.shares="1024";
    }
    cpuacct {
            cpuacct.usage="147354515620554";
    }
}

group system/condor.service {
    cpu {
            cpu.rt_period_us="1000000";
            cpu.rt_runtime_us="0";
            cpu.cfs_period_us="100000";
            cpu.cfs_quota_us="-1";
            cpu.shares="1024";
    }
    cpuacct {
            cpuacct.usage="146844720798260";
    }
}

... * service look ~= 
</code></pre>

<hr />

<h2 id="analyzing-your-configuration">Analyzing your Configuration</h2>
<p>One thing you will notice is that systemd creates an implied hierarchy on your 
machine by default, where each service has an equal amount of cpu.shares.  This means 
when all services are contending for resources, each “service” gets an equal
share. </p>

<p>Lets elaborate on shares a bit.  Say you had two service S(a) = 1, and S(b) = 3 and each service 
has multiple processes all contending for CPU. </p>

<pre><code>%CPU = service.cpu.share /(sum (service shares @ level)) 
%CPU[S(a)] = 1/4 = 25% 
%CPU[S(b)] = 3/4 = 75% 
</code></pre>

<p>So now lets extend this idea and create a simple hierarchy
where there are two groups, with each group having two services:</p>

<pre><code>            Share   Overall%
Group 1     1       25%
    S(a)        1       12.5%
    S(b)        1       12.5%
Group 2     3       75%
    S(c)        3       56.25%
    S(d)        1       18.75%
</code></pre>

<p>Hopefully this should be intuitive, however it can quickly goto plaid. Therefore, it’s 
important to have a handle on how many services you have planed for a given machine, and
your intended hierarchy.  Thus the cost of reliable performance is extra complexity, which 
isn’t so bad provided you’ve done your math.</p>

<hr />

<h2 id="altering-your-configuration">Altering your Configuration</h2>

<p>So now lets provision condor such that it has 50% of the CPU.  First we need to get a count
of number of services that exist on the machine. </p>

<pre><code>$ cgsnapshot -s | grep [.]service | wc -l
30
</code></pre>

<p>As you can see from the previous example, and from the documentation, the default cpu.shares 
given to a service is 1024.  Thus if we want 50% CPU:</p>

<pre><code>.50 = condor.cpu.shares/(1024*29 + condor.cpu.shares)
512*(29) + .50*condor.cpu.shares = condor.cpu.shares
14848 = (1-.50)*condor.cpu.shares 
condor.cpu.shares = 14848/.50 = 29696
</code></pre>

<p>Now we need to plug this magic number in:</p>

<pre><code>vim /usr/lib/systemd/system/condor.service

[Service]
CPUShares=29696
</code></pre>

<p>Once we exit we will need to restart the daemon and verify it worked.</p>

<pre><code>systemctl daemon-reload
systemctl restart condor.service
cgsnapshot -s &gt; cgroup_snap_2.conf
</code></pre>

<p>Now you can compare the two configuration files.</p>

<p>Next you will want to submit a whole bunch of condor jobs, and try to load down the other services. 
To verify that your machine is behaving as expected you can run: </p>

<pre><code>systemd-cgtop
</code></pre>

<p>In this example it can be difficult when you have 30 services to accurately test that you are 
guaranteed 50% so I would recommend that the reader trim their machine down and create a 
more controlled experiment to verify. </p>

<hr />

<h2 id="in-summary">In Summary</h2>
<p>Systemd’s integration with cgroups is a many splendid thing, and when used correctly can
give administrators and developers another tool in which to help create SLAs in their datacenter.</p>

</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="manual/v8.0/10_3Stable_Release.html"> HTCondor 8.0.0 released! ( June 6, 2013 )</a></h1>
      <p class="meta">
        <time datetime="2013-06-06T05:00:00Z" pubdate data-updated="true">Jun 6<span>th</span>, 2013  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is pleased to announce the release of HTCondor 8.0.0.
This release is the first in the new stable series.
The major version number changed because of the project rename to HTCondor and not because of major incompatibility with the version 7.8 stable series.
This new version contains Bosco, support for EC2 Spot instances, interactive jobs, improved job sandboxing, native python API and several new tools.
A complete list of bugs fixed and features can be found in the 
Version History. HTCondor 8.0.0 binaries
and source code are available from our Downloads page.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://www.hpcwire.com/hpcwire/2013-05-30/running_stochastic_models_on_htcondor.html"> HPCwire article highlights running stochastic models on HTCondor ( June 6, 2013 )</a></h1>
      <p class="meta">
        <time datetime="2013-06-06T05:00:00Z" pubdate data-updated="true">Jun 6<span>th</span>, 2013  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">An article published at HPCwire highlights research out of Brigham Young University with a goal to 
demonstrate an alternative model to High Performance Computing (HPC) for water resource stakeholders by leveraging
High Throughput Computing (HTC) with HTCondor.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://bosco.opensciencegrid.org/2013/06/bosco-1-2-release/"> Open Science Grid releases Bosco 1.2, based on HTCondor ( June 6, 2013 )</a></h1>
      <p class="meta">
        <time datetime="2013-06-06T05:00:00Z" pubdate data-updated="true">Jun 6<span>th</span>, 2013  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">Bosco is a client for Linux and Mac operating systems for submitting jobs to 
remote batch systems without administrator assistance. It is designed
for end-users, and only requires ssh access to one or more cluster front-ends.
Target clusters can be HTCondor, LSF, PBS, SGE or SLURM managed resources.  
The new Bosco 1.2 release is much easier to install, will handle more jobs, 
will send clearer error messages, and makes it easier to specify the memory
you need inside the clusters you connect to.  
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://www.hpcwire.com/hpcwire/2013-05-21/cern_google_and_the_future_of_global_science_initiatives.html"> Atlas project at CERN describes their computing environment ( May 29, 2013 )</a></h1>
      <p class="meta">
        <time datetime="2013-05-29T05:00:00Z" pubdate data-updated="true">May 29<span>th</span>, 2013  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HPCwire: CERN, Google Drive Future of Global Science Initiatives article describes the computing environment of 
the ATLAS project at CERN.  
HTCondor and now Google Compute Engine aid the extensive collision 
analysis effort for ATLAS.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2013/05/submitting-r-jobs-with-bosco.html">Submitting R jobs with Bosco</a></h1>
      <p class="meta">
        <time datetime="2013-05-20T14:51:00Z" pubdate data-updated="true">May 20<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content">The Bosco team has been working on integrating with the <a href="http://www.r-project.org/">R</a> statistics processing language. &nbsp;We have&nbsp;chosen&nbsp;to modify the <a href="http://cran.r-project.org/web/packages/GridR/index.html">GridR</a> package in order to integrate with R.<br /><br /><h3>How will the R user see Bosco?</h3><div>The goal of the integration is to simplify the method of submitting processing, written in the R&nbsp;language, to remote clusters and grids. &nbsp;The expected steps for the integration are:</div><div><ol><li>Install Bosco</li><li>Install the Bosco'ified GridR package into your local R environment.</li></ol></div><div>After installing the 2 pieces of software above, the user creates a R script, which includes the 'function' that is to be executed on the remote cluster. &nbsp;The user can send any data as input, lists, tables, an entire CSV file (already read into a R variable). &nbsp;The function output will be automatically imported into the environment when the remote job has completed.</div><div><br /></div><div>Below is a demo of the GridR package working with Bosco to submit to a campus cluster here at Nebraska.</div><div><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-WJlIyBopEBk/UZo2UDWMOCI/AAAAAAAAB8E/8jP712IKSMQ/s1600/Screen+Shot+2013-05-18+at+12.55.40+AM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="433" src="http://4.bp.blogspot.com/-WJlIyBopEBk/UZo2UDWMOCI/AAAAAAAAB8E/8jP712IKSMQ/s640/Screen+Shot+2013-05-18+at+12.55.40+AM.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><a href="http://www.rstudio.com/">RStudio</a> IDE showing demo of Bosco + GridR integration</td></tr></tbody></table><div>The steps in the demo are:</div><div><ol><li>Load the GridR library</li><li>Create the function, in this case named simply 'a' that doubles the value of the argument.</li><li>Initialize the GridR integration to talk to Bosco</li><li>"Apply" the function. &nbsp;Run the function 'a', with the input 14, and write the result to the variable "x". &nbsp;Also, wait for the remote job to complete.</li><li>Finally, I printed out the value of x, which is 28, double the 14.&nbsp;</li></ol><div>This is a very simple demo. &nbsp;You could imagine the function sent to the remote machine could parse the a CSV file, or more complex operations...</div></div><div><br /></div><div>The Bosco team expects to have this integration done and in production by Mid-July for the <a href="http://161.67.142.97/congresos/useR-2013/%E2%80%8E">R users meeting</a>.</div><br /><center> <a href="http://bosco.opensciencegrid.org/download/">     <img alt="Bosco Download" src="https://raw.github.com/osg-bosco/bosco-download-images/master/images/download-orange.png" style="border-width: 0;" /> </a>   </center></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="manual/v7.9/9_3Development_Release.html"> HTCondor 7.9.6 released! ( May 08, 2013 )</a></h1>
      <p class="meta">
        <time datetime="2013-05-08T05:00:00Z" pubdate data-updated="true">May 8<span>th</span>, 2013  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is pleased to announce the release of HTCondor 7.9.6.
This is the final release of the 7.9 series. This release contains new
tools, VMware player support, Linux out of memory killer hints, python
bindings, new configuration parameters, and many bug fixes.
A complete list of bugs fixed and features can be found in the
Version History. HTCondor 7.9.6 binaries
and source code are available from our Downloads page.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://timothysc.github.com/blog/2013/04/22/personalhadoop/">Configuring a Personal Hadoop Development Environment on Fedora 18</a></h1>
      <p class="meta">
        <time datetime="2013-04-22T15:00:00Z" pubdate data-updated="true">Apr 22<span>nd</span>, 2013  &nbsp; &mdash; &nbsp; Timothy St. Clair</time>
      </p>
    </header>
    <div class="entry-content"><h2 id="background">Background</h2>
<p>The following post outlines a setup and configuration of a “personal hadoop” development environment that is much akin to a “personal condor” setup.
The primary purpose is to have a single source for configuration and logs along with a soft-link to development built binaries such that switching 
to a different build is a matter of updating a soft-link while maintaining all other data and configuration. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html">Installing Spark on Fedora 18</a></h1>
      <p class="meta">
        <time datetime="2013-04-11T21:37:28Z" pubdate data-updated="true">Apr 11<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">The Spark project is an actively-developed open-source engine for data analytics on clusters using Scala, Python, or Java. It offers map, filter, and reduce operations over in-memory collections, data from local files, or data taken from HDFS, but unlike standard...</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2013/04/reprocessing-cms-events-with-bosco.html">Reprocessing CMS events with Bosco</a></h1>
      <p class="meta">
        <time datetime="2013-04-02T19:38:00Z" pubdate data-updated="true">Apr 2<span>nd</span>, 2013  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading/">The Impact of Negotiator Cycle Cadence on Slot Loading</a></h1>
      <p class="meta">
        <time datetime="2013-03-21T22:10:00Z" pubdate data-updated="true">Mar 21<span>st</span>, 2013  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>The <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_1Introduction.html#8555">HTCondor negotiator</a> assigns jobs (resource requests) to slots (compute resources) at regular intervals, configured by the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#20544">NEGOTIATOR_INTERVAL</a> parameter.  This interval (the cycle <em>cadence</em>) has a fundamental impact on a pool <em>loading factor</em> -- the fraction of time that slots are being productively utilized. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/">Smooth Gradients for Cubic Hermite Splines</a></h1>
      <p class="meta">
        <time datetime="2013-03-16T14:39:00Z" pubdate data-updated="true">Mar 16<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, ... m_{n-1} \) at knot-points: [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/">Examining the Modulus of Random Variables</a></h1>
      <p class="meta">
        <time datetime="2013-03-15T19:03:00Z" pubdate data-updated="true">Mar 15<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><h3>Motivation</h3> [...]
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2013/03/running-quantum-espresso-on-osg.html">Running Quantum Espresso on the OSG</a></h1>
      <p class="meta">
        <time datetime="2013-03-05T18:53:00Z" pubdate data-updated="true">Mar 5<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://timothysc.github.com/blog/2013/02/22/perprocess/">Per-Process Mount Namespaces</a></h1>
      <p class="meta">
        <time datetime="2013-02-22T16:00:00Z" pubdate data-updated="true">Feb 22<span>nd</span>, 2013  &nbsp; &mdash; &nbsp; Timothy St. Clair</time>
      </p>
    </header>
    <div class="entry-content"><h2 id="background">Background</h2>
<p>“Isolation” in modern computing comes in many flavors and functions.  Virtual machines, c-groups, chroots/jails,
sanboxing, and namespaces all have a role to play.  In this post we will review process mount namespace isolation, which allows a process to isolate 
its mount points from the outside world.  Furthermore, it enables cleanup of that namespace, which is highly useful in grid applications.   [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2013/02/12/statistic-changes-in-htcondor-7-7/">Statistic changes in HTCondor 7.7</a></h1>
      <p class="meta">
        <time datetime="2013-02-12T11:56:04Z" pubdate data-updated="true">Feb 12<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content">Notice to HTCondor 7.8 users - Statistics implemented during the 7.5 series that landed in 7.7.0 were rewritten by the time 7.8 was released. If you were using the original statistics for monitoring and/or reporting, here is a table to help you map old (left column) to new (right column). See – 7.6 -&#62; 7.8 [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=925&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2013/02/using-bosco-to-submit-to-amazon-ec2.html">Using Bosco to submit to Amazon EC2</a></h1>
      <p class="meta">
        <time datetime="2013-02-06T04:27:00Z" pubdate data-updated="true">Feb 6<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2013/02/05/how-accounting-group-configuration-could-work-with-wallaby/">How accounting group configuration could work with Wallaby</a></h1>
      <p class="meta">
        <time datetime="2013-02-05T11:46:28Z" pubdate data-updated="true">Feb 5<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content">Configuration of accounting groups in HTCondor is too often an expert task that requires coordination between administrators and their tools. Wallaby provides a coordination point, so long as a little convention is employed, and can provide a task specific interface to simplify configuration. Quick background, Wallaby provides semantic configuration for HTCondor. It models a pool [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=917&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2013/01/29/some-htcondor-wiki-stats/">Some htcondor-wiki stats</a></h1>
      <p class="meta">
        <time datetime="2013-01-29T11:36:06Z" pubdate data-updated="true">Jan 29<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content">A few years ago I discovered Web Numbr, a service that will monitor a web page for a number and graph that number over time. I installed a handful of webnumbrs to track things at HTCondor&#8217;s gittrac instance. http://webnumbr.com/search?query=condor Thing such as - Tickets resolved with no destination: tickets that don&#8217;t indicate what version they [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=903&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://osgtech.blogspot.com/2013/01/introducing-htcondor-ce.html">Introducing the HTCondor-CE</a></h1>
      <p class="meta">
        <time datetime="2013-01-28T15:33:00Z" pubdate data-updated="true">Jan 28<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Brian Bockelman</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2013/01/21/concurrency-limits-group-defaults/">Concurrency Limits: Group defaults</a></h1>
      <p class="meta">
        <time datetime="2013-01-21T12:47:07Z" pubdate data-updated="true">Jan 21<span>st</span>, 2013  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content">Concurrency limits allow for protecting resources by providing a way to cap the number of jobs requiring a specific resource that can run at one time. For instance, limit licenses and filer access at four regional data centers. Notice the repetition. In addition to the repetition, every license.* and filer.* must be known and recorded [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=895&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2013/01/bosco-111-release.html">Bosco 1.1.1 Release</a></h1>
      <p class="meta">
        <time datetime="2013-01-14T18:59:00Z" pubdate data-updated="true">Jan 14<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2013/01/14/your-api-is-a-feature-give-it-real-resource-management/">Your API is a feature, give it real resource management</a></h1>
      <p class="meta">
        <time datetime="2013-01-14T12:17:29Z" pubdate data-updated="true">Jan 14<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content">So much these days is about distributed resource management. That&#8217;s anything that can be created and destroyed in the cloud[0]. Proper management is especially important when the resource&#8217;s existence is tied to a real economy, e.g. your user&#8217;s credit card[1]. Above is a state machine required to ensure that resources created in AWS EC2 are [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=872&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://osgtech.blogspot.com/2013/01/fun-with-classads.html">Fun with ClassAds</a></h1>
      <p class="meta">
        <time datetime="2013-01-05T22:58:00Z" pubdate data-updated="true">Jan 5<span>th</span>, 2013  &nbsp; &mdash; &nbsp; Brian Bockelman</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/">The Mean of the Modulus Does Not Equal the Modulus of the Mean</a></h1>
      <p class="meta">
        <time datetime="2013-01-02T15:55:00Z" pubdate data-updated="true">Jan 2<span>nd</span>, 2013  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>I've been considering models for the effects of HTCondor negotiation cycle cadence on pool loading and accounting group starvation, which led me to thinking about the effects of taking the modulus of a random variable, for reasons I plan to discuss in future posts. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption/">A Demonstration of Negotiator-Side Resource Consumption</a></h1>
      <p class="meta">
        <time datetime="2012-12-03T15:25:00Z" pubdate data-updated="true">Dec 3<span>rd</span>, 2012  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>HTCondor supports a notion of aggregate compute resources known as partitionable slots (p-slots), which may be consumed by multiple jobs.   Historically, at most one job could be matched against such a slot in a single negotiation cycle, which limited the rate at which partitionable slot resources could be utilized.  More recently, the scheduler has been enhanced with logic to allow it to acquire multiple claims against a partitionable slot, which increases the p-slot utilization rate. However, as this potentially bypasses the negotiator's accounting of global pool resources such as accounting group quotas and concurrency limits, it places some contraints on what jobs can can safely acquire multiple claims against any particular p-slot: for example, only other jobs on the same scheduler can be considered.  Additionally, candidate job requirements must match the requirements of the job that originally matched in the negotiator.  Another significant impact is that the negotiator is still forced to match an entire p-slot, which may have a large match cost (weight): these large match costs cause <a href="https://htcondor-wiki.cs.wisc.edu/index.cgi/tktview?tn=3013">accounting difficulties</a> when submitter shares and/or group quotas drop below the cost of a slot.  This particular problem is growing steadily larger, as machines with ever-larger numbers of cores and other resources appear in HTCondor pools. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin/">Role enforcement in Cumin</a></h1>
      <p class="meta">
        <time datetime="2012-11-12T20:20:00Z" pubdate data-updated="true">Nov 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Trevor McKay</time>
      </p>
    </header>
    <div class="entry-content"><p>Roles in Cumin scope activities and content in the UI.  There are currently two roles defined in Cumin, <code>admin</code> and <code>user</code>.  The <code>admin</code> role is a superset of the <code>user</code> role, and every new account has the <code>user</code> role by default. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://timothysc.github.com/blog/2012/11/12/condor-sudo/">Override HTCondor installation with sudo</a></h1>
      <p class="meta">
        <time datetime="2012-11-12T09:00:00Z" pubdate data-updated="true">Nov 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Timothy St. Clair</time>
      </p>
    </header>
    <div class="entry-content"><h2 id="background">Background</h2>
<p>As a developer, I often find myself wanting to iterate on a build, and test in a sandboxed environment.  Isolating the environment ensures that your changes work well in a controlled experiment, but it has one fundamental flaw, it’s not realistic.  In order to truly test a complicated system it’s best to put it into some production environment.  This is great for testing, but it has been known to give admins a headache, because you are mucking with a known good installation.  So in this post we will set about the task of overriding an installtion of HTCondor using sudo while keeping the following requirements in mind: [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/11/best-practices-for-wallabys-default-group.html">Best practices for Wallaby's default group</a></h1>
      <p class="meta">
        <time datetime="2012-11-01T20:14:53Z" pubdate data-updated="true">Nov 1<span>st</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">Recall that Wallaby applies partial configurations to groups of nodes. Groups can be either explicit —- that is, a named subset of nodes created by the user, or special groups that are built-in to Wallaby; each node’s group memberships have...</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site/">Welcome To The HTCondor Project Github Site</a></h1>
      <p class="meta">
        <time datetime="2012-10-29T20:15:00Z" pubdate data-updated="true">Oct 29<span>th</span>, 2012  &nbsp; &mdash; &nbsp; HTCondor Team GitHub</time>
      </p>
    </header>
    <div class="entry-content"><p>Welcome to the HTCondor Project GitHub website!  This site is the github web and blog presence for the HTCondor project. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/10/configuring-high-availability-condor-central-managers-with-wallaby.html">Configuring high-availability Condor central managers with Wallaby</a></h1>
      <p class="meta">
        <time datetime="2012-10-23T04:34:58Z" pubdate data-updated="true">Oct 23<span>rd</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">Rob Rati and I gave a tutorial on highly-available job queues at Condor Week this year. While it was not a Wallaby-specific tutorial, we did point out that configuring highly-available job queues is easier for users who manage and deploy...</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers/">Using Cluster Suite's GUI to configure High Availability Schedulers </a></h1>
      <p class="meta">
        <time datetime="2012-10-18T17:20:00Z" pubdate data-updated="true">Oct 18<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Robert Rati</time>
      </p>
    </header>
    <div class="entry-content"><p>In an <a href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/">earlier post</a> I talked about using Cluster Suite
to manage high availability schedulers and referenced the command line tools
available perform the configuration.  I'd like to focus on using the GUI that
is part of Cluster Suite to configure an HA schedd.  It's a pretty simple
process but does require you run a wallaby shell command to complete the
configuration. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://tmckayus.github.com/blog/2012/10/10/ldap-credentials/">Credentials in LDAP URLs when Anonymous Search is Disabled</a></h1>
      <p class="meta">
        <time datetime="2012-10-10T20:55:00Z" pubdate data-updated="true">Oct 10<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Trevor McKay</time>
      </p>
    </header>
    <div class="entry-content"><p>Cumin authenticates logins against LDAP using a two step process: [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/">Using Cluster Suite to Manage a High Availability Scheduler</a></h1>
      <p class="meta">
        <time datetime="2012-09-26T19:53:00Z" pubdate data-updated="true">Sep 26<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Robert Rati</time>
      </p>
    </header>
    <div class="entry-content"><p>Condor provides simple and easy to configure HA functionality for the schedd
that relies upon shared storage (usually NFS).  The shared store is used to
store the job queue log and coordinate which node is running the schedd.  This
means that each node that can run a particular schedd not only have condor
configured but the node needs to be configured to access the shared storage. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://tmckayus.github.com/blog/2012/09/24/ldap-auth/">Integrating Cumin with LDAP for Authentication</a></h1>
      <p class="meta">
        <time datetime="2012-09-24T16:41:00Z" pubdate data-updated="true">Sep 24<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Trevor McKay</time>
      </p>
    </header>
    <div class="entry-content"><p>Past versions of Cumin have relied on a local database for storing user accounts.  However, that solution adds extra maintenance for site administrators who already have or plan to have a central authentication mechanism for their users.  Consequently, development is ongoing to integrate Cumin with common central auth mechanisms.  LDAP integration is available now, with support for other technologies planned for the future. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://tmckayus.github.com/blog/2012/09/24/new-post/">So What is Cumin Anyway?</a></h1>
      <p class="meta">
        <time datetime="2012-09-24T16:07:00Z" pubdate data-updated="true">Sep 24<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Trevor McKay</time>
      </p>
    </header>
    <div class="entry-content"><p>Cumin is a Python web UI developed in the Fedora community for managing Condor pools and Qpid messaging brokers.  It is packaged for Fedora but may be run from sources and would probably be easy to port to other Linux distributions (or just run Fedora on a node or two in a heterogeneous environment!)  The current development focus for Cumin is on expanding the Condor management facilities. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://timothysc.github.com/blog/2012/09/21/condor-n-overt/">Elastic Grid with Condor and oVirt Integration</a></h1>
      <p class="meta">
        <time datetime="2012-09-21T08:50:00Z" pubdate data-updated="true">Sep 21<span>st</span>, 2012  &nbsp; &mdash; &nbsp; Timothy St. Clair</time>
      </p>
    </header>
    <div class="entry-content"><h2 id="background">Background</h2>
<p>Gone are the days where an IT administrator could procure a dedicated compute cluster for a single task, so it is often the case where admins are asked to do more with existing resources where possible, especially those which are underutilized.  There are several existing solutions to oversubscription, but few that remain “general purpose” while adapting to the environment as the load within the cluster changes.  Enter Condor, which has been most well known for its batch processing capabilities, but can also be leveraged in many ways as an IaaS tool when coupled with oVirt.  [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://rrati.github.com/blog/2012/09/18/putting-it-together/">Putting It Together</a></h1>
      <p class="meta">
        <time datetime="2012-09-18T12:59:00Z" pubdate data-updated="true">Sep 18<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Robert Rati</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://getwallaby.com/2012/09/authorization-for-wallaby-clients/">Authorization for Wallaby clients</a></h1>
      <p class="meta">
        <time datetime="2012-09-12T22:30:00Z" pubdate data-updated="true">Sep 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways.  This post will explain how the authorization support works and show how to get started using it.  If you just want to get started using Wallaby with authorization support as quickly as possible, skip ahead to the section titled &#8220;Getting Started&#8221; below.  Detailed information about which role is required for each Wallaby API method is <a href="http://getwallaby.com/api-roles/">available here</a>. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/09/authorization-for-wallaby-clients.html">Authorization for Wallaby clients</a></h1>
      <p class="meta">
        <time datetime="2012-09-12T22:23:18Z" pubdate data-updated="true">Sep 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways. This post will explain how the authorization support works and show how to...</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/08/highly-available-configuration-data-with-wallaby.html">Highly-available configuration data with Wallaby</a></h1>
      <p class="meta">
        <time datetime="2012-08-29T21:03:00Z" pubdate data-updated="true">Aug 29<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">Many Condor users are interested in high-availability (HA) services: they don't want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon. (See this talk that Rob Rati and...</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://getwallaby.com/2012/08/live-backup/">Highly-available configuration data with Wallaby</a></h1>
      <p class="meta">
        <time datetime="2012-08-29T14:40:00Z" pubdate data-updated="true">Aug 29<span>th</span>, 2012  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Many Condor users are interested in <em>high-availability</em> (HA) services:  they don&#8217;t want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon.  (See <a href="http://research.cs.wisc.edu/condor/CondorWeek2012/presentations/rati-benton-condor-ha.pdf">this talk</a> that Rob Rati and I gave at Condor Week this year for a couple of solutions to HA with the Condor <code>schedd</code>.)  So it&#8217;s only natural that Condor users who are interested in configuring their pools with <a href="http://getwallaby.com">Wallaby</a> might wonder how Wallaby responds in the face of failure. [...]</p>
</div>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Planet HTCondor Members</h1>
    
      <a href="http://willbenton.com"> Will Benton</a><br>
    
      <a href="http://getwallaby.com/"> William Benton</a><br>
    
      <a href="http://osgtech.blogspot.com"> Brian Bockelman</a><br>
    
      <a href="http://erikerlandson.github.com/"> Erik Erlandson</a><br>
    
      <a href="http://spinningmatt.wordpress.com"> Matthew Farrellee</a><br>
    
      <a href="http://tmckayus.github.com/"> Trevor McKay</a><br>
    
      <a href="http://rrati.github.com/"> Robert Rati</a><br>
    
      <a href="http://timothysc.github.com/"> Timothy St. Clair</a><br>
    
      <a href="http://research.cs.wisc.edu/htcondor"> HTCondor Team</a><br>
    
      <a href="http://htcondor.github.com/"> HTCondor Team GitHub</a><br>
    
      <a href="http://derekweitzel.blogspot.com"> Derek Weitzel</a><br>
    
  </section>
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - HTCondor Project -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
