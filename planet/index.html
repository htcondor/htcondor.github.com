
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Planet HTCondor - HTCondor Project</title>
  <meta name="author" content="HTCondor Project">

  
  <meta name="description" content="In my previous post about Rethinking the Semantics of Group Quotas and Slot Weights, I proposed a concept for unifying the semantics of accounting &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://htcondor.github.com/planet/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/planet/atom.xml" rel="alternate" title="HTCondor Project" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">HTCondor Project</a></h1>
  
    <h2>The website and blog for the HTCondor project on github.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/planet/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:htcondor.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/planet">Planet HTCondor</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      

<br>
<h1 align="center"><u> Planet HTCondor </u></h1>

<div class=\"blog-index\">

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2012/11/15/rethinking-the-semantics-of-group-quotas-and-slot-weights-claim-capacity-model/">Rethinking the Semantics of Group Quotas and Slot Weights: Claim Capacity Model</a></h1>
      <p class="meta">
        <time datetime="2012-11-16T00:22:00Z" pubdate data-updated="true">Nov 16<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In my previous post about <a href="http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources">Rethinking the Semantics of Group Quotas and Slot Weights</a>, I proposed a concept for unifying the semantics of accounting group quotas and slot weights across arbitrary resource allocation strategies.</p>

<p>My initial terminology was that the weight of a slot (i.e. resource ad) is a measure of the <em>maximum</em> number of jobs that might match against that ad, given the currently available resource quantities and the allocation policy.  The cost of a match becomes the amount by which that measure is reduced, after the match's resources are removed from the ad.</p>

<p>In the HTCondor vocabulary, a job acquires a <em>claim</em> on resources to actually run after it has been matched.  It has been proposed that it may be beneficial for HTCondor to evolve toward a model where there are (aggregate) resource ads, and claims against those ads, as a simplification of the current model which involves static, partitionable and dynamic slots, with claims.  With this in mind, a preferable terminology for group quota and weight semantics might be that a resource ad (or slot) has a measure of the maximum number of claims it could dispense: a <em>claim capacity</em> measure.  The cost of a claim (or match) is the corresponding reduction of the resource's claim capacity.</p>

<p>So, this semantic model could be referred to as the Claim Capacity Model of group quotas and slot weights.  With this terminology, the shared 'unit' for group quotas and slot weights would be <em>claims</em> instead of <em>jobs</em>.</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources/">Rethinking the Semantics of Group Quotas and Slot Weights for Heterogeneous and Multidimensional Compute Resources</a></h1>
      <p class="meta">
        <time datetime="2012-11-13T22:31:00Z" pubdate data-updated="true">Nov 13<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>The HTCondor semantic for accounting group quotas and slot weights is currently cpu-centric.  This is an artifact of the historic primacy of cpu as the most commonly-considered limiting resource in computations.  For example the <code>SlotWeight</code> attribute is currently defaulted to <code>Cpus</code>, and when slot weights are disabled, there is logic activated in matchmaking to sum the available cpus on slots to avoid 'undercounting' total pool quotas.</p>

<p>However, HTCondor slots -- the core model of computational resources in an HTCondor pool -- manage four resources by default: cpu, memory, disk and swap.  Furthermore, slots may now be configured with arbitrary custom resources.  As recently mentioned by <a href="http://spinningmatt.wordpress.com/2012/11/13/no-longer-thinking-in-slots-thinking-in-aggregate-resources-and-consumption-policies">Matthew Farrellee</a>, there is a growing pressure to provide robust support not just for traditional cpu-centric resource presentation, usage and allocation, but also seamlessly mediated with memory-centric, gpu-centric or '*'-centric resource allocation policies and more generally allocation policies that are simultaneously aware of all resource dimensions.</p>

<p>This goal immediately raises some questions for the semantics of accounting groups and slot weights when matching jobs against slots during matchmaking.</p>

<p>Consider a pool where 50% of the slots are 'weighted' in a traditional cpu-centric way, but the other 50% are intended to be allocated in a memory-centric way.  This is currently possible, as the <code>SlotWeight</code> attribute can be configured appropriately to be a function of either <code>Cpus</code> or <code>Memory</code>.</p>

<p>But in a scenario where slots are weighted as functions of heterogeneous resource dimensions, it raises a semantic question:  when we sum these weights to obtain the pool-wide available quota, what 'real world' quantity does this total represent -- if any?   Is it a purely heuristic numeric value with no well defined unit attached?</p>

<p>This question has import.  Understanding what the answer is, or should be, impacts what story we tell to users about what their accounting group configuration actually means.  When I assign a quota to an accounting group in such a heterogeneous environment, what is that quota regulating?   When a job matches a cpu-centric slot, does the cost of that match have a different meaning than when matching against a memory-centric slot?   When the slots are partitionable, a match implies a certain multi-dimensional slice of resources allocated from that slot.  What is the cost of that slice?  Does the sum of costs add up to the original weight on the partitionable slot?  If not, how does that affect our understanding of quota semantics?</p>

<p>It may be possible unify all of these ideas by adopting the perspective that a slot's weight is a measure of the maximum number of jobs that can be matched against it.  The cost of a match is W(S)-W(S'), where W(S) is the weight function evaluated on the slot prior to match, and W(S') is the corresponding weight after the match has extracted its requested resources.  The pool's total quota is just the sum of W(S), over all slots S in the pool.  Note, this implies that the 'unit' attached to both slot weights and accounting group quotas is 'jobs'.</p>

<p>Consider a simple example from the traditional cpu-centric configuration:   A partitionable slot is configured with 8 cpus, and <code>SlotWeight</code> is just its default <code>Cpus</code>.  Using this model, the allocation policy is: 'each match must use >= 1 cpu", and that other resource requests are assumed to be not limiting.  The maximum number of matches is 8 jobs, each requesting 1 cpu.   However, a job might also request 2 cpus.  In this case, note that the cost of the match is 2, since the remaining slot has 6 slots, and so W(S') now evaluates to 6.   So, the cost of the match is how many fewer possible jobs the original slot can support after the match takes its requested resources.</p>

<p>This approach can be applied equally well to a memory-centric strategy, or a disk centric strategy, or a gpu-based strategy, or any combination simultaneously.  All weights evaluate to a value with unit 'jobs'.   All match costs are differences between weights (before and after match), and so their values are also in units of 'jobs'.  Therefore, the semantics of the sum of weights over a pool is always well defined: it is a number of jobs, and spefically a measure of the maximum number of jobs that might match against all the slots in the pool.  When a match acquires resources that reduce this maximum by more than 1 job, that is not in any way inconsistent.  It means the job used resources that might have supported two or more 'smaller' jobs.   This means that accounting group quotas (and submitter shares) also have a well defined unit and semantic, which is 'how many (or what fraction of) the maximum possible jobs is this group guaranteed by my accounting policy'</p>

<p>One implication of this proposed semantic for quotas and weights is that the measure for the maximum number of jobs that may match against any given slot must be some finite number.   It implies that all resource dimensions are quantized in some way by the allocation policy.   This scheme would not support a real-valued resource dimension that had no minimum quantization.  I do not think that this is a very heavy-weight requirement, and in fact we have already been moving in that direction with features such as MODIFY_REQUEST_EXPRS_xxx.</p>

<p>When a slot's resource allocation policy is defined over all its resources, what bounds this measure of maximum possible matches?  In a case where each job match <em>must</em> use at least one non-zero quantum of each resource dimension, then the limit is the resource with the mimimum quantized levels.   In a case where jobs may request a zero amount of resources, then the limit is the resource with the maximum quantized levels.  (note, it is required that each match use at least one quantum of at least one resource, otherwise the maximum is not properly bounded).</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2012/11/13/no-longer-thinking-in-slots-thinking-in-aggregate-resources-and-consumption-policies/">No longer thinking in slots, thinking in aggregate resources and consumption policies</a></h1>
      <p class="meta">
        <time datetime="2012-11-13T11:56:14Z" pubdate data-updated="true">Nov 13<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content"><p>The slot model was natural when a machine housed a single core. Though, the slot model did not exist when a machine housed a single core.</p>
<p>When machines were single core the model was a machine, represented as a MachineAd. A MachineAd had an associated CPU, some nominal amount of RAM and some chunk of disk space. Running a job meant consuming a machine.</p>
<p>When machines grew multiple cores the machine model was split. A single machine became independent MachineAds, called virtual machines. However, the name didn&#8217;t stick as the term virtual machine became a popular term in hardware virtualization. So a machine became independent MachineAds, called slots. The unifying entity, the machine itself, was lost. Running a job still meant consuming a slot.</p>
<p>Most recently, slots split into two classes: static and partitionable. Static slots are the slots formerly known as virtual machines. Partitionable slots are a representation of the physical machine itself, and are carved up, on-demand to service jobs. Both types are still MachineAds, but the consumption of partitionable slots is dynamic.</p>
<p>The slot model has demonstrated great utility but has been stretched.</p>
<p>In this time workloads have also changed. They have become more memory bound, disk IO bound, and network bound. They have started relying on specialized hardware and even application level services. They have started both spanning and packing into cores. They have grown complex data dependencies, become very short running, and become infrastructure level long running.</p>
<p>Machines have also grown to include scores of cores, hundreds of gigabytes of RAM, dozens of terabytes of disk, specialized hardware such as GPUs, co-processors, entropy keys, high speed interconnects and a bevy of other attached devices.</p>
<p>Machines are lumpy, heterogeneous means more than operating system and CPU architecture.</p>
<p>Furthermore, if it still existed, the machine model itself would fail to cleanly describe available resources. Classes of resources exist that house entire clusters, grids, or life-cycle manageable application services. Resources share addressable memory across operating systems instances, are custom architectures across whole data centers, and even those that don&#8217;t provide an outline of their capacity. Resources may grow and shrink while in use.</p>
<p>Consumption of these resources is not necessarily straightforward or uniform.</p>
<p>It&#8217;s time to stop thinking in slots. Its time to start thinking in aggregate resources and their consumption policies.</p>
<br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/817/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/817/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=817&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin/">Role enforcement in Cumin</a></h1>
      <p class="meta">
        <time datetime="2012-11-12T20:20:00Z" pubdate data-updated="true">Nov 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Trevor McKay</time>
      </p>
    </header>
    <div class="entry-content"><p>Roles in Cumin scope activities and content in the UI.  There are currently two roles defined in Cumin, <code>admin</code> and <code>user</code>.  The <code>admin</code> role is a superset of the <code>user</code> role, and every new account has the <code>user</code> role by default.</p>

<h3>Differences in the Roles</h3>

<p>The <code>admin</code> role allows a user to see various charts, graphs, and statistics related to performance of the Condor pool.  An admin can also see information about Condor infrastructure components such as schedulers and negotiators and can run certain pool management commands.  Admins are free to manage any job running in the pool regardless of who owns the job, but can also switch to the <code>user</code> view for the admin account.</p>

<p>The <code>user</code> role allows a user to create and manage their own submissions.  They do not have visibility to jobs owned by other users, performance metrics, or pool management commands.</p>

<h3>Enabling Role Enforcement</h3>

<p>Role enforcement is disabled by default in the standard Cumin configuration file, effectively making every user an admin (the default will change in a future revision).  To enable role enforcement, set the <code>auth</code> configuration value to <code>True</code> in the cumin.conf configuration file:</p>

<pre><code>[web]
authorize: True  
</code></pre>

<h3>Setting Role Values</h3>

<p>The role value is part of the account metadata along with username and password.  While username and password may optionally be managed in LDAP repositories, role values at this time may only be defined in the local PostgreSQL database.  This restriction will likely be removed in a future version.  You can read more about LDAP authentication in the earlier blog post <em>Cumin Authentication with LDAP</em>, and we&#8217;ll explain how to set roles for external user accounts below.</p>

<p>Roles are managed with the <code>cumin-admin</code> commands <code>add-assignment</code> and <code>remove-assignment</code>:</p>

<pre><code># cumin-admin add-assignment joeuser admin
# cumin-admin remove-assignment joeuser admin
</code></pre>

<p>(An account may have the <code>user</code> and <code>admin</code> roles at the same time, but currently this has no real effect since <code>admin</code> is a superset.  It is not necessary to explicitly set the <code>user</code> role.)</p>

<h3>Creating an Entry to Hold the Role for an LDAP Account</h3>

<p>For accounts authenticated against LDAP, an entry must be added to the PostgreSQL database as a placeholder before the role value may be set.  This is done with the <code>cumin-admin</code> command <code>external-user</code>:</p>

<pre><code># cumin-admin external-user myldapuser
# cumin-admin add-assignment myladpuser admin
</code></pre>

<h3>More to Come</h3>

<p>A future post may address the relationship of roles to <em>persona</em> and talk about development hooks that allow customization of the UI based on user and site profiles.</p>

<p>The Cumin project wiki can be found <a href="http://fedorahosted.org/grid/wiki/Cumin">here</a></p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://timothysc.github.com/blog/2012/11/12/condor-sudo/">Override HTCondor installation with sudo</a></h1>
      <p class="meta">
        <time datetime="2012-11-12T09:00:00Z" pubdate data-updated="true">Nov 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Timothy St. Clair</time>
      </p>
    </header>
    <div class="entry-content"><h2>Background</h2>

<p>As a developer, I often find myself wanting to iterate on a build, and test in a sandboxed environment.  Isolating the environment ensures that your changes work well in a controlled experiment, but it has one fundamental flaw, it&#8217;s not realistic.  In order to truly test a complicated system it&#8217;s best to put it into some production environment.  This is great for testing, but it has been known to give admins a headache, because you are mucking with a known good installation.  So in this post we will set about the task of overriding an installtion of HTCondor using sudo while keeping the following requirements in mind:</p>

<h3>Requirements</h3>

<ul>
<li>Don&#8217;t alter the existing system installation (binaries or config files).</li>
<li>Be able to reference any custom developer build.</li>
<li>Be able to easily change back to the known good installation with little/no effort.</li>
</ul>


<hr />

<h2>Getting Started</h2>

<p>Before you begin you will need a machine which already has HTCondor installed on it, and all the necessary development tools in order to create a custom build.  You will also need to obtain the <a href="https://github.com/htcondor/htcondor">source tree for HTCondor</a>, and follow the instructions on <a href="https://condor-wiki.cs.wisc.edu/index.cgi/wiki?p=BuildModernization">how to build condor.</a>  I typically &#8216;alias cmake&#8217; in my environment with all the clever developer magic to make a sandbox&#8217;d installation out of the gate.</p>

<pre><code>alias cmake='cmake -DCMAKE_INSTALL_PREFIX:PATH=${PWD}/release_dir \
-DBUILDID:STRING=tstclair_local -DWANT_CONTRIB:BOOL=TRUE \
-DWANT_FULL_DEPLOYMENT:BOOL=FALSE -D_VERBOSE:BOOL=TRUE \
-DWANT_MAN_PAGES:BOOL=TRUE -D_DEBUG:BOOL=TRUE'

cmake . &amp;&amp; make install 
</code></pre>

<p>Lastly you will need an account which has sudo privs on the machine where you will be tinkering.</p>

<hr />

<h2>Setting up a Sandbox</h2>

<p>Once you&#8217;ve created build for the target machine that you would like to test, you will need to create a sandbox location which is also accessible by the &#8216;condor&#8217; user, I typically use /tmp.</p>

<pre><code>mkdir /tmp/mycondor
cp -r release_dir /tmp/mycondor 
</code></pre>

<p>Next you will want to drop 3 files into your sandbox directory.</p>

<p>The first file is a simple bash script which kicks off your sandbox&#8217;d condor ensuring that all the correct environment variables are passed through sudo so that HTCondor can properly execute out of your sandbox.</p>

<figure class='code'><figcaption><span> (sudo_condor.sh)</span> <a href='http://timothysc.github.com/downloads/code/scripts/sudo_condor.sh'>download</a></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="c">#!/bin/sh</span>
</span><span class='line'>
</span><span class='line'><span class="nv">foo</span><span class="o">=</span><span class="sb">`</span><span class="nb">pwd</span><span class="sb">`</span>
</span><span class='line'>
</span><span class='line'><span class="nb">export </span><span class="nv">BASE</span><span class="o">=</span><span class="k">${</span><span class="nv">foo</span><span class="k">}</span>
</span><span class='line'><span class="nb">export </span><span class="nv">CONDOR_CONFIG</span><span class="o">=</span><span class="k">${</span><span class="nv">BASE</span><span class="k">}</span>/override.sh<span class="se">\|</span>
</span><span class='line'><span class="nb">export </span><span class="nv">CONDOR</span><span class="o">=</span><span class="k">${</span><span class="nv">BASE</span><span class="k">}</span>/release_dir
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="k">${</span><span class="nv">BASE</span><span class="k">}</span>:<span class="k">${</span><span class="nv">CONDOR</span><span class="k">}</span>/lib:<span class="k">${</span><span class="nv">CONDOR</span><span class="k">}</span>/bin:<span class="k">${</span><span class="nv">CONDOR</span><span class="k">}</span>/sbin:<span class="k">${</span><span class="nv">CONDOR</span><span class="k">}</span>/libexec:<span class="k">${</span><span class="nv">PATH</span><span class="k">}</span>
</span><span class='line'><span class="nb">export </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="k">${</span><span class="nv">CONDOR</span><span class="k">}</span>/lib:<span class="k">${</span><span class="nv">CONDOR</span><span class="k">}</span>/libexec
</span><span class='line'>
</span><span class='line'><span class="c">#start up new condor</span>
</span><span class='line'><span class="nb">echo</span> <span class="s2">&quot;Starting condor... @${CONDOR} with override ${CONDOR_CONFIG}&quot;</span>
</span><span class='line'>sudo env <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span> <span class="nv">CONDOR_CONFIG</span><span class="o">=</span><span class="nv">$CONDOR_CONFIG</span> <span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span> <span class="nv">BASE</span><span class="o">=</span><span class="k">${</span><span class="nv">BASE</span><span class="k">}</span> <span class="k">${</span><span class="nv">CONDOR</span><span class="k">}</span>/sbin/condor_master
</span></code></pre></td></tr></table></div></figure>


<p>If you are testing your client tools, you will also want to mundge your PATH in your testing shell as seen in the script.</p>

<p>The next file is a script which acts as a piped config script.  In HTCondor, there is a feature which allows admins to generate/mundge the parameters which can be passed in on intialization and reconfig.  It turns out this is useful in meeting our previously mentioned requirement of not mucking with the existing configs while still being able to customize as seen below:</p>

<figure class='code'><figcaption><span> (override.sh)</span> <a href='http://timothysc.github.com/downloads/code/scripts/override.sh'>download</a></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="c">#!/bin/sh</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="o">[</span> -z <span class="s2">&quot;$BASE&quot;</span> <span class="o">]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">    </span><span class="nb">echo</span> <span class="s2">&quot;Using pwd&quot;</span>
</span><span class='line'>    <span class="nb">export </span><span class="nv">BASE</span><span class="o">=</span><span class="k">${</span><span class="nv">PWD</span><span class="k">}</span>
</span><span class='line'><span class="k">fi</span>
</span><span class='line'>
</span><span class='line'><span class="c">#take the original system config</span>
</span><span class='line'>cat /etc/condor/condor_config
</span><span class='line'>
</span><span class='line'><span class="c"># override the execution locations</span>
</span><span class='line'><span class="nb">echo</span> <span class="s2">&quot;RELEASE_DIR=${BASE}/release_dir&quot;</span>
</span><span class='line'><span class="nb">echo</span> <span class="s2">&quot;LIB=${BASE}/release_dir/lib&quot;</span>
</span><span class='line'><span class="nb">echo</span> <span class="s2">&quot;INCLUDE=${BASE}/release_dir/include&quot;</span>
</span><span class='line'><span class="nb">echo</span> <span class="s2">&quot;LIBEXEC=${BASE}/release_dir/libexec&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="c">#apply your custom setting overrides</span>
</span><span class='line'>cat <span class="k">${</span><span class="nv">BASE</span><span class="k">}</span>/condor_config.local
</span></code></pre></td></tr></table></div></figure>


<p>The final file is an optional condor_config.local file, which you can create.  This file is appended to the end of the existing config and allows the developers, or admins, to lay out any configuration that they desire or even override the system to behave the way they would like.</p>

<p>Finally you will need to adjust the access permission so that the &#8216;condor&#8217; user can access the shared location.</p>

<pre><code>sudo chown -R "root:root" /tmp/mycondor
</code></pre>

<p>Now lets rock N&#8217; roll!</p>

<pre><code>cd /tmp/mycondor
./sudo_condor.sh
</code></pre>

<p>You&#8217;ve now taken over a existing machine in your pool using all the configuration settings that were there, while still allowing your own config magic.  You should take heed though, if you are testing any changes to condors internal files, you could possibly corrupt what is there.  To avoid this, you can override the SPOOL and EXECUTE directories in your condor_config.local file.</p>

<hr />

<h2>Verify its correct</h2>

<p>The easiest way to verify correctness is to check that the preamble in the logs(/var/log/condor) contains your BUILDID string, in this case it was &#8216;tstclair_local&#8217;.</p>

<hr />

<h2>Potential Use Cases</h2>

<p>It&#8217;s fairly obvious why a developer would want to do this, but it has many potential use cases outside of just development, which include:</p>

<ul>
<li>Beta testing a new installation prior to a pool upgrade.</li>
<li>Testing version compatibility across releases.</li>
<li>Playing with new shiney condor features in a existing pool.</li>
</ul>

</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2012/11/bosco-v11-features-multi-os-support.html">BOSCO v1.1 Features: Multi-OS Support</a></h1>
      <p class="meta">
        <time datetime="2012-11-06T22:11:00Z" pubdate data-updated="true">Nov 6<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content">This is part 3 of my ongoing series describing new features in BOSCO v1.1. &nbsp;Part 1 covered <a href="http://derekweitzel.blogspot.com/2012/10/bosco-v11-features-ssh-file-transfer.html">file transfer over SSH</a>, Part 2 covered <a href="http://derekweitzel.blogspot.com/2012/11/bosco-v11-features-single-port-usage.html">single port usage</a>. &nbsp;This post will cover the Multi-OS Support in BOSCO.<br /><br /><h3>What is it?</h3><div>The Multi-OS feature is intended to allow users to submit to clusters that may not be the same operating system as the submit host. &nbsp;This is especially useful when users are running a submit host on their personal computer that is running Debian, while the supercomputer in the next building is running Red Hat 6, a common&nbsp;occurrence.</div><div><br /></div><div>The Multi-OS components follow a basic process in order to operate:</div><div><ol><li>Detect the remote operating system with the <span style="font-family: Courier New, Courier, monospace;">findplatform</span> script.</li><li>Download (from the cloud?) the appropriate bosco version for the platform.</li><li>Transfer the files needed on the remote cluster. &nbsp;This includes grabbing the libraries and binaries for the campus factory's glideins. &nbsp;The glidein creation takes the most time of this process as it needs to compress the libraries and binaries before transferring.</li><li>When BOSCO detects jobs idle on the submit host, it will start glideins appropriate for the platform to service the jobs.</li></ol><div>The Multi-OS support required modification of the cluster addition and adding both a <span style="font-family: Courier New, Courier, monospace;">findplatform</span> script and a <span style="font-family: Courier New, Courier, monospace;">glidein_creation</span> script. &nbsp;</div></div><div><br /></div><h3>Why do I care?</h3><div>It is becoming increasingly common that what users run on their machines and what is run on supercomputers are different. &nbsp;When this is true, it is difficult to install software from one onto the other. &nbsp;The Multi-OS feature will greatly simplify the installation of BOSCO on clusters.</div><div><br /></div><div>Our goal with the Multi-OS support is that the users may not know it is even working. &nbsp;The users just say: "I want to run on this cluster", and BOSCO makes it happen. &nbsp;No matter what operating system is running on the remote cluster.</div><div><br /></div><div>One of my tests simulated a possible user&nbsp;scenario&nbsp; &nbsp;I was running a updated RHEL 6 machine which I installed BOSCO. &nbsp;I wanted to submit jobs to a RHEL 5 cluster located in our datacenter. &nbsp;If I simply copied over the bosco install from the RHEL 6 submit host, none of the binaries would work. &nbsp;But instead, I used the <span style="font-family: Courier New, Courier, monospace;">bosco_cluster -a</span> to add the RHEL 5 cluster, and jobs ran seamlessly from the RHEL 6 machine to the RHEL 5. &nbsp;</div><br />The Multi-OS support is available in the latest alphas available on the bosco&nbsp;<a href="http://bosco.opensciencegrid.org/download/">download</a>&nbsp;page.<br /><br /><div class="blogger-post-footer"><img width='1' height='1' src='https://blogger.googleusercontent.com/tracker/3007054864987759910-8516182672952525228?l=derekweitzel.blogspot.com' alt='' /></div></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2012/11/05/faq-job-resubmission/">FAQ: Job resubmission?</a></h1>
      <p class="meta">
        <time datetime="2012-11-05T12:07:43Z" pubdate data-updated="true">Nov 5<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content"><p>A question that often arises when approaching Condor from other batch systems is &#8220;How does Condor deal with resubmission of failed/preempted/killed jobs?&#8221;</p>
<p>The answer requires a slight shift in thinking.</p>
<p>Condor provides more functionality around the resubmission use case than most other schedulers. And the default policy is setup in such a way that most Condor folks don&#8217;t ever think about &#8220;resubmission.&#8221;</p>
<p>Condor will keep your job in the queue (condor_schedd managed) until the policy attached to the job says otherwise.</p>
<p>The default policy says a job will be run as many time as necessary for the job to terminate. So if the machine a job is running on crashes (generally, becomes unavailable), the condor_schedd will automatically try to run the job on another machine.</p>
<p>When you start changing the default policy you can control things such as: if a job should be removed after a period of time, even if it is running or only if it hasn&#8217;t started running; if a job should run multiple times even if it terminated cleanly; if a termination w/ an error should make the job run again, be held in the queue for inspection, be removed from the queue; if a job held for inspection should be held forever or a specific amount of time; if a job should only start running at a specific time in the future, or be run at repeated intervals.</p>
<p>The condor_submit manual page can provide specifics.</p>
<br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/812/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/812/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=812&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2012/11/bosco-v11-features-single-port-usage.html">BOSCO v1.1 Features: Single Port Usage</a></h1>
      <p class="meta">
        <time datetime="2012-11-01T20:59:00Z" pubdate data-updated="true">Nov 1<span>st</span>, 2012  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content">Welcome to part 2 of my ongoing series of v1.1 features for BOSCO. &nbsp;Part 1 was on <a href="http://derekweitzel.blogspot.com/2012/10/bosco-v11-features-ssh-file-transfer.html">SSH File Transfer</a>.<br /><br />This time, I'll talk about a new feature that we didn't planned on implementing at first, using only a single port for all communication. &nbsp;After a small investigation, it was discovered that using a single port is very simple, and with no interruption to other components. &nbsp;I talked briefly about it in a <a href="http://derekweitzel.blogspot.com/2012/09/flocking-to-osg-behind-restrictive.html">previous post</a>.<br /><br /><h3>What is it?</h3><div>In 1.0 of BOSCO, the submit host needed a lot of ports open for connections originating from the remote clusters. &nbsp;This was caused by 2 mechanisms:</div><div><ol><li>File transfer from the BOSCO submit host to the cluster login node before issuing the local submit call (qsub, condor_submit...). &nbsp;This opens ports on the submit host because the cluster would call out to the submit host to initiate transfers.</li><li>Connections for control, status, and workflow management between the cluster worker nodes and BOSCO submit host. &nbsp;This is the Campus Factory, which gives BOSCO the traditional Condor look and feel.</li></ol>In order for BOSCO to function, the submit host needs a large swath of ports in order to operate correctly. &nbsp;Also, as you scale, you will need even more ports open.</div><div><br /></div><div>The file transfers from the submit host to the login node are now being transferred using SSH, see my <a href="http://derekweitzel.blogspot.com/2012/10/bosco-v11-features-ssh-file-transfer.html">previous post</a>.</div><div><br /></div><div>With the new feature of single port usage, all control, status, and workflow management connections are routed through HTCondor's <a href="http://research.cs.wisc.edu/condor/manual/v7.9/3_7Networking_includes.html#SECTION00472000000000000000">share_port_daemon</a> on port 11000 (which is hardcoded, but I picked at random).</div><div><br /></div><h3>Why should I care?</h3><div>Limiting BOSCO to using only 1 incoming port is very useful for users on systems not managed by them. &nbsp;The node will only need 1 port open in order to run BOSCO, 11000. &nbsp;If the system has a firewall, you only have to request port 11000 be opened, rather than huge swaths. &nbsp;If you manage the system, then you will be happy that only 1 port needs to be opened in order to allow BOSCO submissions.</div><div><br /></div><div>Administrators will like this feature as it is more in line with other applications that they may run. &nbsp;For example, httpd only requires 1 port, 80. &nbsp;Now BOSCO is in the same realm, only requiring 1 port, 11000.</div><div class="blogger-post-footer"><img width='1' height='1' src='https://blogger.googleusercontent.com/tracker/3007054864987759910-2355522235500004311?l=derekweitzel.blogspot.com' alt='' /></div></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/11/best-practices-for-wallabys-default-group.html">Best practices for Wallaby's default group</a></h1>
      <p class="meta">
        <time datetime="2012-11-01T20:14:53Z" pubdate data-updated="true">Nov 1<span>st</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">
        <p>Recall that <a href="http://getwallaby.com">Wallaby</a> applies partial configurations to <em>groups</em> of <em>nodes</em>.  Groups can be either <em>explicit</em> &#8212;- that is, a named subset of nodes created by the user, or <em>special</em> groups that are built-in to Wallaby; each node&#8217;s group memberships have a priority ordering, so that an individual node&#8217;s configuration can favor the partial configuration from one group over another.  There are two kinds of special groups:  the <em>default group</em>, which contains every node and a set of <em>identity groups</em>, each of which only contains a single node.  In addition, Wallaby includes a <a href="http://getwallaby.com/2012/06/using-the-skeleton-group/"><em>skeleton group</em></a>, which combines aspects of explicit and special groups:  while it can be managed like an explicit group, all newly-created nodes become members of the skeleton group automatically.  The default group is always the lowest-priority membership for a node and its identity group is always the highest-priority membership; a node&#8217;s skeleton group membership can be reprioritized or removed as necessary.</p>

<p>The default group is an appealing target for common pool configuration, since it is guaranteed to be applied to every node.  However, because Wallaby&#8217;s configuration model is <em>additive</em>, it is likely not the best place for every configured feature or parameter setting that you might initially consider applying to the whole pool.  For example, if a group&#8217;s partial configuration installs a feature, every node that is a member of that group will install that feature (there is no way to say &#8220;this group&#8217;s configuration removes feature <em>F</em>, if it happens to be installed already).  Similarly, if a parameter is set on a group, every node that is a member of that group will have that parameter set; individual node configurations can override the value that the parameter is set to within the group, but there is no way to unset the parameter altogether.  Therefore, if you need to enable a feature on <em>almost every</em> node, the default group is not the right place to install that feature.  (Indeed, the default group is not the right place to put a putatively universal parameter setting or feature installation even if you can imagine a future exception to its universality.)  The default group is also not a great place to put configuration that you expect to take priority over other possible group configurations, since it will always be at the lowest priority.</p>

<p>At this point, you may be asking yourself why you&#8217;d want to put any configuration in the default group.  While I tend towards a minimal default group configuration myself, I absolutely see several use cases for the default group:</p>

<ol>
<li><strong>Setting configuration parameters that are actually uniform across the whole pool</strong> (and will require a new value, not the absence of a value, if they change).  One such parameter is <code>FILESYSTEM_DOMAIN</code>, which you can set to an arbitrary string in order to identify machines that access the same shared filesystem.  If you were to extend your pool with machines that couldn&#8217;t access that same filesystem, you&#8217;d provide a new value for this parameter.</li>
<li><strong>Installing Wallaby features that you actually want installed on every node.</strong>  I&#8217;d include features like <code>Master</code>, which ensures that the <code>condor_master</code> daemon is running (since Wallaby&#8217;s configuration daemon runs under the <code>condor_master</code>; a node can&#8217;t be configured if it isn&#8217;t running) and <code>NodeAccess</code>, which controls access to the pool (although the specific policy parameters required by <code>NodeAccess</code> may change in pool subsets).</li>
<li><strong>Rapidly prototyping configurations for homogeneous or small, experimental pools.</strong>  When you&#8217;re first using Wallaby, the default group is a convenient way to get things running.  Similarly, if most of your nodes are execute nodes with the same policies, you may be able to put most of your configuration in the default group, especially if your submit and central manager configurations are generally a superset of your execute node configuration.  Fortunately, Wallaby makes it straightforward to move configuration from the default group to an explicit group if you should require more flexibility.</li>
</ol>

<p>I&#8217;m sure there are other cases in which using the default group makes good sense, but in general, you should strongly consider using an explicit group or the skeleton group for almost all of your nearly-universal configuration.  If you haven&#8217;t used the skelton group before, <a href="http://getwallaby.com/2012/06/using-the-skeleton-group/">read more about it</a>!</p>

        

    </div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2012/11/01/using-accounting-groups-with-wallaby/">Using Accounting Groups With Wallaby</a></h1>
      <p class="meta">
        <time datetime="2012-11-01T14:41:00Z" pubdate data-updated="true">Nov 1<span>st</span>, 2012  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In this post I will describe how to use HTCondor accounting groups with <a href="http://getwallaby.com">Wallaby</a>.  I will begin by walking through an accounting group configuration on a pool managed by wallaby.  Following, I will demonstrate the configuration in action.</p>

<p>The gist of this demo will be to create a simple accounting group hierarchy:  A top-level group called <code>Demo</code>, and three child groups <code>Demo.A, Demo.B, Demo.C</code>.  <code>Demo</code> will be given a <em>static</em> quota to simulate the behavior of a pool with a particular number of slots available.  The child groups will use <em>dynamic</em> quotas to express their quota shares from the parent as ratios.</p>

<p>First, it is good practice to snapshot current wallaby configuration for reference:</p>

<pre><code>$ wallaby make-snapshot "pre demo state"
</code></pre>

<p>We will be constructing a wallaby feature called <code>AccountingGroups</code> to hold our accounting group configurations.  This creates the feature:</p>

<pre><code>$ wallaby add-feature AccountingGroups
</code></pre>

<p>Wallaby wants to know about features that are used in configurations, so begin by declaring them to the wallaby store:</p>

<pre><code>$ wallaby add-param GROUP_NAMES
$ wallaby add-param GROUP_QUOTA_Demo
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.A
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.B
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.C
$ wallaby add-param GROUP_ACCEPT_SURPLUS_Demo
$ wallaby add-param NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION
$ wallaby add-param NEGOTIATOR_CONSIDER_PREEMPTION
$ wallaby add-param CLAIM_WORKLIFE
</code></pre>

<p>Here we disable the "claim worklife" feature by setting claims to expire immediately.   This prevents jobs under one accounting group from acquiring surplus quota and holding on to it when new jobs arrive under a different group:</p>

<pre><code>$ wallaby add-params-to-feature ExecuteNode CLAIM_WORKLIFE=0
$ wallaby add-params-to-subsystem startd CLAIM_WORKLIFE
$ wallaby add-params-to-feature Scheduler CLAIM_WORKLIFE=0
$ wallaby add-params-to-subsystem scheduler CLAIM_WORKLIFE
</code></pre>

<p>If you alter the configuration parameters, you will want the negotiator to reconfigure itself when you activate.  Here we declare the accounting group features as part of the negotiator subsystem:</p>

<pre><code>$ wallaby add-params-to-subsystem negotiator \
GROUP_NAMES \
GROUP_QUOTA_Demo \
GROUP_QUOTA_DYNAMIC_Demo.A \
GROUP_QUOTA_DYNAMIC_Demo.B \
GROUP_QUOTA_DYNAMIC_Demo.C \
NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION \
NEGOTIATOR_CONSIDER_PREEMPTION
</code></pre>

<p>Activate the configuration so far to tell subsystems about new parameters for reconfig</p>

<pre><code>$ wallaby activate
</code></pre>

<p>Now we construct the actual configuration as the <code>AccountingGroups</code> wallaby feature.  Here we are constructing a group <code>Demo</code> with three subgroups <code>Demo.{A|B|C}</code>.  In a multi-node pool with several cores, it is often easiest to play with group behavior by creating a sub-hierarchy such as this <code>Demo</code> sub-hierarchy, and configuring <code>GROUP_ACCEPT_SURPLUS_Demo=False</code>, so that the sub-hierarchy behaves with a well-defined total slot quota (in this case 15).  The sub-groups A,B and C each take 1/3 of the parent's quota, so in this example each will receive 5 slots.</p>

<pre><code>$ wallaby add-params-to-feature AccountingGroups \
NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION=False \
NEGOTIATOR_CONSIDER_PREEMPTION=False \
GROUP_NAMES='Demo, Demo.A, Demo.B, Demo.C' \
GROUP_ACCEPT_SURPLUS=True \
GROUP_QUOTA_Demo=15 \
GROUP_ACCEPT_SURPLUS_Demo=False \
GROUP_QUOTA_DYNAMIC_Demo.A=0.333 \
GROUP_QUOTA_DYNAMIC_Demo.B=0.333 \
GROUP_QUOTA_DYNAMIC_Demo.C=0.333
</code></pre>

<p>With our accounting group feature created, we can apply it to the machine our negotiator daemon is running on.  Then snapshot our configuration modifications for reference, and activate the new configuration:</p>

<pre><code>$ wallaby add-features-to-node negotiator.node.com AccountingGroups
$ wallaby make-snapshot 'new acct group config'
$ wallaby activate
</code></pre>

<p>Now we will demonstrate the new feature in action.  Submit the following file to your pool, which submits 100 jobs each to groups <code>Demo.A</code> with durations randomly chosen between 25 and 35 seconds:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = $$([25 + random(11)])
transfer_executable = false
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="Demo.A.user1"
queue 100
</code></pre>

<p>Once you make this submission, allow the jobs to negotiate, and you can check to see what accounting groups are running on slots by inspecting the value of <code>RemoteNegotiatingGroup</code> on slot ads.   You should see that subgroup <code>Demo.A</code> has acquired surplus and is running 15 jobs, as there are no jobs under groups <code>Demo.B</code> or <code>Demo.C</code> that need slots.  Note, due to jobs completing between negotiation cycles, these numbers can be less than the maximum possible at certain times.  If you have any other slots in the pool, they will show up in the output below as having either <code>undefined</code> negotiating group or possibly <code>&lt;none&gt;</code> if any other jobs are running.</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
 15 Demo.A
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>Now submit some jobs against <code>Demo.B</code> and <code>Demo.C</code>, like so:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = $$([25 + random(11)])
transfer_executable = false
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="Demo.B.user1"
queue 100
+AccountingGroup="Demo.C.user1"
queue 100
</code></pre>

<p>Once these jobs begin to negotiate, we expect to see the jobs balanced between the three groups evenly, as we gave each group 1/3 of the quota:</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
  5 Demo.A
  5 Demo.B
  5 Demo.C
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>Finally, we see what happens if we remove jobs under <code>Demo.B</code>:</p>

<pre><code>$ condor_rm -constraint 'AccountingGroup =?= "Demo.B.user1"'
</code></pre>

<p>Now we should see quota start to share between <code>Demo.A</code> and <code>Demo.C</code>:</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
  7 Demo.A
  8 Demo.C
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>With this accounting group configuration in place, you can play with changing quotas for the accounting groups and observe the numbers of running jobs change in response.</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2012/10/31/randomized-sleep-jobs-in-htcondor-using-delayed-evaluation/">Randomized Sleep Jobs in HTCondor Using Delayed Evaluation</a></h1>
      <p class="meta">
        <time datetime="2012-10-31T21:17:00Z" pubdate data-updated="true">Oct 31<span>st</span>, 2012  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In some cases, when testing or demonstrating the performance of an HTCondor pool, it is useful to submit a plug of jobs with randomized running times.  The standard technique for controlling run times is to submit a classic 'sleep' job.  However, randomizing the argument to sleep is another matter.  Luckily there is an easy way to do this with a single submit file, using delayed evaluation syntax.</p>

<p>A classad expression placed inside of a special enclosure, like this: <code>$$([ &lt;expr&gt; ])</code>, causes <code>&lt;expr&gt;</code> to be evaluated at the time the job ad is matched with a slot.  You can read more about delayed evaluation <a href="http://research.cs.wisc.edu/condor/manual/v7.8/condor_submit.html#78367">here</a>.  Consider the following example submit file:</p>

<pre><code>universe = vanilla
executable = /bin/sleep

# generate a random sleep duration when job is matched
args = $$([25 + random(11)])

# boilerplate to avoid file transfers and notifications
transfer_executable = false
should_transfer_files = no
when_to_transfer_output = on_exit
notification = never

# generate 100 copies of this job - each will evaluate the
# randomizing expression independently
queue 100
</code></pre>

<p>As you can see in the example above, the value of <code>args</code> is set to the delayed evaluation expression <code>$$([25 + random(11)])</code>, which will evaluate the classad expression <code>25 + random(11)</code> when each job ad matches a slot to run.  The <code>queue 100</code> command generates 100 separate job ads, and so the net effect is 100 jobs, which will each run a sleep job with a duration <em>randomly chosen</em> between 25 and 35.</p>

<p>If we submit this file to a condor pool, and let the jobs run to completion, we can check the pool history file to see how the <code>Args</code> attribute was set on the job ad using the special generative attribute <code>MATCH_EXP_Args</code>, and the <a href="http://erikerlandson.github.com/blog/2012/06/29/easy-histograms-and-tables-from-condor-jobs-and-slots/">cchist tool</a>:</p>

<pre><code>$ cchist condor_history 'MATCH_EXP_Args'
     11 25
      7 26
     10 27
      9 28
      7 29
     13 30
      8 31
      7 32
      8 33
      9 34
     11 35
    100 total
</code></pre>

<p>We can also sanity check our measure of actual run time, to see that those values are close to our values of <code>Args</code>:</p>

<pre><code>$ cchist condor_history 'CompletionDate-JobCurrentStartDate'
      1 25
     11 26
      9 27
      8 28
      9 29
      9 30
     12 31
      4 32
      8 33
     10 34
     12 35
      6 36
      1 37
    100 total
</code></pre>

<p>Have fun with easy random sleep jobs!</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2012/10/bosco-v11-features-ssh-file-transfer.html">BOSCO v1.1 Features: SSH File Transfer</a></h1>
      <p class="meta">
        <time datetime="2012-10-29T19:30:00Z" pubdate data-updated="true">Oct 29<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content">I am hoping to write about a few of the new features of BOSCO 1.1 before it comes out in December or January. &nbsp;This is part 1 of that series:<br /><br /><h3>BOSCO v1.1 Feature: SSH File Transfer</h3><div><b>What is it?</b></div><div>SSH File Transfer feature improves the method of staging input and output files to the remote cluster. &nbsp;In 1.0, files are transferred by starting a daemon on the remote cluster that connects back to the submit host over a random port. &nbsp;This required a lot of open ports on the submit host. &nbsp;</div><div><br /></div><div>The new SSH File Transfer will limit the number of ports required on the submit host. &nbsp;BOSCO will now transfer files over a port that is forwarded over the SSH connection that BOSCO maintains with the remote cluster. &nbsp;The transfers are&nbsp;inherently&nbsp;secure as they are over the SSH connection, as well as they are authenticated by the Condor daemons on either end of the connection (remote cluster and submit host). &nbsp;&nbsp;</div><div><br /></div><div>This fits into the BOSCO team's goal of lowering the amount of ports used by Condor. &nbsp;Our eventual goal is using the Shared Port Daemon to limit the required ports to 1 for BOSCO on the submit host.</div><div><br /></div><div><b>Why should I care?</b></div><div>This will greatly reduce the number of ports required if you are only using the <span style="font-family: Courier New, Courier, monospace;">universe=grid</span><span style="font-family: inherit;">&nbsp;method of submitting jobs. &nbsp;In fact, it will reduce the open ports on the submit host to 0. &nbsp;That means no more configuring firewalls for BOSCO (no campus factory support, see below). &nbsp;Additionally, there is no new configuration required for this feature, it 'just works' (famous last words?)</span></div><div><span style="font-family: inherit;"><br /></span></div><div><span style="font-family: inherit;">The Campus Factory, which adds features such as fault tolerant Condor file transfer and transparent multi-cluster support, still requires multiple open ports in the firewall. &nbsp;Additional effort will be required to change the Campus Factory configuration and daemons to support the single port. &nbsp;I hope that a single port will be all that is needed for v1.2. &nbsp;</span></div><div><span style="font-family: inherit;"><br /></span></div><h3><span style="font-family: inherit;">What's Next</span></h3><div><span style="font-family: inherit;">Over the next couple weeks, I hope to write more about upcoming features such as:</span></div><div><ul><li>Multi-Platform support (ie cluster and submit host are different platforms)</li><li>Mac OSX Support</li><li>Improved Multi-User support</li></ul></div><div><span style="font-family: inherit;"><br /></span></div><div class="blogger-post-footer"><img width='1' height='1' src='https://blogger.googleusercontent.com/tracker/3007054864987759910-3237281153809597870?l=derekweitzel.blogspot.com' alt='' /></div></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site/">Welcome To The HTCondor Project Github Site</a></h1>
      <p class="meta">
        <time datetime="2012-10-29T17:15:00Z" pubdate data-updated="true">Oct 29<span>th</span>, 2012  &nbsp; &mdash; &nbsp; HTCondor Team GitHub</time>
      </p>
    </header>
    <div class="entry-content"><p>Welcome to the HTCondor Project GitHub website!  This site is the github web and blog presence for the HTCondor project.</p>

<p>We will also be hosting the Planet HTCondor feed aggregator for blog entries from HTCondor community members, which you can see <a href="http://htcondor.github.com/planet">here</a>.  You can subscribe to the meta-feed for Planet HTCondor at <a href="http://htcondor.github.com/planet/atom.xml">this link</a>.</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2012/10/29/pre-and-post-job-scripts/">Pre and Post job scripts</a></h1>
      <p class="meta">
        <time datetime="2012-10-29T11:07:05Z" pubdate data-updated="true">Oct 29<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content"><p><a href="http://cs.wisc.edu/condor">Condor</a> has a few ways to run programs associated with a job, beyond the job itself. If you&#8217;re an administrator, you can use the USER_JOB_WRAPPER. If you&#8217;re a user who is friends with your administrator, you can use Job Hooks. If you are ambitious, you can wrap all your jobs in a script that runs programs before and after your actual job.</p>
<p>Or, you can use the PreCmd and PostCmd attributes on your job. They specify programs to run before and after your job executes. By example,</p>
<p><pre class="brush: plain; gutter: false;">
$ cat prepost.job
cmd = /bin/sleep
args = 1

log = prepost.log
output = prepost.out
error = prepost.err

+PreCmd = &amp;quot;pre_script&amp;quot;
+PostCmd = &amp;quot;post_script&amp;quot;

transfer_input_files = pre_script, post_script
should_transfer_files = always

queue
</pre></p>
<p><pre class="brush: bash; gutter: false;">
$ cat pre_script
#!/bin/sh
date &amp;gt; prepost.pre

$ cat post_script
#!/bin/sh
date &amp;gt; prepost.post
</pre></p>
<p>Running,</p>
<p><pre class="brush: plain; gutter: false;">
$ condor_submit prepost.job
Submitting job(s)
.
1 job(s) submitted to cluster 1.

...wait a few seconds, or 259...

$ cat prepost.pre
Sun Oct 14 18:06:00 UTC 2012

$ cat prepost.post
Sun Oct 14 18:06:02 UTC 2012
</pre></p>
<p>That&#8217;s about it, except for some gotchas.</p>
<ul>
<li>transfer_input_files is manual and required</li>
<li>The scripts are run from Iwd, you can&#8217;t use +PreCmd=&#8221;/bin/blah&#8221;, instead +PreCmd=&#8221;blah&#8221; and transfer_input_files=/bin/blah</li>
<li>should_transfer_files = always, scripts are run from Iwd, if run local to the Schedd Iwd will be in the EXECUTE directory but the scripts won&#8217;t be</li>
<li>Script stdout/err and exit code are ignored</li>
<li>You must use +Attr=&#8221;" syntax, +PreCmd=pre_script won&#8217;t work</li>
<li>There is no option of arguments for the scripts</li>
<li>There is no starter environment, thus no $_CONDOR_JOB_AD/$_CONDOR_MACHINE_AD, but you can find .job_ad and .machine_ad in $_CONDOR_SCRATCH_DIR</li>
<li>Make sure the scripts are executable, otherwise the job will be put on hold with a reason similar to: Error from 127-0-0-1.NO_DNS: Failed to execute &#8216;&#8230;/dir_30626/pre_script&#8217;: Permission denied </li>
<li>PostCmd is broken in condor 7.6, but works in 7.8</li>
</ul>
<br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/801/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/801/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=801&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/10/configuring-high-availability-condor-central-managers-with-wallaby.html">Configuring high-availability Condor central managers with Wallaby</a></h1>
      <p class="meta">
        <time datetime="2012-10-23T04:34:58Z" pubdate data-updated="true">Oct 23<span>rd</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">
        <p>Rob Rati and I gave a tutorial on <a href="http://research.cs.wisc.edu/condor/CondorWeek2012/presentations/rati-benton-condor-ha.pdf">highly-available job queues at Condor Week this year</a>.  While it was not a <a href="http://getwallaby.com">Wallaby</a>-specific tutorial, we did point out that configuring highly-available job queues is easier for users who manage and deploy their configurations with Wallaby; compare the manual and automated approaches in the following slides:</p>

<p><img src="http://chapeau.freevariable.com//haschedd.png" alt="Haschedd" title="haschedd.png" border="0" width="398" height="600" /></p>

<p>Configuring <a href="http://research.cs.wisc.edu/condor/manual/v7.6/3_11High_Availability.html#SECTION004112000000000000000">highly-available central managers</a> (HA CMs) is rather more involved than configuring highly-available job queues.  Here&#8217;s what a successful HA CM setup requires:</p>

<ul>
<li>all hosts that serve as candidate central managers (CMs) must be included in the <code>CONDOR_HOST</code> variable across the pool</li>
<li>the <code>had</code> and <code>replication</code> daemons must be set up to run on candidate CMs</li>
<li>the <code>HAD_LIST</code> and <code>REPLICATION_LIST</code> configuration variables must include a list of candidate CMs and the ports on which the <code>had</code> and <code>replication</code> daemons are running on these hosts</li>
<li>various tunable settings related to shared-state and failure detection must be set</li>
</ul>

<p>Wallaby includes <code>HACentralManager</code>, a ready-to-install feature that has sensible defaults for setting up a candidate CM.  The tedious work of constructing lists of hostnames and ports &#8212; and ensuring that these are set everywhere that they must be &#8212; can take great advantage of Wallaby&#8217;s scriptability.  At the bottom of this post is a simple Wallaby shell command that sets up a highly-available central manager with several nodes serving as candidate CMs.  To use it, download it and place it in your <code>WALLABY_COMMAND_DIR</code> (<a href="http://getwallaby.com/2010/10/extending-the-wallaby-shell/">review how to install Wallaby shell command extensions if necessary</a>).  Then invoke it with </p>

<pre><code>wallaby setup-ha-cms fred barney wilma betty
</code></pre>

<p>The above invocation will set up <code>fred</code>, <code>barney</code>, <code>wilma</code>, and <code>betty</code> as candidate CMs, place the candidate CMs in the <code>PotentialCMs</code> group (creating this group if necessary), and configure Wallaby&#8217;s default group to use the highly-available CM cluster.  (The <code>setup-ha-cms</code> command takes options to put candidate CMs in a different group or apply this configuration to some subset of the pool; invoke it with <code>--help</code> for more information.)</p>

<p>Once you&#8217;ve set up your candidate CMs, be sure to activate the new configuration:</p>

<pre><code>wallaby activate
</code></pre>

<p>Of course, <code>wallaby activate</code> will alert you to any problems that prevent your configuration from taking effect.  Correct any errors that come up and activate again, if necessary.  The <code>setup-ha-cms</code> command is a pretty simple example of automating configuration, but it saves a lot of repetitive and error-prone effort!</p>

<p><strong>UPDATE</strong>:  The command will now remove all nodes from the candidate CM group before adding any nodes to it.  This ensures that if the command is run multiple times with different candidate CM node sets, only the most recent set will receive the candidate CM configuration.  (The command as initially posted would apply the candidate CM configuration to every node that was in the candidate CM group at invocation time, but only those nodes that were named in its most recent invocation would actually become candidate CMs.)  Thanks to <a href="http://rrati.github.com">Rob Rati</a> for the observation.</p>

<p><script src="https://gist.github.com/3936568.js"> </script><noscript>View this post in your browser to see the embedded script.</noscript></p>

        

    </div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2012/10/22/tip-iso8601-dates-in-your-logs/">Tip: ISO8601 dates in your logs</a></h1>
      <p class="meta">
        <time datetime="2012-10-22T11:37:21Z" pubdate data-updated="true">Oct 22<span>nd</span>, 2012  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content"><p>Condor produces internal data in both structured and unstructured forms.</p>
<p>The structured forms are just that and designed to be processed by external programs. These are the event logs (UserLog or EVENT_LOG), the HISTORY file and PER_JOB_HISTORY_DIR and POOL_HISTORY_DIR, and the job_queue.log and Accountantnew.log transaction logs.</p>
<p>The unstructured forms are for debugging and designed to be read by a person, often an experienced person. They are often called trace, or debug, logs and are the files in the LOG directory, or the extra output seen when passing -debug to command-line tools, i.e. condor_q -debug.</p>
<p>Consuming and processing the unstructured forms with external programs is increasingly important. Consider tracing incidents through a deployment of 50,000 geographically distributed, physical and virtual systems. Or, even 100 local systems.</p>
<p>More and more tools that provide the ability to aggregate unstructured logs are emerging and they all need to do some basic parsing of the logs. Help make their integration simpler and use a well defined format for timestamps.</p>
<p>For instance, ISO8601 -</p>
<pre>
DEBUG_TIME_FORMAT = "%Y-%m-%dT%H:%M:%S%z "
</pre>
<br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/757/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/757/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=757&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers/">Using Cluster Suite's GUI to configure High Availability Schedulers </a></h1>
      <p class="meta">
        <time datetime="2012-10-18T17:20:00Z" pubdate data-updated="true">Oct 18<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Robert Rati</time>
      </p>
    </header>
    <div class="entry-content"><p>In an <a href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/">earlier post</a> I talked about using Cluster Suite
to manage high availability schedulers and referenced the command line tools
available perform the configuration.  I'd like to focus on using the GUI that
is part of Cluster Suite to configure an HA schedd.  It's a pretty simple
process but does require you run a wallaby shell command to complete the
configuration.</p>

<p>The first thing you need to do is create or import your cluster in the GUI.
If you already have a cluster in the GUI then make sure the nodes you want to
be part of a HA schedd configuration are part of the cluster.</p>

<p>The next step is to create a restricted Failover Domain.  Nodes in this domain
will run the schedd service you create, and making it restricted ensures that
no nodes outside the Failover Domain will run the service.  If a node in the
Failover Domain isn't available then the service won't run.</p>

<p>The third step is to create a service that will comprise your schedd. Make
sure that the relocation policy on the service is Relocate and that it is
configured to use whatever Failover Domain you have already setup.  The
service will contain 2 resources in a parent-child configuration.  The parent
service is the NFS Mount and the child service is a condor instance resource.
This is what sets up the dependency between the NFS Mount being required for
the condor instance to run.  When the resources are configured like this it
means the parent must be functioning for the child to operate.</p>

<p>Finally, you need to sync the cluster configuration with wallaby.  This is
easily accomplished by logging into a machine in the cluster and running:</p>

<pre><code>wallaby cluster-sync-to-store
</code></pre>

<p>That wallaby shell command will inspect the cluster configuration and
configure wallaby to match it.  It can handle any number of schedd
configurations so you don't need to run it once per setup.  However, until
the cluster-sync-to-store command is executed, the schedd service you created
can't and won't run.</p>

<p>Start your service or wait for Cluster Suite to do it for you and you'll find
an HA schedd in your pool.</p>

<p>You can get a video of the process as <a href="http://rrati.fedorapeople.org/videos/cs_gui_schedd.ogv">ogv</a> or <a href="http://rrati.fedorapeople.org/videos/cs_gui_schedd.mp4">mp4</a> if the inline video doesn't work.</p>

<p><video width='800' height='600' preload='none' controls poster=''><source src='http://rrati.fedorapeople.org/videos/cs_gui_schedd.mp4' type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'/></video></p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://spinningmatt.wordpress.com/2012/10/15/advanced-scheduling-execute-periodically-with-cron-jobs/">Advanced scheduling: Execute periodically with cron jobs</a></h1>
      <p class="meta">
        <time datetime="2012-10-15T09:55:02Z" pubdate data-updated="true">Oct 15<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Matthew Farrellee</time>
      </p>
    </header>
    <div class="entry-content">If you want to run a job periodically you could repeatedly submit jobs, or qedit existing jobs after they run, but both of those options are a kludge. Instead, the condor_schedd provides support for cron-like jobs as a first-class citizen. The cron-like feature builds on the ability to defer job execution. However, instead of using [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=744&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" /></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://tmckayus.github.com/blog/2012/10/10/ldap-credentials/">Credentials in LDAP URLs when Anonymous Search is Disabled</a></h1>
      <p class="meta">
        <time datetime="2012-10-10T20:55:00Z" pubdate data-updated="true">Oct 10<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Trevor McKay</time>
      </p>
    </header>
    <div class="entry-content"><p>Cumin authenticates logins against LDAP using a two step process: [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2012/10/05/hosting-a-blog-feed-aggregator-with-octopress/">Hosting a Blog Feed Aggregator With Octopress</a></h1>
      <p class="meta">
        <time datetime="2012-10-05T19:52:00Z" pubdate data-updated="true">Oct 5<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>I have written an Octopress plugin to allow turnkey support for hosting a blog feed aggregator, in Octopress idiomatic style.  I will describe the steps to install it and use it below.  Some of its current features are: [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2012/09/flocking-to-osg-behind-restrictive.html">Flocking to the OSG behind a restrictive Firewall</a></h1>
      <p class="meta">
        <time datetime="2012-09-28T03:28:00Z" pubdate data-updated="true">Sep 28<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/">Using Cluster Suite to Manage a High Availability Scheduler</a></h1>
      <p class="meta">
        <time datetime="2012-09-26T19:53:00Z" pubdate data-updated="true">Sep 26<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Robert Rati</time>
      </p>
    </header>
    <div class="entry-content"><p>Condor provides simple and easy to configure HA functionality for the schedd
that relies upon shared storage (usually NFS).  The shared store is used to
store the job queue log and coordinate which node is running the schedd.  This
means that each node that can run a particular schedd not only have condor
configured but the node needs to be configured to access the shared storage. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://tmckayus.github.com/blog/2012/09/24/ldap-auth/">Integrating Cumin with LDAP for Authentication</a></h1>
      <p class="meta">
        <time datetime="2012-09-24T16:41:00Z" pubdate data-updated="true">Sep 24<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Trevor McKay</time>
      </p>
    </header>
    <div class="entry-content"><p>Past versions of Cumin have relied on a local database for storing user accounts.  However, that solution adds extra maintenance for site administrators who already have or plan to have a central authentication mechanism for their users.  Consequently, development is ongoing to integrate Cumin with common central auth mechanisms.  LDAP integration is available now, with support for other technologies planned for the future. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://tmckayus.github.com/blog/2012/09/24/new-post/">So What is Cumin Anyway?</a></h1>
      <p class="meta">
        <time datetime="2012-09-24T16:07:00Z" pubdate data-updated="true">Sep 24<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Trevor McKay</time>
      </p>
    </header>
    <div class="entry-content"><p>Cumin is a Python web UI developed in the Fedora community for managing Condor pools and Qpid messaging brokers.  It is packaged for Fedora but may be run from sources and would probably be easy to port to other Linux distributions (or just run Fedora on a node or two in a heterogeneous environment!)  The current development focus for Cumin is on expanding the Condor management facilities. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://timothysc.github.com/blog/2012/09/21/condor-n-overt/">Elastic Grid with Condor and oVirt Integration</a></h1>
      <p class="meta">
        <time datetime="2012-09-21T08:50:00Z" pubdate data-updated="true">Sep 21<span>st</span>, 2012  &nbsp; &mdash; &nbsp; Timothy St. Clair</time>
      </p>
    </header>
    <div class="entry-content"><h2>Background</h2> [...]
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://rrati.github.com/blog/2012/09/18/putting-it-together/">Putting It Together</a></h1>
      <p class="meta">
        <time datetime="2012-09-18T12:59:00Z" pubdate data-updated="true">Sep 18<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Robert Rati</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://getwallaby.com/2012/09/authorization-for-wallaby-clients/">Authorization for Wallaby clients</a></h1>
      <p class="meta">
        <time datetime="2012-09-12T22:30:00Z" pubdate data-updated="true">Sep 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways.  This post will explain how the authorization support works and show how to get started using it.  If you just want to get started using Wallaby with authorization support as quickly as possible, skip ahead to the section titled &#8220;Getting Started&#8221; below.  Detailed information about which role is required for each Wallaby API method is <a href="http://getwallaby.com/api-roles/">available here</a>. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/09/authorization-for-wallaby-clients.html">Authorization for Wallaby clients</a></h1>
      <p class="meta">
        <time datetime="2012-09-12T22:23:18Z" pubdate data-updated="true">Sep 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways. This post will explain how the authorization support works and show how to...</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit/">Dust off nuke it from orbit</a></h1>
      <p class="meta">
        <time datetime="2012-09-12T09:12:00Z" pubdate data-updated="true">Sep 12<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Timothy St. Clair</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/08/highly-available-configuration-data-with-wallaby.html">Highly-available configuration data with Wallaby</a></h1>
      <p class="meta">
        <time datetime="2012-08-29T21:03:00Z" pubdate data-updated="true">Aug 29<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">Many Condor users are interested in high-availability (HA) services: they don't want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon. (See this talk that Rob Rati and...</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2012/06/using-wallabys-skeleton-group.html">Using Wallaby's skeleton group</a></h1>
      <p class="meta">
        <time datetime="2012-06-15T21:04:21Z" pubdate data-updated="true">Jun 15<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Will Benton</time>
      </p>
    </header>
    <div class="entry-content">Wallaby 0.15.0 includes a new feature called the skeleton group. (This feature was available in earlier versions of Wallaby, too, but it was experimental and had some rough edges.) Find out how the skeleton group makes configuration more flexible by...</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://getwallaby.com/2012/06/using-the-skeleton-group/">Using the skeleton group</a></h1>
      <p class="meta">
        <time datetime="2012-06-15T17:46:00Z" pubdate data-updated="true">Jun 15<span>th</span>, 2012  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>In Wallaby, Condor nodes are configured by applying <em>features</em> and <em>parameter</em> settings to <em>groups</em>.  In order for the group abstraction to be fully general, <a href="http://getwallaby.com/2011/05/using-wallaby-groups-to-implement-node-tagging/">Wallaby provides two kinds of <em>special groups</em></a>:  the <em>default group</em>, which contains every node (but which is the lowest-priority membership for each node), and a set of <em>identity groups</em>, each of which only contains a single node (and which is always its highest-priority membership, so that special settings applied to a node&#8217;s identity group always take precedence over settings from that node&#8217;s other memberships). [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://getwallaby.com/2012/06/troubleshooting/">Troubleshooting Condor with Wallaby</a></h1>
      <p class="meta">
        <time datetime="2012-06-01T17:27:00Z" pubdate data-updated="true">Jun 1<span>st</span>, 2012  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Often, if you&#8217;re trying to reproduce a problem someone else is having with Condor, you&#8217;ll need their configuration.  Likewise, if you&#8217;re trying to help someone reproduce a problem you&#8217;re having, you&#8217;ll want to send along your configuration to aid them in replicating your setup.  For installations that use legacy flat-file configurations (optionally with a local configuration directory), this can be a pain, since you&#8217;ll need to copy several files from site to site (ensuring that you&#8217;ve included all the files necessary to replicate your configuration, perhaps across multiple machines on the site experiencing the problem). [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://getwallaby.com/2012/03/getwallaby-dot-com-is-now-powered-by-octopress/">Now powered by OctoPress</a></h1>
      <p class="meta">
        <time datetime="2012-03-16T17:27:00Z" pubdate data-updated="true">Mar 16<span>th</span>, 2012  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://osgtech.blogspot.com/2012/03/resource-isolation-in-condor-using.html">Resource Isolation in Condor using cgroups</a></h1>
      <p class="meta">
        <time datetime="2012-03-10T19:28:00Z" pubdate data-updated="true">Mar 10<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Brian Bockelman</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://osgtech.blogspot.com/2012/02/improving-file-isolation-with-chroot.html">Improving File Isolation with chroot</a></h1>
      <p class="meta">
        <time datetime="2012-02-27T19:33:00Z" pubdate data-updated="true">Feb 27<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Brian Bockelman</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://osgtech.blogspot.com/2012/02/file-isolation-using-bind-mounts-and.html">File Isolation using bind mounts and chroots</a></h1>
      <p class="meta">
        <time datetime="2012-02-20T16:03:00Z" pubdate data-updated="true">Feb 20<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Brian Bockelman</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://osgtech.blogspot.com/2012/02/job-isolation-in-condor.html">Job Isolation in Condor</a></h1>
      <p class="meta">
        <time datetime="2012-02-14T17:46:00Z" pubdate data-updated="true">Feb 14<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Brian Bockelman</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://osgtech.blogspot.com/2012/01/openstack-update.html">openstack - update</a></h1>
      <p class="meta">
        <time datetime="2012-01-27T18:29:00Z" pubdate data-updated="true">Jan 27<span>th</span>, 2012  &nbsp; &mdash; &nbsp; Brian Bockelman</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Planet HTCondor Members</h1>
    
      <a href="http://willbenton.com"> Will Benton</a><br>
    
      <a href="http://getwallaby.com/"> William Benton</a><br>
    
      <a href="http://osgtech.blogspot.com"> Brian Bockelman</a><br>
    
      <a href="http://erikerlandson.github.com/"> Erik Erlandson</a><br>
    
      <a href="http://spinningmatt.wordpress.com"> Matthew Farrellee</a><br>
    
      <a href="http://tmckayus.github.com/"> Trevor McKay</a><br>
    
      <a href="http://rrati.github.com/"> Robert Rati</a><br>
    
      <a href="http://timothysc.github.com/"> Timothy St. Clair</a><br>
    
      <a href="http://htcondor.github.com/"> HTCondor Team GitHub</a><br>
    
      <a href="http://derekweitzel.blogspot.com"> Derek Weitzel</a><br>
    
  </section>
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - HTCondor Project -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
