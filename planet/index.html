
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Planet HTCondor - HTCondor Project</title>
  <meta name="author" content="HTCondor Project">

  
  <meta name="description" content="The HTCondor team is pleased to announce the release of HTCondor 8.5.2.
This development series release contains new features that are under &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://htcondor.github.com/planet/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/planet/atom.xml" rel="alternate" title="HTCondor Project" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">HTCondor Project</a></h1>
  
    <h2>The website and blog for the HTCondor project on github.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/planet/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:htcondor.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/planet">Planet HTCondor</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      

<br>
<h1 align="center"><u> Planet HTCondor </u></h1>

<div class=\"blog-index\">

  <article>
    <header>
      <h1 class="entry-title"><a href="manual/v8.5.2/10_2Development_Release.html"> HTCondor 8.5.2 released! ( February 18, 2016 )</a></h1>
      <p class="meta">
        <time datetime="2016-02-18T06:00:00Z" pubdate data-updated="true">Feb 18<span>th</span>, 2016  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is pleased to announce the release of HTCondor 8.5.2.
This development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.4.4
stable release.

Enhancements in the release include:
condor_q now defaults to showing only the current user's jobs;
condor_q -batch produces a single line report for a batch of jobs;
Docker Universe jobs now report and update memory and network usage;
immutable and protected job attributes;
improved performance when querying a HTCondor daemon's location;
Added the ability to set ClassAd attributes within the DAG file;
DAGMan now provides event timestamps in dagman.out.

Further details can be found in the
Version History.
HTCondor 8.5.2 binaries and source code are available from our
Downloads page.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="https://chapeau.freevariable.com/2016/02/dimensionality-reduction-in-spark.html">Dimensionality reduction in Spark</a></h1>
      <p class="meta">
        <time datetime="2016-02-17T01:23:17Z" pubdate data-updated="true">Feb 17<span>th</span>, 2016  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Here&rsquo;s a quick video I put together introducing infrastructure log processing in Spark.  At the end, there are a couple of nice graphs contrasting PCA and t-SNE for embedding high-dimensional log metadata into two dimensions.</p>

<div class="embed-responsive embed-responsive-16by9"><iframe class="embed-responsive-item" src='https://player.vimeo.com/video/155555333' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


<p><a href="https://vimeo.com/155555333">Log processing demo</a> from <a href="https://vimeo.com/willbenton">William Benton</a> on <a href="https://vimeo.com">Vimeo</a>.</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2016/02/08/efficient-multiplexing-for-spark-rdds/">Efficient Multiplexing for Spark RDDs</a></h1>
      <p class="meta">
        <time datetime="2016-02-08T17:09:00Z" pubdate data-updated="true">Feb 8<span>th</span>, 2016  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In this post I'm going to propose a new abstract operation on <a href="http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds">Spark RDDs</a> -- <strong>multiplexing</strong> -- that makes some categories of operations on RDDs both easier to program and in many cases much faster.</p>

<p>My main working example will be the operation of splitting a collection of data elements into N randomly-selected subsamples.  This operation is quite common in machine learning, for the purpose of dividing data into a <a href="https://en.wikipedia.org/wiki/Test_set">training and testing set</a>, or the related task of <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics">creating folds for cross-validation</a>).</p>

<p>Consider the current standard RDD method for accomplishing this task, <code>randomSplit()</code>.  This method takes a collection of N weights, and returns N output RDDs, each of which contains a randomly-sampled subset of the input, proportional to the corresponding weight.  The <code>randomSplit()</code> method generates the jth output by running a random number generator (RNG) for each input data element and accepting all elements which are in the corresponding jth (normalized) weight range.  As a diagram, the process looks like this at each RDD partition:</p>

<p><img src="/assets/images/mux/randomsplit.png" title="Figure 1" alt="Figure 1" /></p>

<p>The observation I want to draw attention to is that to produce the N output RDDs, it has to run a random sampling over every element in the input <em>for each output</em>.  So if you are splitting into 10 outputs (e.g. for a 10-fold cross-validation), you are re-sampling your input 10 times, the only difference being that each output is created using a different acceptance range for the RNG output.</p>

<p>To see what this looks like in code, consider a simplified version of random splitting that just takes an integer <code>n</code> and always produces (n) equally-weighted outputs:</p>

<p>```scala
def splitSample<a href="rdd:%20RDD[T],%20n:%20Int,%20seed:%20Long%20=%2042">T :ClassTag</a>: Seq[RDD[T]] = {
  Vector.tabulate(n) { j =></p>

<pre><code>rdd.mapPartitions { data =&gt;
  scala.util.Random.setSeed(seed)
  data.filter { unused =&gt; scala.util.Random.nextInt(n) == j }
}
</code></pre>

<p>  }
}
```</p>

<p>(Note that for this method to operate correctly, the RNG seed must be set to the same value each time, or the data will not be correctly partitioned)</p>

<p>While this approach to random splitting works fine, resampling the same data N times is somewhat wasteful.  However, it is possible to re-organize the computation so that the input data is sampled only once.  The idea is to run the RNG once per data element, and save the element into a randomly-chosen collection.  To make this work in the RDD compute model, all N output collections reside in a single row of an <em>intermediate</em> RDD -- a "manifold" RDD.  Each output RDD then takes its data from the corresponding collection in the manifold RDD, as in this diagram:</p>

<p><img src="/assets/images/mux/multiplex.png" alt="Figure 2" /></p>

<p>If you abstract the diagram above into a generalized operation, you end up with methods that might like the following:</p>

<p>```scala
def muxPartitions<a href="n:%20Int,%20f:%20(Int,%20Iterator[T]">U :ClassTag</a> => Seq[U],
  persist: StorageLevel): Seq[RDD[U]] = {
  val mux = self.mapPartitionsWithIndex { case (id, itr) =></p>

<pre><code>Iterator.single(f(id, itr))
</code></pre>

<p>  }.persist(persist)
  Vector.tabulate(n) { j => mux.mapPartitions { itr => Iterator.single(itr.next()(j)) } }
}</p>

<p>def flatMuxPartitions<a href="n:%20Int,%20f:%20(Int,%20Iterator[T]">U :ClassTag</a> => Seq[TraversableOnce[U]],
  persist: StorageLevel): Seq[RDD[U]] = {
  val mux = self.mapPartitionsWithIndex { case (id, itr) =></p>

<pre><code>Iterator.single(f(id, itr))
</code></pre>

<p>  }.persist(persist)
  Vector.tabulate(n) { j => mux.mapPartitions { itr => itr.next()(j).toIterator } }
}
```</p>

<p>Here, the operation of sampling is generalized to any user-supplied function that maps RDD partition data into a sequence of objects that are computed in a single pass, and then multiplexed to the final user-visible outputs.  Note that these functions take a <code>StorageLevel</code> argument that can be used to control the caching level of the internal "manifold" RDD.  This typically defaults to <code>MEMORY_ONLY</code>, so that the computation can be saved and re-used for efficiency.</p>

<p>An efficient split-sampling method based on multiplexing, as described above, might be written using <code>flatMuxPartitions</code> as follows:</p>

<p>```scala
def splitSampleMux<a href="rdd:%20RDD[T],%20n:%20Int,%0A%20%20persist:%20StorageLevel%20=%20MEMORY_ONLY,%0A%20%20seed:%20Long%20=%2042">T :ClassTag</a>: Seq[RDD[T]] =
  rdd.flatMuxPartitions(n, (id: Int, data: Iterator[T]) => {</p>

<pre><code>scala.util.Random.setSeed(id.toLong * seed)
val samples = Vector.fill(n) { scala.collection.mutable.ArrayBuffer.empty[T] }
data.foreach { e =&gt; samples(scala.util.Random.nextInt(n)) += e }
samples
</code></pre>

<p>  }, persist)
```</p>

<p>To test whether multiplexed RDDs actually improve compute efficiency, I collected run-time data at various split values of <code>n</code> (from 1 to 10), for both the non-multiplexing logic (equivalent to the standard <code>randomSplit</code>) and the multiplexed version:</p>

<p><img src="/assets/images/mux/benchmark.png" title="Figure 3" alt="Figure 3" /></p>

<p>As the timing data above show, the computation required to run a non-multiplexed version grows linearly with <code>n</code>, just as predicted.  The multiplexed version, by computing the (n) outputs in a single pass, takes a nearly constant amount of time regardless of how many samples the input is split into.</p>

<p>There are other potential applications for multiplexed RDDs.  Consider the following tuple-based versions of multiplexing:</p>

<p>```scala
def muxPartitions<a href="f:%20(Int,%20Iterator[T]">U1 :ClassTag, U2 :ClassTag</a> => (U1, U2),
  persist: StorageLevel): (RDD[U1], RDD[U2]) = {
  val mux = self.mapPartitionsWithIndex { case (id, itr) =></p>

<pre><code>Iterator.single(f(id, itr))
</code></pre>

<p>  }.persist(persist)
  val mux1 = mux.mapPartitions(itr => Iterator.single(itr.next.<em>1))
  val mux2 = mux.mapPartitions(itr => Iterator.single(itr.next.</em>2))
  (mux1, mux2)
}</p>

<p>def flatMuxPartitions<a href="f:%20(Int,%20Iterator[T]">U1 :ClassTag, U2 :ClassTag</a> => (TraversableOnce[U1], TraversableOnce[U2]),
  persist: StorageLevel): (RDD[U1], RDD[U2]) = {
  val mux = self.mapPartitionsWithIndex { case (id, itr) =></p>

<pre><code>Iterator.single(f(id, itr))
</code></pre>

<p>  }.persist(persist)
  val mux1 = mux.mapPartitions(itr => itr.next.<em>1.toIterator)
  val mux2 = mux.mapPartitions(itr => itr.next.</em>2.toIterator)
  (mux1, mux2)
}
```</p>

<p>Suppose you wanted to run an input-validation filter on some data, sending the data that pass validation into one RDD, and data that failed into a second RDD, paired with information about the error that occurred.  Data validation is a potentially expensive operation.  With multiplexing, you can easily write the filter to operate in a single efficient pass to obtain both the valid stream and the stream of error-data:</p>

<p>```scala
def validate<a href="rdd:%20RDD[T],%20validator:%20T%20=>%20Boolean">T :ClassTag</a> = {
  rdd.flatMuxPartitions((id: Int, data: Iterator[T]) => {</p>

<pre><code>val valid = scala.collection.mutable.ArrayBuffer.empty[T]
val bad = scala.collection.mutable.ArrayBuffer.empty[(T, Exception)]
data.foreach { e =&gt;
  try {
    if (!validator(e)) throw new Exception("returned false")
    valid += e
  } catch {
    case err: Exception =&gt; bad += (e, err)
  }
}
(valid, bad)
</code></pre>

<p>  })
}
```</p>

<p>RDD multiplexing is currently a <a href="https://github.com/willb/silex/pull/50">PR against the silex project</a>.  The code I used to run the timing experiments above is <a href="https://github.com/erikerlandson/silex/blob/blog/muxrdd/src/main/scala/com/redhat/et/silex/sample/split.scala#L90">saved for posterity here</a>.</p>

<p>Happy multiplexing!</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="manual/v8.4.4/10_3Stable_Release.html"> HTCondor 8.4.4 released! ( February 2, 2016 )</a></h1>
      <p class="meta">
        <time datetime="2016-02-02T06:00:00Z" pubdate data-updated="true">Feb 2<span>nd</span>, 2016  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is pleased to announce the release of HTCondor 8.4.4.
A stable series release contains significant bug fixes.

Highlights of this release are:
fixed a bug that could cause the collector to crash when DNS lookup fails;
fixed a bug that caused Condor-C jobs with short lease durations to fail;
fixed bugs that affected EC2 grid universe jobs;
fixed a bug that prevented startup if a prior version shared port file exists;
fixed a bug that could cause the condor_shadow to hang on Windows;
a few other bug fixes, consult the version history.

Further details can be found in the
Version History.
HTCondor 8.4.4 binaries and source code are available from our
Downloads page.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="https://indico.cern.ch/e/Spring2016HTCondorWorkshop"> Registration open for Barcelona Workshop for HTCondor / ARC CE ( January 28, 2016 )</a></h1>
      <p class="meta">
        <time datetime="2016-01-28T06:00:00Z" pubdate data-updated="true">Jan 28<span>th</span>, 2016  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">*REGISTRATION IS NOW OPEN* (until 22nd Feb.)!! The workshop fee is 80 
EUROS (VAT included), which covers the lunches and all coffee breaks 
along the event. The list of recommended hotels, instructions for fee 
payment, and how to get to the venue is available in the workshop homepage.

Where: Barcelona, Spain, at the ALBA Synchrotron Facility
When: Monday February 29 2016 thru Friday March 4 2016.
Workshop homepage: https://indico.cern.ch/e/Spring2016HTCondorWorkshop

</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://research.cs.wisc.edu/htcondor"> Re-release of RPMs for HTCondor 8.4.3 and 8.5.1 ( January 8, 2016 )</a></h1>
      <p class="meta">
        <time datetime="2016-01-08T06:00:00Z" pubdate data-updated="true">Jan 8<span>th</span>, 2016  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is re-releasing the RPMs for 8.4.3 and 8.5.1.
A recent change to correct problems with Standard Universe in the
RPM packaging resulted in unoptimized binaries to be packaged.
The new RPMs have optimized binaries.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="https://chapeau.freevariable.com/2015/12/using-word2vec-on-log-messages.html">Using word2vec on logs</a></h1>
      <p class="meta">
        <time datetime="2015-12-11T17:51:36Z" pubdate data-updated="true">Dec 11<span>th</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Lately, I&rsquo;ve been experimenting with <a href="http://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec">Spark&rsquo;s implementation</a> of word2vec.  Since most of the natural-language data I have sitting around these days are service and system logs from machines at work, I thought it would be fun to see how well word2vec worked if we trained it on the text of log messages.  This is obviously pretty far from an ideal training corpus, but these brief, rich messages seem like they should have some minable content.  In the rest of this post, I&rsquo;ll show some interesting results from the model and also describe some concrete preprocessing steps to get more useful results for extracting words from the odd dialect of natural language that appears in log messages. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/11/24/the-prepare-operation-considered-harmful-in-algebird/">The 'prepare' operation considered harmful in Algebird aggregation</a></h1>
      <p class="meta">
        <time datetime="2015-11-24T23:32:00Z" pubdate data-updated="true">Nov 24<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>I want to make an argument that the Algebird <a href="http://twitter.github.io/algebird/#com.twitter.algebird.Aggregator">Aggregator</a> design, in particular its use of the <code>prepare</code> operation in a map-reduce context, has substantial inefficiencies, compared to an equivalent formulation that is more directly suited to taking advantage of Scala's <a href="http://www.scala-lang.org/api/current/index.html#scala.collection.Seq">aggregate method on collections</a> method. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/11/20/very-fast-reservoir-sampling/">Very Fast Reservoir Sampling</a></h1>
      <p class="meta">
        <time datetime="2015-11-20T18:27:00Z" pubdate data-updated="true">Nov 20<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In this post I will demonstrate how to do reservoir sampling orders of magnitude faster than the traditional "naive" reservoir sampling algorithm, using a fast high-fidelity approximation to the reservoir sampling-gap distribution. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="https://chapeau.freevariable.com/2015/11/concrete-advice-about-abstracts.html">Concrete advice about abstracts</a></h1>
      <p class="meta">
        <time datetime="2015-11-16T15:43:49Z" pubdate data-updated="true">Nov 16<span>th</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Consider the following hypothetical conference session abstract: [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="https://chapeau.freevariable.com/2015/10/pacing-technical-talks.html">Pacing technical talks</a></h1>
      <p class="meta">
        <time datetime="2015-10-21T16:17:01Z" pubdate data-updated="true">Oct 21<span>st</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Delivering a technical talk has a lot in common with running a half-marathon or biking a 40k time trial.  You&rsquo;re excited and maybe a little nervous, you&rsquo;re prepared to go relatively hard for a relatively long time, and you&rsquo;re acutely aware of the clock.  In both situations, you might be tempted to take off right from the gun, diving into your hardest effort (or most technical material), but this is a bad strategy. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="https://chapeau.freevariable.com/2015/10/notes-from-flink-forward.html">Notes from Flink Forward</a></h1>
      <p class="meta">
        <time datetime="2015-10-20T15:48:44Z" pubdate data-updated="true">Oct 20<span>th</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/willb/22238437291/in/dateposted-public/" title="Brandenburger Tor lightshow"><img src="https://farm1.staticflickr.com/739/22238437291_22636e4a72_b.jpg" width="1024" height="819" alt="Brandenburger Tor lightshow"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script> [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/">A Library of Binary Tree Algorithms as Mixable Scala Traits</a></h1>
      <p class="meta">
        <time datetime="2015-09-26T19:43:00Z" pubdate data-updated="true">Sep 26<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In this post I am going to describe some work I've done recently on a system of Scala traits that support tree-based collection algorithms prefix-sum, nearest key query and value increment in a mixable format, all backed by Red-Black balanced tree logic, which is also a fully inheritable trait. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/">Lightweight Non-Negative Numerics for Better Scala Type Signatures</a></h1>
      <p class="meta">
        <time datetime="2015-08-19T00:42:00Z" pubdate data-updated="true">Aug 19<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In this post I want to discuss several advantages of defining lightweight non-negative numeric types in Scala, whose primary benefit is that they allow improved type signatures for Scala functions and methods.  I'll first describe the simple class definition, and then demonstrate how it can be used in function signatures and the benefits of doing so. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2015/08/gpus-and-adding-new-resources-types-to.html">GPUs and adding new resources types to the HTCondor-CE</a></h1>
      <p class="meta">
        <time datetime="2015-08-07T21:45:00Z" pubdate data-updated="true">Aug 7<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://derekweitzel.blogspot.com/2015/07/the-more-things-change-more-they-stay.html">The more things change, the more they stay the same</a></h1>
      <p class="meta">
        <time datetime="2015-07-28T15:00:00Z" pubdate data-updated="true">Jul 28<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Derek Weitzel</time>
      </p>
    </header>
    <div class="entry-content"></div>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Planet HTCondor Members</h1>
    
      <a href="https://chapeau.freevariable.com/"> William Benton</a><br>
    
      <a href="http://erikerlandson.github.com/"> Erik Erlandson</a><br>
    
      <a href="http://research.cs.wisc.edu/htcondor"> HTCondor Team</a><br>
    
      <a href="http://derekweitzel.blogspot.com"> Derek Weitzel</a><br>
    
  </section>
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - HTCondor Project -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
