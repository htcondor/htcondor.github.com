
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Planet HTCondor - HTCondor Project</title>
  <meta name="author" content="HTCondor Project">

  
  <meta name="description" content="There will be a workshop for HTCondor and ARC CE users in Barcelona, Spain on Feb 29 2016 &mdash; March 4 2016 Where: Barcelona, Spain, at the ALBA &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://htcondor.github.com/planet/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/planet/atom.xml" rel="alternate" title="HTCondor Project" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">HTCondor Project</a></h1>
  
    <h2>The website and blog for the HTCondor project on github.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/planet/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:htcondor.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/planet">Planet HTCondor</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      

<br>
<h1 align="center"><u> Planet HTCondor </u></h1>

<div class=\"blog-index\">

  <article>
    <header>
      <h1 class="entry-title"><a href="https://indico.cern.ch/e/Spring2016HTCondorWorkshop"> HTCondor / ARC CE Workshop: 29 February 2016 to 4 March 2016 ( January 4, 2016 )</a></h1>
      <p class="meta">
        <time datetime="2016-01-04T06:00:00Z" pubdate data-updated="true">Jan 4<span>th</span>, 2016  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">There will be a workshop for HTCondor and ARC CE users in Barcelona, Spain on Feb 29 2016 &mdash; March 4 2016


Where: Barcelona, Spain, at the ALBA Synchrotron Facility
When: Monday February 29 2016 thru Friday March 4 2016.
 Workshop homepage: https://indico.cern.ch/e/Spring2016HTCondorWorkshop


Save the dates! The HTCondor team, the NorduGrid collaboration, and the 
Port d'InformaciÃ³. Cientifica
(PIC) + ALBA Synchrotron present a workshop for the users and administrators of HTCondor, the HTCondor CE and the ARC CE to learn and connect in Barcelona, Spain. This is an opportunity for novice and experienced system administrators and users to learn, get help and have exchanges between themselves and with the developers and experts.

The workshop will offer:


 Introductory tutorials on using and administrating HTCondor, HTCondor CE and ARC CE
 Technical talks on usage and deployment from developers and your fellow users
 Talks and tutorials on recent features, configuration, and roadmap
 The opportunity to meet with HTCondor developers, ARC CE developers, and other experts for non-structured Ã¢office hoursÃ¢ consultancy


Speaking of learning from the community, we would like to hear from people interested in presenting at this workshop. If you have a use case or best practices involving HTCondor, HTCondor CE or ARC CE you'd like to share, please send us an email at hepix-condorworkshop2016-interest (at) cern (dot) ch .

Information on registration will be available soon at:
https://indico.cern.ch/e/Spring2016HTCondorWorkshop

Timetable overview: Monday, Tuesday, and Wednesday presentations will be dedicated to HTCondor and HTCondor CE, while Thursday's presentations dedicated to ARC CE. HTCondor and ARC CE developers and experts will be available on Thursday and Friday morning for non-structured "office hours" consultancy and individual discussions with users.

We hope to see you in Barcelona!

</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="manual/v8.5.1/10_2Development_Release.html"> HTCondor 8.5.1 released! ( December 21, 2015 )</a></h1>
      <p class="meta">
        <time datetime="2015-12-21T06:00:00Z" pubdate data-updated="true">Dec 21<span>st</span>, 2015  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is pleased to announce the release of HTCondor 8.5.1.
This development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.4.3
stable release.

Enhancements in the release include:
the shared port daemon is enabled by default;
the condor_startd now records the peak memory usage instead of recent;
the condor_startd advertizes CPU submodel and cache size;
authorizations are automatically setup when "Match Password" is enabled;
added a schedd-constraint option to condor_q.

With the shared port daemon enabled, all HTCondor daemons share a single
inbound network port. This change makes it much easier to construct a
firewall configuration that allows HTCondor use.

Further details can be found in the
Version History.
HTCondor 8.5.1 binaries and source code are available from our
Downloads page.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="manual/v8.4.3/10_3Stable_Release.html"> HTCondor 8.4.3 released! ( December 16, 2015 )</a></h1>
      <p class="meta">
        <time datetime="2015-12-16T06:00:00Z" pubdate data-updated="true">Dec 16<span>th</span>, 2015  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is pleased to announce the release of HTCondor 8.4.3.
A stable series release contains significant bug fixes.

Highlights of this release are:
fixed the processing of the -append option in the condor_submit command;
fixed a bug to run more that 100 dynamic slots on a single execute node;
fixed bugs that would delay daemon startup when using shared port on Windows;
fixed a bug where the cgroup VM limit would not be set for sizes over 2 GiB;
fixed a bug to use the ec2_iam_profile_name for Amazon EC2 Spot instances;
a few other bug fixes, consult the version history.

Further details can be found in the
Version History.
HTCondor 8.4.3 binaries and source code are available from our
Downloads page.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2015/12/using-word2vec-on-log-messages.html">Using word2vec on logs</a></h1>
      <p class="meta">
        <time datetime="2015-12-11T17:51:36Z" pubdate data-updated="true">Dec 11<span>th</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Lately, I&rsquo;ve been experimenting with <a href="http://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec">Spark&rsquo;s implementation</a> of word2vec.  Since most of the natural-language data I have sitting around these days are service and system logs from machines at work, I thought it would be fun to see how well word2vec worked if we trained it on the text of log messages.  This is obviously pretty far from an ideal training corpus, but these brief, rich messages seem like they should have some minable content.  In the rest of this post, I&rsquo;ll show some interesting results from the model and also describe some concrete preprocessing steps to get more useful results for extracting words from the odd dialect of natural language that appears in log messages.</p>

<h3>Background</h3>

<p><a href="http://arxiv.org/abs/1310.4546">word2vec</a> is a family of techniques for encoding words as relatively low-dimensional vectors that capture interesting semantic information.  That is, words that are synonyms are likely to have vectors that are similar (by cosine similarity).  Another really neat aspect of this encoding is that linear transformations of these vectors can expose semantic information like analogies:  for example, given a model trained on news articles, adding the vectors for &ldquo;Madrid&rdquo; and &ldquo;France&rdquo; and subtracting the vector for &ldquo;Spain&rdquo; results in a vector very close to that for &ldquo;Paris.&rdquo;</p>

<p>Spark&rsquo;s implementation of word2vec uses <a href="https://en.wikipedia.org/wiki/N-gram#Bias-versus-variance_trade-off">skip-grams</a>, so the training objective is to produce a model that, given a word, predicts the context in which it is likely to appear.</p>

<h3>Preliminaries</h3>

<p>Like the <a href="">original implementation of word2vec</a>, Spark&rsquo;s implementation uses a window of &#177;5 surrounding words (this is not user-configurable) and defaults to discarding all words that appear fewer than 5 times (this threshold is user-configurable).  Both of these assumptions seem sane for the sort of training &ldquo;sentences&rdquo; that appear in log messages, but they won&rsquo;t be sufficient.</p>

<p>Spark doesn&rsquo;t provide a lot of tools for tokenizing and preprocessing natural-language text.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>  Simple string splitting is as ubiquitous in trivial language processing examples just as it is in trivial word count examples, but it&rsquo;s not going to give us the best results. Fortunately, there are some minimal steps we can take to start getting useful tokens out of log messages.  We&rsquo;ll look at these steps and what see what motivates them now.</p>

<h4>What is a word?</h4>

<p>Let&rsquo;s first consider what kinds of tokens might be interesting for analyzing the content of log messages.  At the very least, we might care about:</p>

<ol>
<li>dictionary words,</li>
<li>trademarks (which may or may not be dictionary words),</li>
<li>technical jargon terms (which may or may not be dictionary words),</li>
<li>service names (which may or may not be dictionary words),</li>
<li>symbolic constant names (e.g., <code>ENOENT</code> and <code>OPEN_MAX</code>),</li>
<li>pathnames (e.g., <code>/dev/null</code>), and</li>
<li>programming-language identifiers (e.g., <code>OutOfMemoryError</code> and <code>Kernel::exec</code>).</li>
</ol>


<p>For this application, we&rsquo;re less interested in the following kinds of tokens, although it is possible to imagine other applications in which they might be important:</p>

<ol>
<li>hostnames,</li>
<li>IPv4 and IPv6 addresses,</li>
<li>MAC addresses,</li>
<li>dates and times, and</li>
<li>hex hash digests.</li>
</ol>


<h4>Preprocessing steps</h4>

<p>If we&rsquo;re going to convert sequences of lines to sequences of sequences of tokens, we&rsquo;ll eventually be splitting strings.  Before we split, we&rsquo;ll collapse all runs of whitespace into single spaces so that we get more useful results when we do split.  This isn&rsquo;t strictly necessary &mdash; we could elect to split on runs of whitespace instead of single whitespace characters, or we could filter out empty strings from word sequences before training on them.  But this makes for cleaner input and it makes the subsequent transformations a little simpler.</p>

<p>Here&rsquo;s Scala code to collapse runs of whitespace into a single space:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">def</span> <span class="n">replace</span><span class="o">(</span><span class="n">r</span><span class="k">:</span> <span class="kt">scala.util.matching.Regex</span><span class="o">,</span> <span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span> <span class="o">(</span><span class="n">orig</span><span class="k">:</span><span class="kt">String</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">r</span><span class="o">.</span><span class="n">replaceAllIn</span><span class="o">(</span><span class="n">orig</span><span class="o">,</span> <span class="n">s</span><span class="o">)</span> <span class="o">}</span>
</span><span class='line'><span class="k">val</span> <span class="n">collapseSpaces</span> <span class="k">=</span> <span class="n">replace</span><span class="o">(</span><span class="k">new</span> <span class="n">scala</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">matching</span><span class="o">.</span><span class="nc">Regex</span><span class="o">(</span><span class="s">&quot;[\\s]+&quot;</span><span class="o">),</span> <span class="s">&quot; &quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The next thing we&rsquo;ll want to do is eliminate all punctuation from the ends of each word.  An appropriate definition of &ldquo;punctuation&rdquo; will depend on the sorts of tokens we wind up deciding are interesting, but I considered punctuation characters to be anything except:</p>

<ol>
<li>alphanumeric characters,</li>
<li>dashes, and</li>
<li>underscores.</li>
</ol>


<p>Whether or not we want to retain intratoken punctuation depends on the application; there are good arguments to be made for retaining colons and periods (MAC addresses, programming-language identifiers in stack traces, hostnames, etc.), slashes (paths), at-signs (email addresses), and other marks as well.  I&rsquo;ll be retaining these marks but stripping all others.  After these transformations, we can split on whitespace and get a relatively sensible set of tokens.</p>

<p>Here&rsquo;s Scala code to strip punctuation from lines:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">rejectedIntratokenPunctuation</span> <span class="k">=</span> <span class="k">new</span> <span class="n">scala</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">matching</span><span class="o">.</span><span class="nc">Regex</span><span class="o">(</span><span class="s">&quot;[^A-Za-z0-9-_./:@]&quot;</span><span class="o">)</span>
</span><span class='line'><span class="k">val</span> <span class="n">leadingPunctuation</span> <span class="k">=</span> <span class="k">new</span> <span class="n">scala</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">matching</span><span class="o">.</span><span class="nc">Regex</span><span class="o">(</span><span class="s">&quot;(\\s)[^\\sA-Za-z0-9-_/]+|()^[^\\sA-Za-z0-9-_/]+&quot;</span><span class="o">)</span>
</span><span class='line'><span class="k">val</span> <span class="n">trailingPunctuation</span> <span class="k">=</span> <span class="k">new</span> <span class="n">scala</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">matching</span><span class="o">.</span><span class="nc">Regex</span><span class="o">(</span><span class="s">&quot;[^\\sA-Za-z0-9-_/]+(\\s)|()[^\\sA-Za-z0-9-_/]+$&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">stripPunctuation</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=&gt;</span> <span class="nc">String</span> <span class="k">=</span>
</span><span class='line'>  <span class="n">replace</span><span class="o">(</span><span class="n">leadingPunctuation</span><span class="o">,</span> <span class="s">&quot;$1&quot;</span><span class="o">)</span> <span class="n">compose</span>
</span><span class='line'>  <span class="n">replace</span><span class="o">(</span><span class="n">trailingPunctuation</span><span class="o">,</span> <span class="s">&quot;$1&quot;</span><span class="o">)</span> <span class="n">compose</span>
</span><span class='line'>  <span class="n">replace</span><span class="o">(</span><span class="n">rejectedIntratokenPunctuation</span><span class="o">,</span> <span class="s">&quot;&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>In order to filter out strings of numbers, we&rsquo;ll reject all tokens that don&rsquo;t contain at least one letter.  (We could be stricter and reject all tokens that don&rsquo;t contain at least one letter that isn&rsquo;t a hex digit, but I decided to be permissive in order to avoid rejecting interesting words that only contain letters <code>A-F</code>.)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">oneletter</span> <span class="k">=</span> <span class="k">new</span> <span class="n">scala</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">matching</span><span class="o">.</span><span class="nc">Regex</span><span class="o">(</span><span class="s">&quot;.*([A-Za-z]).*&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here&rsquo;s what our preprocessing pipeline looks like, assuming an RDD of log messages called <code>messages</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">def</span> <span class="n">tokens</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">post</span><span class="k">:</span> <span class="kt">String</span><span class="o">=&gt;</span><span class="nc">String</span> <span class="k">=</span> <span class="n">identity</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>  <span class="n">collapseWhitespace</span><span class="o">(</span><span class="n">s</span><span class="o">)</span>
</span><span class='line'>    <span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="n">post</span><span class="o">(</span><span class="n">stripPunctuation</span><span class="o">(</span><span class="n">s</span><span class="o">)))</span>
</span><span class='line'>    <span class="o">.</span><span class="n">collect</span> <span class="o">{</span> <span class="k">case</span> <span class="n">token</span> <span class="k">@</span> <span class="n">oneletter</span><span class="o">(</span><span class="k">_</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">token</span> <span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">tokenSeqs</span> <span class="k">=</span> <span class="n">messages</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">tokens</span><span class="o">(</span><span class="n">line</span><span class="o">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now we have a sequence of words for each log message and are ready to train a word2vec model.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.mllib.feature.Word2Vec</span>
</span><span class='line'><span class="k">val</span> <span class="n">w2v</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Word2Vec</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">w2v</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">tokenSeqs</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that there are a few things we could be doing in our preprocessing pipeline but aren&rsquo;t, like using a whitelist (for dictionary words or service names), or rejecting stopwords.  This approach is pretty basic, but it produces some interesting results in any case.</p>

<h3>Results and conclusions</h3>

<p>I evaluated the model by using it to find synonyms for (more or less) arbitrary words that appeared in log messages.  Recall that word2vec basically models words by the contexts in which they might appear; informally, synonyms are thus words with similar contexts.</p>

<ul>
<li>The top synonyms for <code>nova</code> (the OpenStack compute service) included <code>vm</code>, <a href="http://docs.openstack.org/developer/glance/"><code>glance</code></a>, <code>containers</code>, <code>instances</code>, and <code>images</code> &mdash; all of these are related to running OpenStack compute jobs.</li>
<li>The top synonyms for <code>volume</code> included <code>update</code>, <a href="https://wiki.openstack.org/wiki/Cinder"><code>cinder.scheduler.host_manager</code></a>, and several UUIDs for actual volumes.</li>
<li>The top synonyms for <code>tmpfs</code> included <code>type</code>, <code>dev</code>, <code>uses</code>, <code>initialized</code>, and <code>transition</code>.</li>
<li>The top synonyms for <code>sh</code> included <code>/usr/bin/bash</code>, <code>_AUDIT_SESSION</code>, <code>NetworkManager</code>, <code>_SYSTEMD_SESSION</code>, <code>postfixqmgr</code>.</li>
<li>The top synonyms for <code>password</code> included <code>publickey</code>, <code>Accepted</code>, <code>opened</code>, <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface"><code>IPMI</code></a>, and the name of an internal project.</li>
</ul>


<p>These results aren&rsquo;t earth-shattering &mdash; indeed, they won&rsquo;t even tell you <a href="https://scholar.google.com/scholar?q=yelp+sentiment+analysis&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart&amp;sa=X&amp;ved=0ahUKEwj74vLpl9TJAhXLXh4KHccICIgQgQMIGzAA">where to get a decent burrito</a> &mdash;  but they&rsquo;re interesting, they&rsquo;re sensible, and they point to the effectiveness of word2vec even given a limited, unidiomatic corpus full of odd word-like tokens.  Of course, one can imagine ways to make our preprocessing more robust.  Similarly, there are certainly other ways to generate a training corpus for these words: perhaps using the set of all messages for a particular service and severity as a training sentence,  using the documentation for the services involved, using format strings present in the source or binaries for the services themselves, or some combination of these.</p>

<p>Semantic modeling of terms in log messages is obviously useful for log analytics:  it can be used as part of a pipeline to classify related log messages by topic, in feature engineering for anomaly detection, and to suggest alternate search terms for interactive queries.  However, it is a pleasant surprise that we can train a competent word2vec model for understanding log messages from the uncharacteristic utterances that comprise log messages themselves.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Spark does provide a <a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.StopWordsRemover">stopword filter for English</a> and there are external libraries to fill in some of its language-processing gaps.  In particular, I&rsquo;ve had good luck with the <a href="http://tartarus.org/~martin/PorterStemmer/">Porter stemmer</a> implementation from <a href="https://github.com/scalanlp/chalk/">Chalk</a>.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/11/24/the-prepare-operation-considered-harmful-in-algebird/">The 'prepare' operation considered harmful in Algebird aggregation</a></h1>
      <p class="meta">
        <time datetime="2015-11-24T23:32:00Z" pubdate data-updated="true">Nov 24<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>I want to make an argument that the Algebird <a href="http://twitter.github.io/algebird/#com.twitter.algebird.Aggregator">Aggregator</a> design, in particular its use of the <code>prepare</code> operation in a map-reduce context, has substantial inefficiencies, compared to an equivalent formulation that is more directly suited to taking advantage of Scala's <a href="http://www.scala-lang.org/api/current/index.html#scala.collection.Seq">aggregate method on collections</a> method. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/11/20/very-fast-reservoir-sampling/">Very Fast Reservoir Sampling</a></h1>
      <p class="meta">
        <time datetime="2015-11-20T18:27:00Z" pubdate data-updated="true">Nov 20<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In this post I will demonstrate how to do reservoir sampling orders of magnitude faster than the traditional "naive" reservoir sampling algorithm, using a fast high-fidelity approximation to the reservoir sampling-gap distribution. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="manual/v8.4.2/10_3Stable_Release.html"> HTCondor 8.4.2 released! ( November 17, 2015 )</a></h1>
      <p class="meta">
        <time datetime="2015-11-17T06:00:00Z" pubdate data-updated="true">Nov 17<span>th</span>, 2015  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is pleased to announce the release of HTCondor 8.4.2.
A stable series release contains significant bug fixes.

Highlights of this release are:
a bug fix to prevent the condor_schedd from crashing;
a bug fix to honor TCP_FORWARDING_HOST;
Standard Universe works properly in RPM installations of HTCondor;
the RPM packages no longer claim to provide Globus libraries;
bug fixes to DAGMan's "maximum idle jobs" throttle;
several other bug fixes, consult the version history.


Further details can be found in the
Version History.
HTCondor 8.4.2 binaries and source code are available from our
Downloads page.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2015/11/concrete-advice-about-abstracts.html">Concrete advice about abstracts</a></h1>
      <p class="meta">
        <time datetime="2015-11-16T15:43:49Z" pubdate data-updated="true">Nov 16<span>th</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Consider the following hypothetical conference session abstract: [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="manual/v8.4.1/10_3Stable_Release.html"> HTCondor 8.4.1 released! ( October 27, 2015 )</a></h1>
      <p class="meta">
        <time datetime="2015-10-27T05:00:00Z" pubdate data-updated="true">Oct 27<span>th</span>, 2015  &nbsp; &mdash; &nbsp; HTCondor Team</time>
      </p>
    </header>
    <div class="entry-content">The HTCondor team is pleased to announce the release of HTCondor 8.4.1.
A stable series release contains significant bug fixes.  This release
contains all of the bug fixes from the recent HTCondor 8.2.10 release.

Highlights of this release are:
four new policy metaknobs to make configuration easier;
a bug fix to prevent condor daemons from crashing on reconfiguration;
an option natural sorting option on condor_status;
support of admin to mount certain directories into Docker containers;
many other bug fixes, consult the version history.

Further details can be found in the
Version History.
HTCondor 8.4.1 binaries and source code are available from our
Downloads page.
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2015/10/pacing-technical-talks.html">Pacing technical talks</a></h1>
      <p class="meta">
        <time datetime="2015-10-21T16:17:01Z" pubdate data-updated="true">Oct 21<span>st</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>Delivering a technical talk has a lot in common with running a half-marathon or biking a 40k time trial.  You&rsquo;re excited and maybe a little nervous, you&rsquo;re prepared to go relatively hard for a relatively long time, and you&rsquo;re acutely aware of the clock.  In both situations, you might be tempted to take off right from the gun, diving into your hardest effort (or most technical material), but this is a bad strategy. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2015/10/notes-from-flink-forward.html">Notes from Flink Forward</a></h1>
      <p class="meta">
        <time datetime="2015-10-20T15:48:44Z" pubdate data-updated="true">Oct 20<span>th</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/willb/22238437291/in/dateposted-public/" title="Brandenburger Tor lightshow"><img src="https://farm1.staticflickr.com/739/22238437291_22636e4a72_b.jpg" width="1024" height="819" alt="Brandenburger Tor lightshow"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script> [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/">A Library of Binary Tree Algorithms as Mixable Scala Traits</a></h1>
      <p class="meta">
        <time datetime="2015-09-26T19:43:00Z" pubdate data-updated="true">Sep 26<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In this post I am going to describe some work I've done recently on a system of Scala traits that support tree-based collection algorithms prefix-sum, nearest key query and value increment in a mixable format, all backed by Red-Black balanced tree logic, which is also a fully inheritable trait. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/">Lightweight Non-Negative Numerics for Better Scala Type Signatures</a></h1>
      <p class="meta">
        <time datetime="2015-08-19T00:42:00Z" pubdate data-updated="true">Aug 19<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In this post I want to discuss several advantages of defining lightweight non-negative numeric types in Scala, whose primary benefit is that they allow improved type signatures for Scala functions and methods.  I'll first describe the simple class definition, and then demonstrate how it can be used in function signatures and the benefits of doing so. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution/">The Reservoir Sampling Gap Distribution</a></h1>
      <p class="meta">
        <time datetime="2015-08-17T14:35:00Z" pubdate data-updated="true">Aug 17<span>th</span>, 2015  &nbsp; &mdash; &nbsp; Erik Erlandson</time>
      </p>
    </header>
    <div class="entry-content"><p>In a <a href="http://erikerlandson.github.io/blog/2014/09/11/faster-random-samples-with-gap-sampling/">previous post</a>, I showed that random Bernoulli and Poisson sampling could be made much faster by modeling the <em>sampling gap distribution</em> - that is, directly drawing random samples from the distribution of how many elements would be skipped over between actual samples taken. [...]</p>
</div>
  </article>

  <article>
    <header>
      <h1 class="entry-title"><a href="http://chapeau.freevariable.com/2015/06/summit-fedmsg.html">fedmsg talk at Spark Summit</a></h1>
      <p class="meta">
        <time datetime="2015-06-15T15:05:27Z" pubdate data-updated="true">Jun 15<span>th</span>, 2015  &nbsp; &mdash; &nbsp; William Benton</time>
      </p>
    </header>
    <div class="entry-content"><p>I&rsquo;m speaking at Spark Summit today about using Spark to analyze operational data from the Fedora project.  Here are some links to further resources related to my talk: [...]</p>
</div>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Planet HTCondor Members</h1>
    
      <a href="http://chapeau.freevariable.com/"> William Benton</a><br>
    
      <a href="http://erikerlandson.github.com/"> Erik Erlandson</a><br>
    
      <a href="http://research.cs.wisc.edu/htcondor"> HTCondor Team</a><br>
    
  </section>
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - HTCondor Project -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
