<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2014-04-30T09:35:14-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.1.5 released! ( April 15, 2014 )]]></title>
      <link href="manual/v8.1.5/10_3Development_Release.html"/>
      <updated>2014-04-15T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor Team is pleased to announce the release of HTCondor version 8.1.5.
Major new features include:
a change to the default policy, such that it does not preempt jobs;
several new instances of non-blocking I/O to improve performance;
fewer server resources are used by the condor_schedd when handling condor_q requests;
a bug fix, such that large submit description files do not cause condor_submit to crash;
a bug fix, such that large configuration files do not cause the condor_master daemon to crash.
A complete list of bugs fixed and features can be found in the
Version History.
HTCondor 8.1.5 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ OpenSSL vulnerability ( April 10, 2014 )]]></title>
      <link href="https://lists.cs.wisc.edu/archive/htcondor-users/2014-April/msg00054.shtml"/>
      <updated>2014-04-10T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[HTCondor users who are using the SSL or GSI authentication methods, or
submitting grid universe jobs may be vulnerable.  Please see

the post on the HTCondor-users mailing list.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Fitness data visualization with Apache Spark]]></title>
      <link href="http://chapeau.freevariable.com/2014/04/fitness-data-visualization-with-apache-spark.html"/>
      <updated>2014-04-02T04:55:41Z</updated>
      <id>tag:chapeau.freevariable.com,2014://1.45</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[
        <noscript><p>This post contains embedded maps; you&#8217;ll need to view it in a browser with JavaScript support in order to see them.</p></noscript>

<p>One problem that a lot of enthusiastic amateur cyclists encounter is how to make sense of all the workout telemetry data that their smartphone or cycle computer captures.  Most riders have some sense of how their cadence, heart rate, speed, road grade, and wattage come into play at any given moment in a ride as it&#8217;s happening, but answering questions about the bigger picture about how these fit together over time remains more difficult.  I&#8217;ve been experimenting with <a href="http://chapeau.freevariable.com/2013/12/a-simple-machine-learning-app-with-spark.html">cycling data analytics using Apache Spark for some time now</a>, but I thought I&#8217;d share some visualizations that I put together recently to answer a question that&#8217;s been nagging me as the weather warms up here in Wisconsin.</p>

<p>In my last post on using Spark to process fitness data, I presented a very simple visualization based on plotting the centers of clustered GPS traces.  By plotting darker center markers for denser clusters (and generating a large number of clusters), I was able to picture which roads and intersections I spent the most time riding on in the set of activities that I analyzed.  This time, however, I was more interested in a visualization that would tell me <em>what to do</em> rather than a visualization that would tell me <em>what I had already done</em>.</p>

<h3>Background</h3>

<p>One of the most useful tools for a cyclist who is interested in quantifying his or her performance and training is a direct-force power meter.  By measuring the actual force applied at some point on the bicycle drivetrain, these devices can accurately tell riders how many calories they&#8217;re burning in a ride, whether or not they&#8217;re &#8220;burning matches&#8221; (that is, using anaerobic metabolism instead of aerobic metabolism) at a given point in a race, how to pace long steady efforts to maximize performance, and precisely how hard to work in interval training in order to improve various kinds of fitness.  The last of these capabilities will be our focus in this post.</p>

<p>It&#8217;s obvious that there is a difference between ultra-endurance efforts and sprint efforts; no one would try to sprint for an entire 40km time trial (or run a marathon at their 100m pace), and it would be pointless to do sprint-duration efforts at the sort of pace one could maintain for a 12-hour race.  More generally, every athlete has a power-duration curve of the best efforts they could produce over time:  one&#8217;s best 5-second power might be double their best one-minute power and four times their best one-hour power, for example.  There are several points where this curve changes for most people, and these correspond to various physiological systems (for example, the shift from anaerobic to aerobic metabolism).  By targeting interval workouts to certain power zones, athletes can improve the corresponding physiological systems.</p>

<h3>Technique</h3>

<p>I began by clustering points from GPS traces, but instead of plotting the cluster centers, I plotted the convex hulls of all of the points in each cluster.  By giving me polygons containing every point from my data set, this gave me a pretty good picture of where I&#8217;d actually been.  I then calculated my mean power for three durations &#8212; corresponding roughly to anaerobic, VO2max, and just-above-aerobic efforts &#8212; at every point in each activity.  In other words, I mapped each point in each ride to the mean power I was about to produce in that ride.  Then, for each duration, I found the best efforts starting in each cluster and used these data to shade the convex hulls so that hulls where better &#8220;best efforts&#8221; originated would thus appear more saturated.</p>

<p>Because Spark is expressive and can work interactively, it was straightforward to experiment with various techniques and constant factors to make the most sense of these data.  Debugging is straightforward; since I stick to effect-free code as much as possible, I can test my logic without running it under Spark.  Furthermore, Spark is fast enough to make trying a bunch of different options completely painless, even on my desktop computer.</p>

<h3>Results</h3>

<p>I&#8217;m including here three plots of cluster hulls, shaded by the best mean power I achieved starting in that cluster for one minute (green), three minutes (blue), and ten minutes (red). With these visualizations (and with increasingly friendly road cycling weather here in Wisconsin), I can decide where to go to do interval workouts based on where I&#8217;ve had my best efforts in the past.  The data tell me that if I want to work on my one-minute power, I should focus on the Timber Lane climb up from Midtown; if I want to work on my three-minute power, it&#8217;s either Barlow Road or the east side of Indian Lake; and if I want to work on my ten-minute power, it&#8217;s off to Mounds Park Road <a href="http://www.usacycling.org/road-races-kick-off-2013-amateur-para-cycling-road-nationals.htm">for the same climb that made everyone suffer in the national championship road race</a> last year.</p>

<p>(Click and drag or zoom to inspect any map; if one is missing polygons, drag and they should render.)</p>

<script src="https://embed.github.com/view/geojson/willb/sur-la-plaque/examples-20140104/examples/slp60.json"></script>

<script src="https://embed.github.com/view/geojson/willb/sur-la-plaque/examples-20140104/examples/slp180.json"></script>

<script src="https://embed.github.com/view/geojson/willb/sur-la-plaque/examples-20140104/examples/slp600.json"></script>

<h3>Future work</h3>

<p>I have many ideas for where to take this work next and have some implementation in progress that is producing good results but not (yet) perspicuous visualizations.  However, even the more mundane things on my to-do list are pretty interesting:  among other things, I&#8217;d like to do some performance evaluation and see just how much cycling data we could feasibly process on a standard workstation or small cluster (my code is currently unoptimized); to add a web-based front end allowing more interactive analysis; and to improve my (currently very simple) computational geometry and power-analysis code to make better use of Spark&#8217;s abstractions and distributed execution.  (<a href="https://github.com/willb/sur-la-plaque/">The code itself</a>, of course, is available under the Apache license and I welcome your feedback or pull requests.)</p>

<p>I love tools that make it easy to sketch solutions to hard problems interactively (indeed, I spent a lot of time in graduate school developing an <a href="http://web.willbenton.com/software/dimple">interactive tool for designing program analyses</a> &#8212; although in general it&#8217;s more fun to think about bicycling problems than whether or not two references alias one another), and Spark is one of the most impressive interactive environments I&#8217;ve seen for solving big problems.  I&#8217;m looking forward to prototyping and refining more tools for understanding cycling training and performance in the future.</p>

        

    ]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Submitting jobs to HTCondor using Python]]></title>
      <link href="http://osgtech.blogspot.com/2014/03/submitting-jobs-to-htcondor-using-python.html"/>
      <updated>2014-03-19T20:32:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-689352737761121268</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Moving from a Globus to an HTCondor Compute Element]]></title>
      <link href="http://derekweitzel.blogspot.com/2014/02/moving-from-globus-to-htcondor-compute.html"/>
      <updated>2014-02-27T23:05:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-7950648301232917905</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.1.4 released! ( February 27, 2014 )]]></title>
      <link href="manual/v8.1.4/10_3Development_Release.html"/>
      <updated>2014-02-27T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor Team is pleased to announce the release of HTCondor version 8.1.4.
This development release contains all the bug fixes from the stable release version 8.0.6.
Major new features include:
added grid universe support for Google Compute Engine;
support for defining custom resources that easily manage GPUs;
a new tool that does GPU discovery;
improved scalability when using the shared port service;
Python 3 support;
enhanced resilience due to the prompt detection of network failures.
A complete list of bugs fixed and features can be found in the
Version History.
HTCondor 8.1.4 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Bi-directional Variation of the O(NP) Edit Distance Algorithm]]></title>
      <link href="http://erikerlandson.github.com/blog/2014/02/20/a-bi-directional-variation-of-the-o-np-edit-distance-algorithm/"/>
      <updated>2014-02-21T02:51:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2014/02/20/a-bi-directional-variation-of-the-o-np-edit-distance-algorithm</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The O(ND) edit distance algorithm <a href="#ref1">[1]</a> is a standard for efficient computation of the edit distance between two sequences, appearing in applications such as the GNU diff tool.  There is also a variation <a href="#ref2">[2]</a> that operates in O(NP) time, where P is the number of deletions in the shortest edit path.  This O(NP) algorithm has a lower computational cost, since P &lt;= D/2 (and may be &lt;&lt; D/2 in some circumstances) <a href="#ref3">[3]</a>.  In order to apply these algorithms to obtain an <em>edit script</em> in linear space, they must be adapted into a bidirectional form that enables recursive divide-and-conquer.   The basic principles of a bidirectional adaptation of the O(ND) algorithm are described in <a href="#ref1">[1]</a>.   However, no such discussion of a bidirectional O(NP) algorithm is provided in <a href="#ref2">[2]</a>.  Understanding this adaptation involves some observations that aren't immediately obvious.  In this post, I will describe these key observations. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[sbt is in Fedora 20]]></title>
      <link href="http://chapeau.freevariable.com/2014/02/sbt-is-in-fedora-20.html"/>
      <updated>2014-02-20T22:27:57Z</updated>
      <id>tag:chapeau.freevariable.com,2014://1.44</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Longtime Chapeau readers may recall last summer’s lament about the state of the Scala ecosystem in Fedora. We’ve taken a lot of steps since then. After a rough patch for the Fedora Scala package, Scala 2.10 is available and works...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ Consider presenting your work at HTCondor Week 2014 ( February 20, 2014 )]]></title>
      <link href="http://research.cs.wisc.edu/htcondor/HTCondorWeek2014/speaker_info.html"/>
      <updated>2014-02-20T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[HTCondor Week attendees are interested in hearing about your efforts during
our annual meeting, April 28-30.
Please consider presenting.
Details for adding your talk to the schedule are given in this page of
Information for HTCondor Week Speakers.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[One weird trick to eviscerate open source licenses]]></title>
      <link href="http://chapeau.freevariable.com/2014/02/one-weird-trick-to-eviscerate-open-source-licenses.html"/>
      <updated>2014-02-19T17:26:28Z</updated>
      <id>tag:chapeau.freevariable.com,2014://1.43</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[The GNU project’s Four Freedoms present the essential components of Free software: freedom to use the program for any purpose, freedom to study and change the program’s source code, freedom to redistribute the author’s version of the code, and freedom...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Hot Rod Hadoop with Tachyon on Fedora 21 (Rawhide)]]></title>
      <link href="http://timothysc.github.com/blog/2014/02/17/bdas-tachyon/"/>
      <updated>2014-02-17T16:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2014/02/17/bdas-tachyon</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><img class="left" src="http://timothysc.github.com/images/Tachyon.jpg" title="" > [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.0.6 released! ( February 11, 2014 )]]></title>
      <link href="manual/v8.0.6/10_3Stable_Release.html"/>
      <updated>2014-02-11T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.0.6.
This new version contains a port of HTCondor for Red Hat Enterprise Linux 7.0 Beta on the x86_64 architecture that includes support for the standard universe.
It also contains bug fixes for:
transferring files larger then 4 GiB on Windows and 32-bit platforms;
using a minimum of 1024-bit keys on proxy certificates generated by HTCondor;
accepting DAG input files larger then 2 GiB;
the Windows MSI installer setting up a proper configuration for the VM universe;
honoring CPU affinity on Windows platforms;
issues with a failing condor_schedd daemon, when HTCondor is compiled with gcc 4.8+, the default compiler on recent Fedora releases.
A complete list of bugs fixed can be found in the
Version History.
HTCondor 8.0.6 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A simple machine learning app with Spark]]></title>
      <link href="http://chapeau.freevariable.com/2013/12/a-simple-machine-learning-app-with-spark.html"/>
      <updated>2013-12-04T13:47:26Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.42</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[I'm currently on my way back from the first-ever Spark Summit, where I presented a talk on some of my work with the Fedora Big Data SIG to package Apache Spark and its infrastructure for Fedora. (My slides are online,...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Apache Thrift in Fedora]]></title>
      <link href="http://chapeau.freevariable.com/2013/10/apache-thrift-in-fedora.html"/>
      <updated>2013-10-16T19:58:16Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.41</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[You probably already know that Apache Thrift is a framework for developing distributed services and clients to access these in multiple languages. You probably also knew that Thrift is extremely popular among the sorts of cool projects that those of...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bootstrapping your MapReduce 2.X programming on Fedora 20]]></title>
      <link href="http://timothysc.github.com/blog/2013/09/14/hadoop-mapreduce/"/>
      <updated>2013-09-14T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/09/14/hadoop-mapreduce</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><img src="http://timothysc.github.com/images/ElephantCowboy.jpg" alt="Picture Courtesy of Mauro Flores jr"/> [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Creating a native Mac Installer for Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/07/creating-native-mac-installer-for-bosco.html"/>
      <updated>2013-07-11T20:34:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9151105712164146929</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Leveraging systemd cgroup integration to provide SLAs on Fedora 18 & 19]]></title>
      <link href="http://timothysc.github.com/blog/2013/06/14/systemd-cgroup-sla/"/>
      <updated>2013-06-14T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/06/14/systemd-cgroup-sla</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Submitting R jobs with Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/05/submitting-r-jobs-with-bosco.html"/>
      <updated>2013-05-20T14:51:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9067247722276578550</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
</feed>
