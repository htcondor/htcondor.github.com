<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2015-06-10T03:39:22-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[Bokeh plots from Spark]]></title>
      <link href="http://chapeau.freevariable.com/2015/05/bokeh-plots-from-spark.html"/>
      <updated>2015-05-21T16:05:10Z</updated>
      <id>http://chapeau.freevariable.com/2015/05/bokeh-plots-from-spark</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>This post will show you an extremely simple way to make quick-and-dirty <a href="http://bokeh.pydata.org/en/latest/">Bokeh</a> plots from data you&rsquo;ve generated in Spark, but the basic technique is generally applicable to any data that you&rsquo;re generating in some application that doesn&rsquo;t necessarily link in the Bokeh libraries.</p>

<h3>Getting started</h3>

<p>We&rsquo;ll need to have a recent version of Bokeh installed and some place to put our data.  If you don&rsquo;t already have Bokeh installed, use <code>virtualenv</code> to get it set up:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>virtualenv ~/.bokeh-venv
</span><span class='line'><span class="nb">source</span> ~/.bokeh-venv/bin/activate
</span><span class='line'>pip install bokeh numpy pandas
</span></code></pre></td></tr></table></div></figure>


<p>This will download and build a nontrivial percentage of the Internet.  Consider getting some coffee or catching up with a colleague while it does its thing.</p>

<p>The next thing we&rsquo;ll need is some place to stash data we&rsquo;ve generated.  I&rsquo;ll use <a href="https://github.com/willb/firkin">a very simple service</a> that I developed just for this kind of application, but you can use whatever you want as long as it will let you store and retrieve JSON data from a given URL.</p>

<p>With all that in place, we&rsquo;re ready to make a simple plot.</p>

<h3>A basic static-HTML plot</h3>

<p>We&rsquo;re going to use Bokeh to construct a basic line graph in a static HTML file.  The catch is that instead of specifying the data statically, we&rsquo;re going to specify it as a URL, which the page will poll so it can update the plot when it changes.  Here&rsquo;s what a script to construct that kind of plot looks like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#!/usr/bin/env python</span>
</span><span class='line'>
</span><span class='line'><span class="kn">from</span> <span class="nn">bokeh.plotting</span> <span class="kn">import</span> <span class="n">figure</span><span class="p">,</span> <span class="n">output_file</span><span class="p">,</span> <span class="n">show</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">bokeh.models.sources</span> <span class="kn">import</span> <span class="n">AjaxDataSource</span>
</span><span class='line'><span class="n">output_file</span><span class="p">(</span><span class="s">&quot;json.html&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&quot;data polling example&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">source</span> <span class="o">=</span> <span class="n">AjaxDataSource</span><span class="p">(</span><span class="n">data_url</span><span class="o">=</span><span class="s">&quot;http://localhost:4091/tag/foo&quot;</span><span class="p">,</span> <span class="n">polling_interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</span><span class='line'><span class="n">p</span> <span class="o">=</span> <span class="n">figure</span><span class="p">()</span>
</span><span class='line'><span class="n">p</span><span class="o">.</span><span class="n">line</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span> <span class="s">&#39;y&#39;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
</span><span class='line'><span class="n">show</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that the above example assumes you&rsquo;re using the Firkin service as your data store.  If you&rsquo;re using something else, you will probably need to change the <code>data_url</code> parameter to the <code>AjaxDataSource</code> constructor.</p>

<h3>Publishing and updating data</h3>

<p>Now we&rsquo;ll fire up the Firkin server and post some data.  From a checkout of the Firkin code, run <code>sbt server/console</code> and then create a connection to the server using the client library:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">client</span> <span class="k">=</span> <span class="k">new</span> <span class="n">com</span><span class="o">.</span><span class="n">freevariable</span><span class="o">.</span><span class="n">firkin</span><span class="o">.</span><span class="nc">Client</span><span class="o">(</span><span class="s">&quot;localhost&quot;</span><span class="o">,</span> <span class="mi">4091</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can now supply some values for <code>x</code> and <code>y</code>.  We&rsquo;ll start simple:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="cm">/* publish an object to http://localhost:4091/tag/foo */</span>
</span><span class='line'><span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="o">(</span><span class="s">&quot;foo&quot;</span><span class="o">,</span> <span class="s">&quot;&quot;&quot;{&quot;x&quot;: [1,2,3,4,5,6,7,8,9,10], &quot;y&quot;: [2,4,6,8,10,12,14,16,18,20]}&quot;&quot;&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you don&rsquo;t already have <code>json.html</code> from the previous step loaded in your browser, fire it up.  You should see a plot that looks like this:</p>

<p><img src="http://chapeau.freevariable.com/static/201505/bokeh1.png" alt="plot of y=2x for 1..10" /></p>

<p>If we update the data stored at this URL, the plot will update automatically.  Try it out; publish a new data set:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="o">(</span><span class="s">&quot;foo&quot;</span><span class="o">,</span> <span class="s">&quot;&quot;&quot;{&quot;x&quot;: [1,2,3,4,5,6,7,8,9,10], &quot;y&quot;: [2,4,6,8,10,12,14,16,18,30]}&quot;&quot;&quot;</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The plot will refresh, reflecting the updated <code>y</code> value:</p>

<p><img src="http://chapeau.freevariable.com/static/201505/bokeh2.png" alt="plot of y=2x for 1..9 and y=3x for x=10" /></p>

<p>(Again, if you&rsquo;re using some other JSON object cache to store your data sets, the principles will be the same but the syntax won&rsquo;t be.)</p>

<h3>Connecting Bokeh to Spark</h3>

<p>Once we have a sink for JSON data, it&rsquo;s straightforward to publish data to it from Spark code.  Here&rsquo;s a simple example, using <a href="https://github.com/json4s/json4s"><code>json4s</code></a> to serialize the RDDs:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">org.json4s.JsonDSL._</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.json4s.jackson.JsonMethods._</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// assume that spark is a SparkContext object, declared elsewhere</span>
</span><span class='line'><span class="k">val</span> <span class="n">x</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="mi">1</span> <span class="n">to</span> <span class="mi">100</span><span class="o">)</span>
</span><span class='line'><span class="c1">// x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">y</span> <span class="k">=</span> <span class="n">x</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span> <span class="o">/</span> <span class="mi">4</span><span class="o">)</span>
</span><span class='line'><span class="n">y</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">1</span><span class="o">]</span> <span class="n">at</span> <span class="n">map</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">json</span> <span class="k">=</span> <span class="o">(</span><span class="s">&quot;x&quot;</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">toList</span><span class="o">)</span> <span class="o">~</span> <span class="o">(</span><span class="s">&quot;y&quot;</span> <span class="o">-&gt;</span> <span class="n">y</span><span class="o">.</span><span class="n">collect</span><span class="o">.</span><span class="n">toList</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">client</span> <span class="k">=</span> <span class="k">new</span> <span class="n">com</span><span class="o">.</span><span class="n">freevariable</span><span class="o">.</span><span class="n">firkin</span><span class="o">.</span><span class="nc">Client</span><span class="o">(</span><span class="s">&quot;localhost&quot;</span><span class="o">,</span> <span class="mi">4091</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="o">(</span><span class="s">&quot;data&quot;</span><span class="o">,</span> <span class="n">compact</span><span class="o">(</span><span class="n">render</span><span class="o">(</span><span class="n">json</span><span class="o">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>After we do this, the data will be available at <code>http://localhost:4091/tag/data</code>.</p>

<h3>Alternate approaches</h3>

<p>The approach described so far in this post was designed to provide the simplest possible way to make a basic plot backed by a relatively small amount of dynamic data.  (If we have data to plot that we can&rsquo;t store in memory on a single node, we&rsquo;ll need something more sophisticated.)  It is suitable for prototyping or internal use.  Other approaches, like the two below, might make more sense for other situations:</p>

<ol>
<li>Bokeh offers several <a href="http://bokeh.pydata.org/en/latest/docs/dev_guide/bindings.html">alternate language bindings</a>, including <a href="https://github.com/bokeh/bokeh-scala">one for Scala</a>.  This means that you can define plots and supply data for them from within applications that link these libraries in.  This is the approach that <a href="https://github.com/andypetrella/spark-notebook">spark-notebook</a> takes, for example.</li>
<li>Another possibility is setting up the <a href="http://bokeh.pydata.org/en/0.8.1/docs/user_guide/server.html">Bokeh server</a> and publishing plots and data to it.  The Bokeh server offers several additional capabilities, including support for scalable visualizations (e.g., via sampling large datasets) and support for multiple authenticated users.</li>
</ol>

]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Planning your career like a racing season]]></title>
      <link href="http://chapeau.freevariable.com/2015/05/process-goals.html"/>
      <updated>2015-05-14T21:04:20Z</updated>
      <id>http://chapeau.freevariable.com/2015/05/process-goals</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Most people set personal and professional goals.  If you work in software, your near-term professional goals might sound like this:</p>

<ul>
<li>Ship the next version of our team&rsquo;s product without any undiscovered crashing bugs</li>
<li>Improve the performance of the caching layer by 10%</li>
<li>Become a committer on some particular open-source project</li>
</ul>


<p>Those probably sound pretty reasonable, right?  They aren&rsquo;t vague wishes, they&rsquo;re goals.  They probably aren&rsquo;t totally unrealistic, and you&rsquo;ll know you&rsquo;ve achieved them when some objective, measurable thing happens.  (They&rsquo;re <a href="http://en.wikipedia.org/wiki/SMART_criteria">SMART</a>, in other words.)</p>

<p>We&rsquo;ll come back to these goals.  First, though, I&rsquo;d like digress and talk about bike racing, and specifically about the kinds of goals an amateur racer might set for a year.  Maybe those would look like this:</p>

<ul>
<li>Stay healthy and avoid injuries all season</li>
<li>Improve my one-minute power output by 0.5 W/kg</li>
<li>Upgrade my racing category</li>
</ul>


<p>These are more or less analogous to the professional goals.  They&rsquo;re objective, measurable, and reasonable.  However, they&rsquo;re also at least partially out of your control.  You can&rsquo;t totally prevent yourself from getting sick or crashing.  Your one-minute power might be right at the limits of your genetic capabilities (or maybe your season shapes up so that it makes more sense to focus on improving other aspects of your fitness).  And the category upgrade is up to an official in your local cycling association &mdash; you can get an automatic upgrade by winning races, but whether or not you win is also largely out of your control.</p>

<p>I first read about the idea of <a href="http://velonews.competitor.com/2013/10/training-center/setting-goals-finding-your-perfect-process_306088"><em>process and outcome goals</em></a> in Joe Friel&rsquo;s <em>The Cyclist&rsquo;s Training Bible</em>, but I&rsquo;ve found them extremely helpful in talking about professional goals as well.  The idea is that there are two kinds of goals:  outcome goals, which are results, and process goals, which relate to how you prepare and execute.  Of course, you&rsquo;re ultimately interested in outcomes (winning races, shipping great products, becoming recognized as an authority in your field), but outcomes are always to some extent out of your control.</p>

<p>Instead of focusing on outcomes for goals, it makes more sense to focus on what you can control:  the processes that support those outcomes.  So, in the bike case, you could recast the outcome goals as:</p>

<ul>
<li>Make sure I get at least 7 hours of sleep a night and avoid sketchy racers in corners or sprints</li>
<li>Do plyometric exercises at least twice a week in the offseason</li>
<li>Identify key races that I can do well in and make sure to show up for them well-rested and with adequate nutrition; then focus on avoiding particular tactical mistakes I&rsquo;ve made in past races</li>
</ul>


<p>The software goals I mentioned at the beginning of the article are also outcome goals.  You can&rsquo;t guarantee that your product won&rsquo;t have any undiscovered crashing bugs, but you can sure put processes in place so that you&rsquo;re more likely to discover crashing bugs before you ship.  Similarly, a 10% performance improvement sounds great, but it might require unjustifiable effort or be unachievable (conversely, it might turn out that 10% improvement is insufficient to improve the behavior of the whole system)!  Community leadership positions always involve political as well as meritocratic considerations; while you can make a case for yourself as a good candidate, you can&rsquo;t force people to vote for you.</p>

<p>Recast as process goals, the software goals might look like this:</p>

<ul>
<li>Ensure that no new commit to our product introduces untested code, use property-based tests for all internal data structures, and incorporate <a href="http://en.wikipedia.org/wiki/Fuzz_testing">fuzzing</a> of every public interface into the QA process.</li>
<li>Profile the caching layer under a range of conditions and document the hot spots, identifying algorithmic and implementation-level avenues for performance improvement.  Add performance testing to CI.</li>
<li>Participate in the project community, answering questions on the mailing list every week and submitting at least one nontrivial patch a week.</li>
</ul>


<p>It&rsquo;s easy to imagine the rest of your career and think about outcomes you want to see:  earning a prestigious position, achieving acknowledged impact in your department or company, or writing a popular framework (or book).<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>  But those goals are often pretty far off from what you need to do to get there.  Setting process goals supports the outcomes that you want to achieve.  But the really remarkable thing is that they do so much more than that.  By focusing on improving your preparation and execution, you&rsquo;re making yourself a better engineer (or bike racer) even if you don&rsquo;t get the outcomes you want right away &mdash; and making it more likely you&rsquo;ll see great outcomes in the future.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Outcome goals are a particularly dangerous trap if you&rsquo;re coming from an environment like academia or open-source development, where outcome-related metrics like tenure, citation count, and number of GitHub &ldquo;stars&rdquo; are never far from your evaluation of your own career.  (The frictionless recognitions afforded by social media &ldquo;likes&rdquo; and &ldquo;favorites&rdquo; bring this headache to a much broader audience.)<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Parallel K-Medoids Using Scala ParSeq]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/"/>
      <updated>2015-05-06T23:33:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Scala supplies a <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections library</a> that was designed to make it easy for a programmer to add parallel computing over the elements in a collection.  In this post, I will describe a case study of applying Scala's parallel collections to cleanly implement multithreading support for training a K-Medoids clustering model. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Elasticsearch and Spark 1.3]]></title>
      <link href="http://chapeau.freevariable.com/2015/04/elasticsearch-and-spark-1-dot-3.html"/>
      <updated>2015-04-30T20:34:37Z</updated>
      <id>http://chapeau.freevariable.com/2015/04/elasticsearch-and-spark-1-dot-3</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a> has offered Hadoop <code>InputFormat</code> and <code>OutputFormat</code> implementations for quite some time.  These made it possible to process Elasticsearch indices with Spark just as you would any other Hadoop data source.  Here&rsquo;s an example of this in action, taken from <a href="http://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html">Elastic&rsquo;s documentation</a>: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Effective continuous integration for Spark projects]]></title>
      <link href="http://chapeau.freevariable.com/2015/04/spark-apps-and-ci.html"/>
      <updated>2015-04-21T20:57:24Z</updated>
      <id>http://chapeau.freevariable.com/2015/04/spark-apps-and-ci</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a href="http://silex.freevariable.com">Silex</a> is a small library of helper code intended to make it easier to build real-world Spark applications;<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> most of it is factored out from applications we&rsquo;ve developed internally at Red Hat.  We have a couple of long-term goals for the Silex project: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.5 released! ( April 20, 2015 )]]></title>
      <link href="manual/v8.3.5/10_3Development_Release.html"/>
      <updated>2015-04-20T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.5.
A development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.2.8
stable release.
A few of the enhancements in this release include:
new features that increase the power of job specification in the
submit description file;
RPMs for Red Hat Enterprise Linux 6 and 7 are modularized and only
distributed via our YUM repository;
The new condor-all RPM requires
the other HTCondor RPMs of a typical HTCondor installation.
Further details can be found in the
Version History.
HTCondor 8.3.5 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Natural join for data frames in Spark]]></title>
      <link href="http://chapeau.freevariable.com/2015/04/natural-join-for-spark-dataframes.html"/>
      <updated>2015-04-08T21:21:21Z</updated>
      <id>http://chapeau.freevariable.com/2015/04/natural-join-for-spark-dataframes</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a href="http://en.wikipedia.org/wiki/Relational_algebra#Natural_join_.28.E2.8B.88.29">Natural join</a> is a useful special case of the relational join operation (and is extremely common when denormalizing data pulled in from a relational database).  Spark&rsquo;s DataFrame API provides an expressive way to specify arbitrary joins, but it would be nice to have some machinery to make the simple case of natural join as easy as possible.  Here&rsquo;s what a natural join needs to do: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.2.8 released! ( April 7, 2015 )]]></title>
      <link href="manual/v8.2.8/10_3Stable_Release.html"/>
      <updated>2015-04-07T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor version 8.2.8.
A stable series release contains significant bug and security fixes.
This version contains:
a bug fix to reconnect a TCP session when an HTCondorView collector restarts;
a bug fix to avoid starting too many jobs, only to kill some chosen at random.
A complete list of fixed bugs can be found in the
Version History.
HTCondor 8.2.8 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Hygienic Closures for Scala Function Serialization]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization/"/>
      <updated>2015-03-31T13:06:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In most use cases of Scala closures, what you see is what you get, but there are exceptions where looks can be deceiving and this can have a big impact on closure serialization.  Closure serialization is of more than academic interest.  Tools like Apache Spark cannot operate without serializing functions over the network.  In this post I'll describe some scenarios where closures include more than what is evident in the code, and then a technique for preventing unwanted inclusions. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor helps astronomers with the hydrogen location problem ( March 26, 2015 )]]></title>
      <link href="http://www.news.wisc.edu/23594"/>
      <updated>2015-03-26T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[This  UW Madison news article discusses how a new computational approach permits evaluation of hydrogen data using software, which may replace the time consuming manual approach. Putting HTCondor into the mix scales well given the vast quantities of data expected as Square Kilometer Array radio telescope is realized.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor Week 2015 Registration Open (March 25, 2015 )]]></title>
      <link href="http://research.cs.wisc.edu/htcondor/HTCondorWeek2015/"/>
      <updated>2015-03-25T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[We invite HTCondor users, administrators, and developers to HTCondor Week 2015, our annual HTCondor user conference, in beautiful Madison, Wisconsin, May 19-22, 2015. HTCondor Week features tutorials and talks from HTCondor developers, administrators, and users.  It also provides an opportunity for one-on-one or small group collaborations throughout the week.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.4 released! ( March 5, 2015 )]]></title>
      <link href="manual/v8.3.4/10_3Development_Release.html"/>
      <updated>2015-03-05T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.4.
This development release contains a single bug fix for a problem introduced
in version 8.3.3 that can cause jobs to not be matched to resources when the
condor_schedd is flocking.
This 8.3.4 release also has a known issue which prevents a mixed mode,
IPv4 and IPv6 HTCondor installation from starting jobs. If using IPv4
and IPv6 in mixed mode communication is required, please continue using
HTCondor version 8.3.2. The issue will be fixed in version 8.3.5.
Further details can be found in the
Version History.
HTCondor 8.3.4 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[HTCondor CacheD: Caching for HTC - Part 2]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/htcondor-cached-caching-for-htc-part-2.html"/>
      <updated>2015-01-25T15:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-5260378956420164105</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Monadic 'break' and 'continue' for Scala Sequence Comprehensions]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions/"/>
      <updated>2015-01-24T18:54:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Author's note: I've since received some excellent feedback from the Scala community, which I included in some <a href="#notes">end notes</a>. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Condor CacheD: Caching for HTC - Part 1]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/condor-cached-caching-for-htc-part-1.html"/>
      <updated>2015-01-22T16:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1889975382858537261</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Faster Random Samples With Gap Sampling]]></title>
      <link href="http://erikerlandson.github.com/blog/2014/09/11/faster-random-samples-with-gap-sampling/"/>
      <updated>2014-09-11T14:57:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2014/09/11/faster-random-samples-with-gap-sampling</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Generating a random sample of a collection is, logically, a O(np) operation, where (n) is the sample size and (p) is the sampling probability.  For example, extracting a random sample, without replacement, from an array might look like this in pseudocode: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Getting Started with Mesos on Fedora 21 and CentOS 7]]></title>
      <link href="http://timothysc.github.com/blog/2014/09/08/mesos-breeze/"/>
      <updated>2014-09-08T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2014/09/08/mesos-breeze</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><img class="left" src="http://timothysc.github.com/images/mesos_logo.png"> [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Scala Iterator 'drop' Method Generates a Matryoshka Class Nesting]]></title>
      <link href="http://erikerlandson.github.com/blog/2014/09/03/matryoshka-class-construction-from-the-scala-iterator-drop-method/"/>
      <updated>2014-09-04T00:23:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2014/09/03/matryoshka-class-construction-from-the-scala-iterator-drop-method</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The Scala Iterator <code>drop</code> method has a complexity bug that shows up when one calls <code>drop</code> repeatedly, for example when traversing over an iterator in a loop. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[GPUs on the OSG]]></title>
      <link href="http://derekweitzel.blogspot.com/2014/06/gpus-on-osg.html"/>
      <updated>2014-06-25T18:36:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-6396978665247392483</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
</feed>
