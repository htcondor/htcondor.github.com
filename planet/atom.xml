<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2013-12-29T03:18:20-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.1.3 released! ( December 23, 2013 )]]></title>
      <link href="manual/v8.1.3/10_3Development_Release.html"/>
      <updated>2013-12-23T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor Team is pleased to announce the release of HTCondor version 8.1.3.
This development release contains all the bug fixes from the stable release version 8.0.5.
Major new features include:
the parsing of configuration has changed such that comments are permitted within multi-line definitions;
the condor_sos tool helps administrators manage overloaded daemons by causing commands to be handled with a higher priority;
a new Python binding reads event logs.
A complete list of bugs fixed and features can be found in the 
Version History.
HTCondor 8.1.3 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.0.5 released! ( December 12, 2013 )]]></title>
      <link href="manual/v8.0.5/10_3Stable_Release.html"/>
      <updated>2013-12-12T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.0.5.
This new version contains bug fixes for:
a heavily loaded condor_schedd daemon crashing when starting a local universe job,
a condor_schedd daemon failing to start due to illegal values in the job queue or accounting recovery logs,
interactive jobs not running when using cgroups,
permissions errors preventing java universe jobs from running,
and VMware vm universe jobs removing useful devices.
A complete list of bugs fixed can be found in the
Version History.
HTCondor 8.0.5 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Hello Fedora with docker in 3 steps]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/12/10/hello-fedora-with-docker-in-3-steps/"/>
      <updated>2013-12-10T13:18:17Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=931</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[<p>It really is this simple,</p>
<pre class="brush: bash; gutter: false; title: ; notranslate">
1. sudo yum install -y docker-io

2. sudo systemctl start docker

3. sudo docker run mattdm/fedora cat /etc/system-release
</pre>
<hr />
<p>Bonus, for when you want to go deeper -</p>
<p>If you don&#8217;t want to use sudo all the time, which you shouldn&#8217;t want to do, you add yourself to the docker group,</p>
<pre class="brush: bash; gutter: false; title: ; notranslate">
$ sudo usermod -a -G docker $USER
</pre>
<p>If you don&#8217;t want to log out and back in, make your new group effective immediately,</p>
<pre class="brush: bash; gutter: false; title: ; notranslate">
$ su - $USER
$ groups | grep -q docker &amp;&amp; echo Good job || echo Try again
</pre>
<p>If you want to run a known image, search for it on <a href="https://index.docker.io" rel="nofollow">https://index.docker.io</a> or on the command line,</p>
<pre class="brush: bash; gutter: false; title: ; notranslate">
$ docker search fedora
</pre>
<p>Try out a shell with,</p>
<pre class="brush: bash; gutter: false; title: ; notranslate">
$ docker run -i -t mattdm/fedora /bin/bash
</pre><br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/931/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/931/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=931&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A simple machine learning app with Spark]]></title>
      <link href="http://chapeau.freevariable.com/2013/12/a-simple-machine-learning-app-with-spark.html"/>
      <updated>2013-12-04T13:47:26Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.42</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[
        <p>I'm currently on my way back from the first-ever <a href="http://spark-summit.org">Spark Summit</a>, where I presented a talk on some of my work with the <a href="https://fedoraproject.org/wiki/SIGs/bigdata">Fedora Big Data SIG</a> to package Apache Spark and its infrastructure for Fedora.  (<a href="http://spark-summit.org/wp-content/uploads/2013/10/E-Will-Benton-Redhat.pdf">My slides</a> are online, but they aren't particularly useful without the talk.  I'll post a link to the video when it's available, though.)</p>

<p>If you're interested in learning more about Spark, a great place to start is the <a href="http://spark-summit.org/2013/exercises/">guided exercises</a> that the Spark team put together; simply follow their instructions to fire up an EC2 cluster with Spark installed and then work through the exercises.  In one of the exercises, you'll have <a href="http://spark-summit.org/2013/exercises/machine-learning-with-spark.html">an opportunity</a> to build up one of the classic Spark demos:  distributed k-means clustering in about a page of code.</p>

<p>Implementing k-means on resilient distributed datasets is an excellent introduction to key Spark concepts and idioms. With recent releases of Spark, though, machine learning can be simpler still: <a href="http://spark.incubator.apache.org/docs/latest/mllib-guide.html">MLLib</a> includes an implementation of k-means clustering (as well as several other fundamental algorithms).  One of my spare-time projects has been experimenting with featurizing bicycling telemetry data (coordinates, altitude, mean maximal power, and heart rate) in order to aid self-coaching, and I've been using MLLib for this project.  I don't have any results yet that are interesting from a coaching perspective, but simply using GPS coordinates as feature vectors leads naturally to an expressive visualization:</p>

<p><script src="https://gist.github.com/willb/161a3551dd8552075d91.js"></script><noscript>Visit this post in a browser with JavaScript support enabled to see the embedded map.</noscript></p>

<p>The above map visualizes about six weeks of road rides in late summer and early fall.  It does so by plotting the centers of clusters; darker markers correspond to clusters that contain more trackpoints.  I've generated similar maps by hand <a href="http://blog.willbenton.com/2013/01/2012-cycling/">before</a>, and Strava offers <a href="http://blog.strava.com/new-premium-feature-personal-heatmaps-6719/">automatic activity heatmaps</a> now, but I like the clustering visualization since it can plot routes (when run with hundreds of clusters) or plot hot areas (when run with dozens of clusters).  </p>

<p>Some fairly rough code to generate such a map is available in <a href="https://github.com/willb/sur-la-plaque">my cycling data analysis sandbox</a>; you can download and run the app yourself.  First, place a bunch of TCX files in a directory (here we're using "activities").  Then build and run the app, specifying the location of your activities directory with the "-d" parameter:</p>

<pre><code>% sbt console
scala&gt; com.freevariable.surlaplaque.GPSClusterApp.main(Array("-dactivities"))
</code></pre>

<p>You can influence the output and execution of the app with several environment variables:  <code>SLP_MASTER</code> sets the Spark master (defaults to local with 8 threads); <code>SLP_OUTPUT_FILE</code> sets the name of the GeoJSON output file (defaults to <code>slp.json</code>), <code>SLP_CLUSTERS</code> sets the number of clusters and <code>SLP_ITERATIONS</code> sets the number of k-means iterations.  Once you have the GeoJSON file, you can publish it by <a href="https://help.github.com/articles/mapping-geojson-files-on-github">posting it to GitHub</a> or your favorite map hosting service.</p>

<p>To get started with MLLib in your own projects, make sure to add <code>spark-mllib</code> to your <code>build.sbt</code> file:</p>

<pre><code>libraryDependencies += "org.apache.spark" % "spark-core_2.9.3" % "0.8.0-incubating"

libraryDependencies += "org.apache.spark" % "spark-mllib_2.9.3" % "0.8.0-incubating"
</code></pre>

<p>From there, it's extremely straightforward to get k-means running; here are the relevant lines from my app (<code>vectors</code> is an <code>RDD</code> of <code>Array[Double]</code>):</p>

<pre><code>val km = new KMeans()
km.setK(numClusters)
km.setMaxIterations(numIterations)

val model = km.run(vectors)

val labeledVectors = vectors.map((arr:Array[Double]) =&gt; (model.predict(arr), arr))
</code></pre>

<p>In just a few lines of code, this code initializes a k-means object, optimizes a model, and labels each trackpoint with the cluster the model expects it to belong to.  Since this functionality is blazing fast and available interactively from the Spark shell, we can easily experiment with different feature extraction policies and see what helps us get some insight from our data.</p>

        

    ]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor assists in Einstein@Home discovery of a new radio pulsar ( November 4, 2013 )]]></title>
      <link href="http://einstein.phys.uwm.edu/forum_thread.php?id=10397"/>
      <updated>2013-11-04T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[We add our congratulations to James Drews of the University of Wisconsin - Madison for the discovery of J1859+03, a new radio pulsar, within data from the Arecibo Observatory PALFA survey.  James backfills the Computer Aided Engineering HTCondor pool with the Einstein@Home boinc client.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.1.2 released! ( October 31, 2013 )]]></title>
      <link href="manual/v8.1.2/10_3Development_Release.html"/>
      <updated>2013-10-31T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.1.2.
This development release contains all the bug fixes from the stable release version 8.0.4.
Major new features include:
partitionable slots can now be split into dynamic slots at negotiation time using new consumption policies;
new condor_chirp commands permit updates to job ClassAd attributes to occur in a delayed fashion, reducing the overhead of making the update;
there are many Python binding improvements including a new Negotiator class;
condor_ssh_to_job now works for grid universe jobs on amazon EC2 resources;
new command line options for condor_config_val and condor_history allow them to query remote machines;
increased the scalability of the condor_shared_port daemon, condor_queue, and condor_status by increasing concurrency.
A complete list of bugs fixed and features can be found in the 
Version History.
HTCondor 8.1.2 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.0.4 released! ( October 24, 2013 )]]></title>
      <link href="manual/v8.0.4/10_3Stable_Release.html"/>
      <updated>2013-10-24T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.0.4.
This new version contains a clipped version of HTCondor for Ubuntu 12.04
on the x86_64 architecture, and a fix for condor_ssh_to_job incorrectly removing
jobs when cgroups are used.
A complete list of bugs fixed can be found in the
Version History.
HTCondor 8.0.4 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Apache Thrift in Fedora]]></title>
      <link href="http://chapeau.freevariable.com/2013/10/apache-thrift-in-fedora.html"/>
      <updated>2013-10-16T19:58:16Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.41</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[You probably already know that Apache Thrift is a framework for developing distributed services and clients to access these in multiple languages. You probably also knew that Thrift is extremely popular among the sorts of cool projects that those of...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bootstrapping your MapReduce 2.X programming on Fedora 20]]></title>
      <link href="http://timothysc.github.com/blog/2013/09/14/hadoop-mapreduce/"/>
      <updated>2013-09-14T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/09/14/hadoop-mapreduce</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><img src="http://timothysc.github.com/images/ElephantCowboy.jpg" alt="Picture Courtesy of Mauro Flores jr"/> [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Making Fedora a better place for Scala]]></title>
      <link href="http://chapeau.freevariable.com/2013/08/making-fedora-a-better-place-for-scala.html"/>
      <updated>2013-08-05T17:14:10Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.40</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Scala combines a lot of excellent features (functional-style pattern matching, an expressive type system, closures, etc.) with JVM compatibility and a very interesting developer ecosystem (e.g., Akka, Play, Lift, scalacheck, and Spark, just to name a few notable projects). Fedora...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Creating a native Mac Installer for Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/07/creating-native-mac-installer-for-bosco.html"/>
      <updated>2013-07-11T20:34:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9151105712164146929</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Leveraging systemd cgroup integration to provide SLAs on Fedora 18 & 19]]></title>
      <link href="http://timothysc.github.com/blog/2013/06/14/systemd-cgroup-sla/"/>
      <updated>2013-06-14T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/06/14/systemd-cgroup-sla</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Submitting R jobs with Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/05/submitting-r-jobs-with-bosco.html"/>
      <updated>2013-05-20T14:51:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9067247722276578550</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Configuring a Personal Hadoop Development Environment on Fedora 18]]></title>
      <link href="http://timothysc.github.com/blog/2013/04/22/personalhadoop/"/>
      <updated>2013-04-22T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/04/22/personalhadoop</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Installing Spark on Fedora 18]]></title>
      <link href="http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html"/>
      <updated>2013-04-11T21:37:28Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.39</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[The Spark project is an actively-developed open-source engine for data analytics on clusters using Scala, Python, or Java. It offers map, filter, and reduce operations over in-memory collections, data from local files, or data taken from HDFS, but unlike standard...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Reprocessing CMS events with Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/04/reprocessing-cms-events-with-bosco.html"/>
      <updated>2013-04-02T19:38:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9221383956864186778</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Impact of Negotiator Cycle Cadence on Slot Loading]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading/"/>
      <updated>2013-03-21T22:10:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_1Introduction.html#8555">HTCondor negotiator</a> assigns jobs (resource requests) to slots (compute resources) at regular intervals, configured by the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#20544">NEGOTIATOR_INTERVAL</a> parameter.  This interval (the cycle <em>cadence</em>) has a fundamental impact on a pool <em>loading factor</em> -- the fraction of time that slots are being productively utilized. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Smooth Gradients for Cubic Hermite Splines]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/"/>
      <updated>2013-03-16T14:39:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, ... m_{n-1} \) at knot-points: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Examining the Modulus of Random Variables]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/"/>
      <updated>2013-03-15T19:03:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h3>Motivation</h3> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Running Quantum Espresso on the OSG]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/03/running-quantum-espresso-on-osg.html"/>
      <updated>2013-03-05T18:53:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-2337400839561942722</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Per-Process Mount Namespaces]]></title>
      <link href="http://timothysc.github.com/blog/2013/02/22/perprocess/"/>
      <updated>2013-02-22T16:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/02/22/perprocess</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Statistic changes in HTCondor 7.7]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/12/statistic-changes-in-htcondor-7-7/"/>
      <updated>2013-02-12T11:56:04Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=925</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Notice to HTCondor 7.8 users - Statistics implemented during the 7.5 series that landed in 7.7.0 were rewritten by the time 7.8 was released. If you were using the original statistics for monitoring and/or reporting, here is a table to help you map old (left column) to new (right column). See â€“ 7.6 -&#62; 7.8 [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=925&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Bosco to submit to Amazon EC2]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/02/using-bosco-to-submit-to-amazon-ec2.html"/>
      <updated>2013-02-06T04:27:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-4538100752405939638</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[How accounting group configuration could work with Wallaby]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/05/how-accounting-group-configuration-could-work-with-wallaby/"/>
      <updated>2013-02-05T11:46:28Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=917</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Configuration of accounting groups in HTCondor is too often an expert task that requires coordination between administrators and their tools. Wallaby provides a coordination point, so long as a little convention is employed, and can provide a task specific interface to simplify configuration. Quick background, Wallaby provides semantic configuration for HTCondor. It models a pool [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=917&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Some htcondor-wiki stats]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/29/some-htcondor-wiki-stats/"/>
      <updated>2013-01-29T11:36:06Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=903</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[A few years ago I discovered Web Numbr, a service that will monitor a web page for a number and graph that number over time. I installed a handful of webnumbrs to track things at HTCondor&#8217;s gittrac instance. http://webnumbr.com/search?query=condor Thing such as - Tickets resolved with no destination: tickets that don&#8217;t indicate what version they [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=903&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Introducing the HTCondor-CE]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/introducing-htcondor-ce.html"/>
      <updated>2013-01-28T15:33:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1124494645797252707</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Concurrency Limits: Group defaults]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/21/concurrency-limits-group-defaults/"/>
      <updated>2013-01-21T12:47:07Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=895</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Concurrency limits allow for protecting resources by providing a way to cap the number of jobs requiring a specific resource that can run at one time. For instance, limit licenses and filer access at four regional data centers. Notice the repetition. In addition to the repetition, every license.* and filer.* must be known and recorded [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=895&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Fun with ClassAds]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/fun-with-classads.html"/>
      <updated>2013-01-05T22:58:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1674994974092153801</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Mean of the Modulus Does Not Equal the Modulus of the Mean]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/"/>
      <updated>2013-01-02T15:55:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I've been considering models for the effects of HTCondor negotiation cycle cadence on pool loading and accounting group starvation, which led me to thinking about the effects of taking the modulus of a random variable, for reasons I plan to discuss in future posts. [...]</p>
]]></content>
    </entry>
  
</feed>
