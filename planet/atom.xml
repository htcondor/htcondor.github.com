<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2013-03-26T15:50:57-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[The Impact of Negotiator Cycle Cadence on Slot Loading]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading/"/>
      <updated>2013-03-21T22:10:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_1Introduction.html#8555">HTCondor negotiator</a> assigns jobs (resource requests) to slots (compute resources) at regular intervals, configured by the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#20544">NEGOTIATOR_INTERVAL</a> parameter.  This interval (the cycle <em>cadence</em>) has a fundamental impact on a pool <em>loading factor</em> -- the fraction of time that slots are being productively utilized.</p>

<p>Consider the following diagram, which illustrates the utilization of a slot over the lifetime of a job.  When a job completes, its slot will remain empty until it can be assigned a new job on the next negotiation cycle.</p>

<p><img src="/assets/images/slot_load_study/loading_factor_diagram.png" width="750"></p>

<p>As the diagram above shows, the loading factor for a slot can be expressed as D/Z, where D is the duration of the job, and Z is the total time until the next cycle occurring after the job completes.  We can also write Z = D+I, where I is the "idle time" from job completion to the start of the next negotiation cycle.   Loading factor is always &lt;= 1, where a value of 1 corresponds to ideal loading -- every slot is utilized 100% of the time.  In general, loading will be &lt; 1, as jobs rarely complete exactly on a cycle boundary.</p>

<p>It is worth briefly noting that the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#18202">claim reuse</a> feature was developed to help address this problem.  However, claim re-use is not compatible with all other features -- for example enabling claim re-use can cause accounting group starvation -- and so what follows remains relevant to many HTCondor configurations.</p>

<p>Given a particular negotiation cycle cadence, how does a slot's loading factor behave, as a function of job duration?  The loading factor can be expressed as:</p>

<div markdown="0">
\\[
\\text{Loading Factor} = \\frac{D}{C \\left( q + \\lceil r \\rceil \\right)} \\\\
 \\\\
\\text{where:} \\\\
D = \\text{job duration} \\\\
C = \\text{cycle cadence} \\\\
q = \\lfloor D / C \\rfloor \\\\
r = \\left( D / C \\right) - q \\\\
\\]
</div>


<p>The following plot illustrates how the loading factor changes with job duration, assuming a cadence of 300 seconds (5 minutes):</p>

<p><img src="/assets/images/slot_load_study/load_factor_300s.png" width="750"></p>

<p>We immediately see that there is a saw-tooth pattern to the plot.  As the job duration increases towards the boundary of a cycle, there is less and less idle time until the next cycle, and so the loading approaches 1.0.  However, once the job's end crosses the thresold to <em>just past</em> the start of the cycle, it immediately drops to the worse possible case: the slot will be idle for nearly an entire cycle.</p>

<p>The other important pattern is that the bottom of the saw-tooth gradually increases.  As a job's duration occupies more whole negotiation cycles, the idle time at the end of the last cycle represents a decreasing fraction of the total time.</p>

<p>Observe that the most important 'unit' in this plot is the number of negotiation cycles.  Since the saw-toothing scales with the cycle interval, we can express the same plot in units of cycles instead of seconds:</p>

<p><img src="/assets/images/slot_load_study/load_factor_cu.png" width="750"></p>

<p>The results above suggest a couple possible approaches for tuning negotiator cycle cadence to optimize slot loading in an HTCondor pool.  The first is to configure the negotiator interval to be small relative to a typical job duration, as the lower-bound on loading factor increases with the number of cycles a job's duration occupies.  For example, if a typical job duration is 10 minutes, then a cycle cadence of 60 seconds ensures that in general 9 out of 10 cycles will be fully utilized, and so loading will be around 90%.  However, if one has mostly very short jobs, this can be difficult, as negotiation cycle cadences much less than 60 seconds may risk causing performance problems even on a moderately loaded pool.</p>

<p>A second approach is to try and tune the cadence so that as many jobs as possible complete <em>near the end</em> of a cycle, thus minimizing delay until the next cycle.  For example, if job durations are relatively consistent, say close to 90 seconds, then setting the negotiator interval to something like 50 seconds will induce those jobs to finish near the end of the 2nd negotiation cycle (at t+100 seconds), for a loading factor around 90%.  The caveat here is that job durations are frequently <em>not</em> that consistent, and as job duration spread increases, one's ability to play this game <a href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/">rapidly evaporates</a>.</p>

<p>In this post, I have focused on the behavior of individual jobs and individual slots.  An obvious next question is what happens to aggregate pool loading when job durations are treated as population sampling from random variables, which I plan to explore in future posts.</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Smooth Gradients for Cubic Hermite Splines]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/"/>
      <updated>2013-03-16T14:39:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, ... m_{n-1} \) at knot-points:</p>

<div markdown="0">
\\[
y(t) = h_{00}(t) y_j + h_{10}(t) m_j + h_{01}(t) y_{j+1} + h_{11}(t) m_{j+1} \\\\
\\]
</div>


<p>where the Hermite bases are:</p>

<div markdown="0">
\\[
h_{00} = 2t^3 - 3t^2 + 1 \\\\
h_{10} = t^3 - 2t^2 + t \\\\
h_{01} = -2t^3 + 3t^2 \\\\
h_{11} = t^3 - t^2 \\\\
\\]
</div>


<p>(For now, I will be using the unit-interval form of the interpolation, where t runs from 0 to 1 on each interval.  I will also discuss the non-uniform interval equations below)</p>

<p>This formulation allows one to explicitly specify the interpolation gradient at each knot point, and to choose from various gradient assignment policies, for example <a href="http://en.wikipedia.org/wiki/Cubic_Hermite_spline#Interpolating_a_data_set">those listed here</a>, even supporting policies for <a href="http://en.wikipedia.org/wiki/Monotone_cubic_interpolation">enforcing monotonic interpolations</a>.</p>

<p>One important caveat with cubic Hermite splines is that although the gradient \( y'(t) \) is guaranteed to be continuous, it is <em>not</em> guaranteed to be smooth (that is, differentiable) <em>across</em> the knots (it is of course smooth <em>inside</em> each interval). Therefore, another useful category of gradient policy is to obtain gradients \( m_0, m_1, ... m_{n-1} \) such that \( y'(t) \) is also smooth across knots.</p>

<p>(I feel sure that what follows was long since derived elsewhere, but my attempts to dig the formulation up on the internet failed, and so I decided the derivation might make a useful blog post)</p>

<p>To ensure smooth gradient across knot points, we want the 2nd derivative \( y"(t) \) to be equal at the boundaries of adjacent intervals:</p>

<div markdown="0">
\\[
h_{00}^"(t) y_{j-1} + h_{10}^"(t) m_{j-1} + h_{01}^"(t) y_j + h_{11}^"(t) m_j \\\\
= \\\\
h_{00}^"(t) y_j + h_{10}^"(t) m_j + h_{01}^"(t) y_{j+1} + h_{11}^"(t) m_{j+1}
\\]
</div>


<p>or substituting the 2nd derivative of the basis definitions above:</p>

<div markdown="0">
\\[
\\left( 12 t - 6 \\right) y_{j-1} + \\left( 6 t - 4 \\right) m_{j-1}  + \\left( 6 - 12 t \\right) y_j + \\left( 6 t - 2 \\right) m_j \\\\
= \\\\
\\left( 12 t - 6 \\right) y_{j} + \\left( 6 t - 4 \\right) m_{j}  + \\left( 6 - 12 t \\right) y_{j+1} + \\left( 6 t - 2 \\right) m_{j+1}
\\]
</div>


<p>Observe that t = 1 on the left hand side of this equation, and t = 0 on the right side, and so we have:</p>

<div markdown="0">
\\[
6 y_{j-1} + 2 m_{j-1} - 6 y_j + 4 m_j
=
-6 y_j - 4 m_j + 6 y_{j+1} - 2 m_{j+1}
\\]
</div>


<p>which we can rearrange as:</p>

<div markdown="0">
\\[
2 m_{j-1} + 8 m_j + 2 m_{j+1}
=
6 \\left( y_{j+1} - y_{j-1} \\right)
\\]
</div>


<p>Given n knot points, the above equation holds for j = 1 to n-2 (using zero-based indexing, as nature intended).  Once we define equations for j = 0 and j = n-1, we will have a system of equations to solve.  There are two likely choices.  The first is to simply specify the endpoint gradients \( m_0 = G \) and \( m_{n-1} = H \) directly, which yields the following <a href="http://en.wikipedia.org/wiki/Tridiagonal_matrix_algorithm">tri-diagonal matrix equation:</a></p>

<div markdown="0">
\\[
\\left( \\begin{array} {ccccc}
1 &   &   &   &   \\\\
2 & 8 & 2 &   &   \\\\
  & 2 & 8 & 2 &   \\\\
  &   & \\vdots &   &   \\\\
  &   & 2 & 8 & 2 \\\\ 
  &   &   &   & 1 \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
G \\\\
6 \\left( y_2 - y_0 \\right) \\\\
6 \\left( y_3 - y_1 \\right) \\\\
\\vdots \\\\
6 \\left( y_{n-1} - y_{n-3} \\right) \\\\
H \\\\
\\end{array} \\right)
\\]
</div>


<p>The second common endpoint policy is to set the 2nd derivative equal to zero -- the "natural spline."   Setting the 2nd derivative to zero at the left-end knot (and t = 0) gives us:</p>

<div markdown="0">
\\[
4 m_0 + 2 m_1   =   6 \\left( y_1 - y_0 \\right)
\\]
</div>


<p>Similarly, at the right-end knot (t = 1), we have:</p>

<div markdown="0">
\\[
2 m_0 + 4 m_1   =   6 \\left( y_{n-1} - y_{n-2} \\right)
\\]
</div>


<p>And so for a natural spline endpoint policy the matrix equation looks like this:</p>

<div markdown="0">
\\[
\\left( \\begin{array} {ccccc}
4 & 2 &   &   &   \\\\
2 & 8 & 2 &   &   \\\\
  & 2 & 8 & 2 &   \\\\
  &   & \\vdots &   &   \\\\
  &   & 2 & 8 & 2 \\\\ 
  &   &   & 2 & 4 \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
6 \\left( y_1 - y_0 \\right) \\\\
6 \\left( y_2 - y_0 \\right) \\\\
6 \\left( y_3 - y_1 \\right) \\\\
\\vdots \\\\
6 \\left( y_{n-1} - y_{n-3} \\right) \\\\
6 \\left( y_{n-1} - y_{n-2} \\right) \\\\
\\end{array} \\right)
\\]
</div>


<p>The derivation above is for uniform (and unit) intervals, where t runs from 0 to 1 on each knot interval.  I'll now discuss the variation where knot intervals are non-uniform.   The non-uniform form of the interpolation equation is:</p>

<div markdown="0">
\\[
y(x) = h_{00}(t) y_j + h_{10}(t) d_j m_j + h_{01}(t) y_{j+1} + h_{11}(t) d_j m_{j+1} \\\\
\\text{ } \\\\
\\text{where:} \\\\
\\text{ }  \\\\
d_j = x_{j+1} - x_j \\text{  for  } j = 0, 1, ... n-2 \\\\
t = (x - x_j) / d_j
\\]
</div>


<p>Taking \( t = t(x) \) and applying the chain rule, we see that 2nd derivative equation now looks like:</p>

<div markdown="0">
\\[
y"(x) = \\frac { \\left( 12 t - 6 \\right) y_{j} + \\left( 6 t - 4 \\right) d_j m_{j}  + \\left( 6 - 12 t \\right) y_{j+1} + \\left( 6 t - 2 \\right) d_j m_{j+1} } { d_j^2 }
\\]
</div>


<p>Applying a derivation similar to the above, we find that our (interior) equations look like this:</p>

<div markdown="0">
\\[
\\frac {2} { d_{j-1} }  m_{j-1} + \\left( \\frac {4} { d_{j-1} } + \\frac {4} { d_j } \\right) m_j + \\frac {2} {d_j} m_{j+1}
=
\\frac { 6 \\left( y_{j+1} - y_{j} \\right) } { d_j^2 } + \\frac { 6 \\left( y_{j} - y_{j-1} \\right) } { d_{j-1}^2 }
\\]
</div>


<p>and natural spline endpoint equations are:</p>

<div markdown="0">
\\[
\\text{left:  } \\frac {4} {d_0} m_0 + \\frac {2} {d_0} m_1   =   \\frac {6 \\left( y_1 - y_0 \\right)} {d_0^2} \\\\
\\text{right: } \\frac {2} {d_{n-2}} m_0 + \\frac {4} {d_{n-2}} m_1   =   \\frac {6 \\left( y_{n-1} - y_{n-2} \\right)} {d_{n-2}^2}
\\]
</div>


<p>And so the matrix equation for specified endpoint gradients is:</p>

<div markdown="0">
\\[
\\scriptsize
\\left( \\begin{array} {ccccc}
\\normalsize 1 \\scriptsize &   &   &   &   \\\\
\\frac{2}{d_0} & \\frac{4}{d_0} {+} \\frac{4}{d_1} & \\frac{2}{d_1} &   &   \\\\
  & \\frac{2}{d_1} & \\frac{4}{d_1} {+} \\frac{4}{d_2} & \\frac{2}{d_2} &   \\\\
  &   & \\vdots &   &   \\\\
  &   & \\frac{2}{d_{n-3}} & \\frac{4}{d_{n-3}} {+} \\frac{4}{d_{n-2}} & \\frac{2}{d_{n-2}} \\\\ 
  &   &   &   & \\normalsize 1 \\scriptsize \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
G \\\\
6 \\left( \\frac{y_2 {-} y_1}{d_1^2} {+} \\frac{y_1 {-} y_0}{d_0^2} \\right) \\\\
6 \\left( \\frac{y_3 {-} y_2}{d_2^2} {+} \\frac{y_2 {-} y_1}{d_1^2} \\right)  \\\\
\\vdots \\\\
6 \\left( \\frac{y_{n-1} {-} y_{n-2}}{d_{n-2}^2} {+} \\frac{y_{n-2} {-} y_{n-3}}{d_{n-3}^2} \\right) \\\\
H \\\\
\\end{array} \\right)
\\normalsize
\\]
</div>


<p>And the equation for natural spline endpoints is:</p>

<div markdown="0">
\\[
\\scriptsize
\\left( \\begin{array} {ccccc}
\\frac{4}{d_0} & \\frac{2}{d_0}  &   &   &   \\\\
\\frac {2} {d_0} & \\frac {4} {d_0} {+} \\frac {4} {d_1} & \\frac{2}{d_1} &   &   \\\\
  & \\frac{2}{d_1} & \\frac{4}{d_1} {+} \\frac{4}{d_2} & \\frac{2}{d_2} &   \\\\
  &   & \\vdots &   &   \\\\
  &   & \\frac{2}{d_{n-3}} & \\frac{4}{d_{n-3}} {+} \\frac{4}{d_{n-2}} & \\frac{2}{d_{n-2}} \\\\ 
  &   &   & \\frac{2}{d_{n-2}} & \\frac{4}{d_{n-2}} \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
\\frac{6 \\left( y_1 {-} y_0 \\right)}{d_0^2} \\\\
6 \\left( \\frac{y_2 {-} y_1}{d_1^2}  {+}  \\frac{y_1 {-} y_0}{d_0^2} \\right) \\\\
6 \\left( \\frac{y_3 {-} y_2}{d_2^2}  {+}  \\frac{y_2 {-} y_1}{d_1^2} \\right)  \\\\
\\vdots \\\\
6 \\left( \\frac{y_{n-1} {-} y_{n-2}}{d_{n-2}^2}  {+}  \\frac{y_{n-2} {-} y_{n-3}}{d_{n-3}^2} \\right) \\\\
\\frac{6 \\left( y_{n-1} {-} y_{n-2} \\right)}{d_{n-2}^2} \\\\
\\end{array} \\right)
\\normalsize
\\]
</div>

]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Examining the Modulus of Random Variables]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/"/>
      <updated>2013-03-15T19:03:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h3>Motivation</h3>

<p>The original motivation for these experiments was consideration of the impact of negotiator cycle cadence (i.e. the time between the start of one cycle and the start of the next) on HTCondor pool loading.  Specifically, any HTCondor job that completes and vacates its resource may leave that resource unloaded until it can be re-matched on the next cycle.  Therefore, the duration of resource vacancies (and hence, pool loading) can be thought of as a function of job durations <em>modulo</em> the cadence of the negotiator cycle.  In general, the aggregate behavior of job durations on a pool is useful to model as a random variable.  And so, it seemed worthwhile to build up a little intuition about the behavior of a random variable when you take its modulus.</p>

<h3>Methodology</h3>

<p>I took a Monte Carlo approach to this study because a tractable theoretical framework eluded me, and you do not have to dive very deep to show that <a href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/">even trivial random variable behavior under a modulus is dependent on the distribution</a>.   A Monte Carlo framework for the study also allows for other underlying distributions to be easily studied, by altering the random variable being sampled.   In the interest of getting right into results, I'll briefly discuss the tools I used at the end of this post.</p>

<h3>Modulus and Variance</h3>

<p>Consider what happens to a random variable's modulus as its variance increases.  This sequence of plots shows that the modulus of a normal distribution tends toward a uniform distribution over the modulus interval, as the underlying variance increases:</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.20.png" width="375" height="375">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.30.png" width="375" height="375">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.40.png" width="375" height="375">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.50.png" width="375" height="375">  |</td>
</tr>
</tbody>
</table>


<br>


<p>From the above plots, we can see that in the case of a normal distribution, its modulus tends toward uniform rather quickly - by the time the underlying variance is half of the modulus interval.</p>

<p>The following plots demonstrate the same effect with a one-tailed distribution (the exponential) -- it requires a larger variance for the effect to manifest.</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/exponential_01.png" width="375" height="375">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/exponential_04.png" width="375" height="375">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/exponential_10.png" width="375" height="375">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/exponential_20.png" width="375" height="375">  |</td>
</tr>
</tbody>
</table>


<br>


<p>A third example, using a log-normal distribution.   The variance of the log-normal increases as a function of both \( \mu \) and \( \sigma \).  In this example \( \mu \) is increased systematically, holding \( \sigma \) constant at 1:</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/lognormal_0.0_1.0.png" width="375" height="375">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/lognormal_0.5_1.0.png" width="375" height="375">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/lognormal_1.0_1.0.png" width="375" height="375">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/lognormal_2.0_1.0.png" width="375" height="375">  |</td>
</tr>
</tbody>
</table>


<br>


<p>For a final examination of variance, I will again use log-normals and this time vary \( \sigma \), while holding \( \mu \) constant at 0.  Here we see that the effect of increasing the log-normal variance via \( \sigma \) does <em>not</em> follow the pattern in previous examples -- the distribution does not 'spread' and its modulus does not evolve toward a uniform distribution!</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/lognormal_0.0_0.5.png" width="375" height="375">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/lognormal_0.0_1.0.png" width="375" height="375">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/lognormal_0.0_1.5.png" width="375" height="375">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/lognormal_0.0_2.0.png" width="375" height="375">  |</td>
</tr>
</tbody>
</table>


<br>


<h3>Modulus and Mean</h3>

<p>The following table of plots demonstrates the decreasing effect that a distribution's location (mean) has, as its spread increases and its modulus approaches uniformity.   In fact, we see that <em>any</em> distribution in the 'uniform modulus' parameter region is indistinguishable from any other, with respect to its modulus -- all changes to mean or variance <em>within</em> this region have no affect on the distribution's modulus!</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.0_0.3.png" width="260" height="260">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.5_0.3.png" width="260" height="260">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_1.0_0.3.png" width="260" height="260">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.0_0.4.png" width="260" height="260">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.5_0.4.png" width="260" height="260">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_1.0_0.4.png" width="260" height="260">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.0_0.5.png" width="260" height="260">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_0.5_0.5.png" width="260" height="260">  </td>
<td align="center">  <img src="/assets/images/rv_mod_study/normal_1.0_0.5.png" width="260" height="260">  |</td>
</tr>
</tbody>
</table>


<br>


<h3>Conclusions</h3>

<p>Generally, as the spread of a distribution increases, its modulus tends toward a uniform distribution on the modulus interval.   Although it was tempting to state this in terms of increasing variance, we see from the 2nd log-normal experiment that variance can increase without increasing 'spread' in a way that causes the trend toward uniform modulus.   Currently, I'm not sure what the true invariant is, that properly distinguishes the 2nd log-normal scenario from the others.</p>

<p>For any distribution that <em>does</em> reside in the 'uniform-modulus' parameter space, we see that neither changes to location nor spread (nor even category of distribution) can be distinguished by the distribution modulus.</p>

<h3>Tools</h3>

<p>I used the following software widgets:</p>

<ul>
<li><a href="https://github.com/erikerlandson/condor_tools/blob/cad8773da36fa7f3c60c93895a428d6f1fae6752/bin/rv_modulus_study">rv_modulus_study</a> -- the jig for Monte Carlo sampling of underlying distributions and their corresponding modulus</li>
<li><a href="https://github.com/erikerlandson/dtools/wiki/dplot">dplot</a> -- a simple cli wrapper around <code>matplotlib.pyplot</code> functionality</li>
<li><a href="https://github.com/willb/capricious/">Capricious</a> -- a library for random sampling of various distribution types</li>
<li><a href="https://github.com/erikerlandson/capricious/blob/c8ec13f1f49880bb3573034de59971f84d15f7c1/lib/capricious/spline_distribution.rb">Capricious::SplineDistribution</a> -- a ruby class for estimating PDF and CDF of a distribution from sampled data, using cubic Hermite splines (note, at the time of this writing, I'm using an experimental variation on my personal repo fork, at the link)</li>
</ul>

]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ Paradyn/HTCondor Week 2013 registration open (March 8, 2013)]]></title>
      <link href="http://research.cs.wisc.edu/htcondor/HTCondorWeek2013/"/>
      <updated>2013-03-08T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[We want to invite you to 
HTCondor Week 2013
, our annual HTCondor user conference, in beautiful Madison, WI April 29-May 3, 2013. (HTCondor Week was formerly named Condor Week, matching 
a name change for the software.) We will again host HTCondor Week at the Wisconsin Institutes for Discovery, a state of the art facility for academic and private research specifically designed to foster private and public collaboration. It provides HTCondor Week attendees a compelling environment to attend tutorials and talks from HTCondor developers and users like you. It also provides many comfortable spaces for one-on-one or small group collaborations throughout the week. This year we continue our partnership with the Paradyn Tools Project, making this year Paradyn/HTCondor Week 2013. There will be a full slate of tutorials and talk for both HTCondor and Paradyn.

Our current development series, 7.9, is well underway toward our upcoming production release. When you attend, you will learn how to take advantage of the latest features such as per-job PID namespaces, cgroup enforced resource limits, Python bindings, CPU affinity, BOSCO for submitting jobs to remote batch systems without administrator assistance, EC2 spot instance support, and a variety of speed and memory optimizations. You'll also get a peek into our longer term development plans--something you can only get at HTCondor Week!

We will have a variety of in-depth tutorials, talks, and panels where you can not only learn more about HTCondor, but you can also learn how other people are using and deploying HTCondor. Best of all you can establish contacts and learn best practices from people in industry, government and academia who are using HTCondor to solve hard problems, many of which may be similar to those facing you.

Speaking of learning from the community, we'd love to have you give a talk at HTCondor Week. Talks are 20 minutes long and are a great way share your ideas and get feedback from the community. If you have a compelling use of HTCondor you'd like to share, let Alan De Smet know (adesmet@cs.wisc.edu) and he'll help you out. 

More information on speaking at HTCondor Week is available at the HTCondor Week web site.

You can register, get the hotel details and see the agenda overview on  
the HTCondor Week 2013 site. See you soon in Madison! 
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Running Quantum Espresso on the OSG]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/03/running-quantum-espresso-on-osg.html"/>
      <updated>2013-03-05T18:53:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-2337400839561942722</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[While running Quantum Espresso on the Open Science Grid, we found a number of issues:<br /><ul><li>OpenMPI needs to have an rsh binary. &nbsp;Even if you are using shared memory for openmpi, and openmpi does not use rsh, it still looks for the binary and fails if it cannot find it.</li><li>Chroots (used on HCC machines for grid jobs) do not support pty's. &nbsp;OpenMPI has a compile option to turn off pty support.</li></ul><div>Once these issues where fixed, we were able to submit QE jobs to the OSG using Condor's partitionable slots on 8 cores.</div><div><br /></div><h3>Preparing Submission</h3><div>Before submitting our first QE job, we had to compile OpenMPI and QE. &nbsp;Since we are an HPC center, we had OpenMPI compiled for our Infiniband, therefore it would always fail on the OSG where there is no Infiniband (let alone our brand and drivers).</div><div><br /></div><div>After compiling, we created compressed files that contained the required files to run QE:</div><div><ul><li>bin.tar.gz - Only includes the cp.x file, specific to our run. &nbsp;It could have well included much more common pw.x.</li><li>lib.tar.gz - Includes the Intel math libraries and libgfortran.</li><li>openmpi.tar.gz - Includes the entire openmpi install directory (make install)</li></ul></div><div>Additionally, we wrote a wrapper script, run_espresso_grid.sh, that unpacks the required files and sets the environment.<br /><br /><div class="gistLoad" data-id="5093020" id="gist-5093020"><pre>#!/bin/bash<br />tar xzf bin.tar.gz<br />tar xzf lib.tar.gz<br />tar xzf pseudo.tar.gz<br />tar xzf openmpi.tar.gz<br />mkdir tmp<br /> <br />export PATH=$PWD/bin:$PWD/openmpi/bin:$PATH<br />export LD_LIBRARY_PATH=$PWD/lib:$PWD/openmpi/lib:$LD_LIBRARY_PATH<br />export OPAL_PREFIX=$PWD/openmpi<br /> <br />mpirun --mca orte_rsh_agent `pwd`/rsh -np 8 cp.x &lt; h2o-64-grid.in &gt; h2o-64-grid.out<br /></pre></div><h3>Submission</h3></div><div>We used GlideinWMS to submit to the OSG, below is our HTCondor submit file.</div><div><div class="gistLoad" data-id="5092949" id="gist-5092949"><pre>universe = vanilla<br />output = condor.out.$(CLUSTER).$(PROCESS)<br />error = condor.err.$(CLUSTER).$(PROCESS)<br />log            = condor.log<br />executable = run_espresso_grid.sh<br />request_cpus=8<br />request_memory = 10*1024<br />should_transfer_files = YES<br />when_to_transfer_output = ON_EXIT_OR_EVICT<br />transfer_input_files = bin.tar.gz, lib.tar.gz, pseudo.tar.gz, openmpi.tar.gz, h2o-64-grid.in, /usr/bin/rsh<br />transfer_output_files =h2o-64-grid.out<br />+RequiresWholeMachine=True<br />Requirements = CAN_RUN_WHOLE_MACHINE =?= TRUE<br />queue <br /></pre></div><br /></div><div>Note that we pull rsh from the submission machine. &nbsp;OpenMPI does not actually use rsh to start the processes on a shared memory machine, but it does require that the RSH binary is available.<br /><br /></div><div><h3>Acknowledgments</h3></div><div>This was done with the tremendous help of Jun Wang.</div><div><br /></div><script src="https://raw.github.com/moski/gist-Blogger/master/public/gistLoader.js" type="text/javascript"></script> <br /><center><br /><a href="http://creativecommons.org/licenses/by/3.0/deed.en_US" rel="license"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by/3.0/88x31.png" style="border-width: 0;" /></a><br />This work is licensed under a <a href="http://creativecommons.org/licenses/by/3.0/deed.en_US" rel="license">Creative Commons Attribution 3.0 Unported License</a>. </center>]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Per-Process Mount Namespaces]]></title>
      <link href="http://timothysc.github.com/blog/2013/02/22/perprocess/"/>
      <updated>2013-02-22T16:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/02/22/perprocess</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 7.9.4 released! (February 20, 2013)]]></title>
      <link href="manual/v7.9/9_3Development_Release.html"/>
      <updated>2013-02-20T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 7.9.4.
This release supports per job PID namespaces for Linux RHEL 6, improvements
to the resource usage of the EC2 GAHP, support for capping the size of input
and output file transfer, and new analysis modes for condor_q -analyze.
A complete list of bugs fixed and features can be found in the
Version History. HTCondor 7.9.4 binaries
and source code are available from our Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Statistic changes in HTCondor 7.7]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/12/statistic-changes-in-htcondor-7-7/"/>
      <updated>2013-02-12T11:56:04Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=925</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Notice to HTCondor 7.8 users - Statistics implemented during the 7.5 series that landed in 7.7.0 were rewritten by the time 7.8 was released. If you were using the original statistics for monitoring and/or reporting, here is a table to help you map old (left column) to new (right column). See – 7.6 -&#62; 7.8 [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=925&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Bosco to submit to Amazon EC2]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/02/using-bosco-to-submit-to-amazon-ec2.html"/>
      <updated>2013-02-06T04:27:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-4538100752405939638</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[How accounting group configuration could work with Wallaby]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/05/how-accounting-group-configuration-could-work-with-wallaby/"/>
      <updated>2013-02-05T11:46:28Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=917</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Configuration of accounting groups in HTCondor is too often an expert task that requires coordination between administrators and their tools. Wallaby provides a coordination point, so long as a little convention is employed, and can provide a task specific interface to simplify configuration. Quick background, Wallaby provides semantic configuration for HTCondor. It models a pool [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=917&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Some htcondor-wiki stats]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/29/some-htcondor-wiki-stats/"/>
      <updated>2013-01-29T11:36:06Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=903</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[A few years ago I discovered Web Numbr, a service that will monitor a web page for a number and graph that number over time. I installed a handful of webnumbrs to track things at HTCondor&#8217;s gittrac instance. http://webnumbr.com/search?query=condor Thing such as - Tickets resolved with no destination: tickets that don&#8217;t indicate what version they [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=903&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Introducing the HTCondor-CE]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/introducing-htcondor-ce.html"/>
      <updated>2013-01-28T15:33:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1124494645797252707</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Concurrency Limits: Group defaults]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/21/concurrency-limits-group-defaults/"/>
      <updated>2013-01-21T12:47:07Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=895</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Concurrency limits allow for protecting resources by providing a way to cap the number of jobs requiring a specific resource that can run at one time. For instance, limit licenses and filer access at four regional data centers. Notice the repetition. In addition to the repetition, every license.* and filer.* must be known and recorded [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=895&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bosco 1.1.1 Release]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/01/bosco-111-release.html"/>
      <updated>2013-01-14T18:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1926902995750303001</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Your API is a feature, give it real resource management]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/14/your-api-is-a-feature-give-it-real-resource-management/"/>
      <updated>2013-01-14T12:17:29Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=872</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[So much these days is about distributed resource management. That&#8217;s anything that can be created and destroyed in the cloud[0]. Proper management is especially important when the resource&#8217;s existence is tied to a real economy, e.g. your user&#8217;s credit card[1]. Above is a state machine required to ensure that resources created in AWS EC2 are [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=872&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bosco 1.1 Release]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/01/bosco-11-release.html"/>
      <updated>2013-01-08T23:01:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-2171189043756995217</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Fun with ClassAds]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/fun-with-classads.html"/>
      <updated>2013-01-05T22:58:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1674994974092153801</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Mean of the Modulus Does Not Equal the Modulus of the Mean]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/"/>
      <updated>2013-01-02T15:55:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I've been considering models for the effects of HTCondor negotiation cycle cadence on pool loading and accounting group starvation, which led me to thinking about the effects of taking the modulus of a random variable, for reasons I plan to discuss in future posts. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 7.8.7 released! (December 18, 2012)]]></title>
      <link href="manual/v7.8/9_3Stable_Release.html"/>
      <updated>2012-12-18T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 7.8.7.
This release contains several bug fixes related to grid jobs, including EC2 resource jobs. 
It has bug fixes for glexec, privilege separation, condor_chirp, and a bug that prevented
HTCondor from being stopped on system shutdown on Red Hat Linux systems. A complete list
of bugs fixed can be found in the 
Version History.  HTCondor 7.8.7
and source code are available from our Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Demonstration of Negotiator-Side Resource Consumption]]></title>
      <link href="http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption/"/>
      <updated>2012-12-03T15:25:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>HTCondor supports a notion of aggregate compute resources known as partitionable slots (p-slots), which may be consumed by multiple jobs.   Historically, at most one job could be matched against such a slot in a single negotiation cycle, which limited the rate at which partitionable slot resources could be utilized.  More recently, the scheduler has been enhanced with logic to allow it to acquire multiple claims against a partitionable slot, which increases the p-slot utilization rate. However, as this potentially bypasses the negotiator's accounting of global pool resources such as accounting group quotas and concurrency limits, it places some contraints on what jobs can can safely acquire multiple claims against any particular p-slot: for example, only other jobs on the same scheduler can be considered.  Additionally, candidate job requirements must match the requirements of the job that originally matched in the negotiator.  Another significant impact is that the negotiator is still forced to match an entire p-slot, which may have a large match cost (weight): these large match costs cause <a href="https://htcondor-wiki.cs.wisc.edu/index.cgi/tktview?tn=3013">accounting difficulties</a> when submitter shares and/or group quotas drop below the cost of a slot.  This particular problem is growing steadily larger, as machines with ever-larger numbers of cores and other resources appear in HTCondor pools. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[BOSCO v1.1 Features: Multi-Cluster Support]]></title>
      <link href="http://derekweitzel.blogspot.com/2012/11/bosco-v11-features-multi-cluster-support.html"/>
      <updated>2012-11-29T06:33:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1512416798236467341</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Role enforcement in Cumin]]></title>
      <link href="http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin/"/>
      <updated>2012-11-12T20:20:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Roles in Cumin scope activities and content in the UI.  There are currently two roles defined in Cumin, <code>admin</code> and <code>user</code>.  The <code>admin</code> role is a superset of the <code>user</code> role, and every new account has the <code>user</code> role by default. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Override HTCondor installation with sudo]]></title>
      <link href="http://timothysc.github.com/blog/2012/11/12/condor-sudo/"/>
      <updated>2012-11-12T09:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/11/12/condor-sudo</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Best practices for Wallaby's default group]]></title>
      <link href="http://chapeau.freevariable.com/2012/11/best-practices-for-wallabys-default-group.html"/>
      <updated>2012-11-01T20:14:53Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.38</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Recall that Wallaby applies partial configurations to groups of nodes. Groups can be either explicit —- that is, a named subset of nodes created by the user, or special groups that are built-in to Wallaby; each node’s group memberships have...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Welcome To The HTCondor Project Github Site]]></title>
      <link href="http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site/"/>
      <updated>2012-10-29T20:15:00Z</updated>
      <id>http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site</id>
      <author>
        <name><![CDATA[HTCondor Team GitHub]]></name>
        <uri>http://htcondor.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Welcome to the HTCondor Project GitHub website!  This site is the github web and blog presence for the HTCondor project. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Configuring high-availability Condor central managers with Wallaby]]></title>
      <link href="http://chapeau.freevariable.com/2012/10/configuring-high-availability-condor-central-managers-with-wallaby.html"/>
      <updated>2012-10-23T04:34:58Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.37</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Rob Rati and I gave a tutorial on highly-available job queues at Condor Week this year. While it was not a Wallaby-specific tutorial, we did point out that configuring highly-available job queues is easier for users who manage and deploy...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Cluster Suite's GUI to configure High Availability Schedulers ]]></title>
      <link href="http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers/"/>
      <updated>2012-10-18T17:20:00Z</updated>
      <id>http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In an <a href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/">earlier post</a> I talked about using Cluster Suite
to manage high availability schedulers and referenced the command line tools
available perform the configuration.  I'd like to focus on using the GUI that
is part of Cluster Suite to configure an HA schedd.  It's a pretty simple
process but does require you run a wallaby shell command to complete the
configuration. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Credentials in LDAP URLs when Anonymous Search is Disabled]]></title>
      <link href="http://tmckayus.github.com/blog/2012/10/10/ldap-credentials/"/>
      <updated>2012-10-10T20:55:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/10/10/ldap-credentials</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Cumin authenticates logins against LDAP using a two step process: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Cluster Suite to Manage a High Availability Scheduler]]></title>
      <link href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/"/>
      <updated>2012-09-26T19:53:00Z</updated>
      <id>http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Condor provides simple and easy to configure HA functionality for the schedd
that relies upon shared storage (usually NFS).  The shared store is used to
store the job queue log and coordinate which node is running the schedd.  This
means that each node that can run a particular schedd not only have condor
configured but the node needs to be configured to access the shared storage. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Integrating Cumin with LDAP for Authentication]]></title>
      <link href="http://tmckayus.github.com/blog/2012/09/24/ldap-auth/"/>
      <updated>2012-09-24T16:41:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/09/24/ldap-auth</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Past versions of Cumin have relied on a local database for storing user accounts.  However, that solution adds extra maintenance for site administrators who already have or plan to have a central authentication mechanism for their users.  Consequently, development is ongoing to integrate Cumin with common central auth mechanisms.  LDAP integration is available now, with support for other technologies planned for the future. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[So What is Cumin Anyway?]]></title>
      <link href="http://tmckayus.github.com/blog/2012/09/24/new-post/"/>
      <updated>2012-09-24T16:07:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/09/24/new-post</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Cumin is a Python web UI developed in the Fedora community for managing Condor pools and Qpid messaging brokers.  It is packaged for Fedora but may be run from sources and would probably be easy to port to other Linux distributions (or just run Fedora on a node or two in a heterogeneous environment!)  The current development focus for Cumin is on expanding the Condor management facilities. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Elastic Grid with Condor and oVirt Integration]]></title>
      <link href="http://timothysc.github.com/blog/2012/09/21/condor-n-overt/"/>
      <updated>2012-09-21T08:50:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/09/21/condor-n-overt</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Putting It Together]]></title>
      <link href="http://rrati.github.com/blog/2012/09/18/putting-it-together/"/>
      <updated>2012-09-18T12:59:00Z</updated>
      <id>http://rrati.github.com/blog/2012/09/18/putting-it-together</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Authorization for Wallaby clients]]></title>
      <link href="http://getwallaby.com/2012/09/authorization-for-wallaby-clients/"/>
      <updated>2012-09-12T22:30:00Z</updated>
      <id>http://getwallaby.com/2012/09/authorization-for-wallaby-clients</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways.  This post will explain how the authorization support works and show how to get started using it.  If you just want to get started using Wallaby with authorization support as quickly as possible, skip ahead to the section titled &#8220;Getting Started&#8221; below.  Detailed information about which role is required for each Wallaby API method is <a href="http://getwallaby.com/api-roles/">available here</a>. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Authorization for Wallaby clients]]></title>
      <link href="http://chapeau.freevariable.com/2012/09/authorization-for-wallaby-clients.html"/>
      <updated>2012-09-12T22:23:18Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.36</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways. This post will explain how the authorization support works and show how to...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Dust off nuke it from orbit]]></title>
      <link href="http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit/"/>
      <updated>2012-09-12T09:12:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Highly-available configuration data with Wallaby]]></title>
      <link href="http://chapeau.freevariable.com/2012/08/highly-available-configuration-data-with-wallaby.html"/>
      <updated>2012-08-29T21:03:00Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.35</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Many Condor users are interested in high-availability (HA) services: they don't want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon. (See this talk that Rob Rati and...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Highly-available configuration data with Wallaby]]></title>
      <link href="http://getwallaby.com/2012/08/live-backup/"/>
      <updated>2012-08-29T14:40:00Z</updated>
      <id>http://getwallaby.com/2012/08/live-backup</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Many Condor users are interested in <em>high-availability</em> (HA) services:  they don&#8217;t want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon.  (See <a href="http://research.cs.wisc.edu/condor/CondorWeek2012/presentations/rati-benton-condor-ha.pdf">this talk</a> that Rob Rati and I gave at Condor Week this year for a couple of solutions to HA with the Condor <code>schedd</code>.)  So it&#8217;s only natural that Condor users who are interested in configuring their pools with <a href="http://getwallaby.com">Wallaby</a> might wonder how Wallaby responds in the face of failure. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Wallaby's skeleton group]]></title>
      <link href="http://chapeau.freevariable.com/2012/06/using-wallabys-skeleton-group.html"/>
      <updated>2012-06-15T21:04:21Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.34</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Wallaby 0.15.0 includes a new feature called the skeleton group. (This feature was available in earlier versions of Wallaby, too, but it was experimental and had some rough edges.) Find out how the skeleton group makes configuration more flexible by...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using the skeleton group]]></title>
      <link href="http://getwallaby.com/2012/06/using-the-skeleton-group/"/>
      <updated>2012-06-15T17:46:00Z</updated>
      <id>http://getwallaby.com/2012/06/using-the-skeleton-group</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In Wallaby, Condor nodes are configured by applying <em>features</em> and <em>parameter</em> settings to <em>groups</em>.  In order for the group abstraction to be fully general, <a href="http://getwallaby.com/2011/05/using-wallaby-groups-to-implement-node-tagging/">Wallaby provides two kinds of <em>special groups</em></a>:  the <em>default group</em>, which contains every node (but which is the lowest-priority membership for each node), and a set of <em>identity groups</em>, each of which only contains a single node (and which is always its highest-priority membership, so that special settings applied to a node&#8217;s identity group always take precedence over settings from that node&#8217;s other memberships). [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Troubleshooting Condor with Wallaby]]></title>
      <link href="http://getwallaby.com/2012/06/troubleshooting/"/>
      <updated>2012-06-01T17:27:00Z</updated>
      <id>http://getwallaby.com/2012/06/troubleshooting</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Often, if you&#8217;re trying to reproduce a problem someone else is having with Condor, you&#8217;ll need their configuration.  Likewise, if you&#8217;re trying to help someone reproduce a problem you&#8217;re having, you&#8217;ll want to send along your configuration to aid them in replicating your setup.  For installations that use legacy flat-file configurations (optionally with a local configuration directory), this can be a pain, since you&#8217;ll need to copy several files from site to site (ensuring that you&#8217;ve included all the files necessary to replicate your configuration, perhaps across multiple machines on the site experiencing the problem). [...]</p>
]]></content>
    </entry>
  
</feed>
