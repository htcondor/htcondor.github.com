<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2015-11-19T03:22:08-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.4.2 released! ( November 17, 2015 )]]></title>
      <link href="manual/v8.4.2/10_3Stable_Release.html"/>
      <updated>2015-11-17T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.4.2.
A stable series release contains significant bug fixes.

Highlights of this release are:
a bug fix to prevent the condor_schedd from crashing;
a bug fix to honor TCP_FORWARDING_HOST;
Standard Universe works properly in RPM installations of HTCondor;
the RPM packages no longer claim to provide Globus libraries;
bug fixes to DAGMan's "maximum idle jobs" throttle;
several other bug fixes, consult the version history.


Further details can be found in the
Version History.
HTCondor 8.4.2 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Concrete advice about abstracts]]></title>
      <link href="http://chapeau.freevariable.com/2015/11/concrete-advice-about-abstracts.html"/>
      <updated>2015-11-16T15:43:49Z</updated>
      <id>http://chapeau.freevariable.com/2015/11/concrete-advice-about-abstracts</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Consider the following hypothetical conference session abstract:</p>

<blockquote><p>Much like major oral surgery, writing talk abstracts is universally acknowledged as difficult and painful.  This has never been more true than it is now, in our age of ubiquitous containerization technology.  Today&rsquo;s aggressively overprovisioned, multi-track conferences provide high-throughput information transfer in minimal venue space, but do so at a cost:  namely, they impose stingy abstract word limits.  The increasing prevalence of novel &ldquo;lightning talk&rdquo; tracks presents new challenges for aspiring presenters.  Indeed, the time it takes to read a lightning talk abstract may be a substantial fraction of the time it takes to deliver the talk!  The confluence of these factors, <em>inter alia</em>, presents an increasingly hostile environment for conference talk submissions in late 2015.  Your talk proposals must adapt to this changing landscape or face rejection.  Is there a solution?</p></blockquote>

<p>Hopefully, you recognize some key elements of subpar abstracts that you&rsquo;ve seen, reviewed, or &mdash; maybe, alas &mdash; even submitted in this example.</p>

<p>To identify what&rsquo;s <em>fundamentally</em> wrong with it, we should first consider what the primary rhetorical aims for an abstract are.  In particular, an abstract needs to</p>

<ol>
<li><em>provide context</em> so that a general audience can understand that the problem the talk addresses is interesting,</li>
<li><em>summarize</em> the content of a talk so that audiences and reviewers know what to expect, and</li>
<li><em>motivate</em> conference attendees to put the talk on their schedule (and, more immediately, motivate the program committee to accept the talk).</li>
</ol>


<p>The abstract above does none of these things, for both stylistic and structural reasons.</p>

<p>The example abstract&rsquo;s prose is generally clunky, but the main stylistic problem is its overuse of jargon and enthymemes.  If you don&rsquo;t already spend time in the same neighborhoods of the practice as the author, you probably don&rsquo;t understand all of these terms to mean the same things that the author does or agree with his or her sense of what is &ldquo;universally acknowledged.&rdquo;  It is easy to fall in to using jargon when you&rsquo;re deep in a particular problem domain:  after all, most of the people you interact with use these words and you all seem to understand each other.  However, jargon terms are essentially content-free:  they convey nothing new to specialists and are completely opaque to novices.  By propping up your writing on these empty terms instead of explaining yourself, you are excluding the cohort of your audience who doesn&rsquo;t already understand your problem and shamelessly pandering to the cohort that does.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>The main structural problem with the example abstract is that it doesn&rsquo;t actually make an argument for why the talk is interesting or worth attending; instead, it focuses on emphasizing the problems faced by abstract writers and ends with a cliffhanger.  (The cliffhanger strategy not only adds no additional content, it is also <a href="https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines">especially risky</a>.)  A surprising number of abstracts, even accepted ones, suffer because they focus on only one or two of an abstract&rsquo;s responsibilities, but it is possible to set your abstract up for success by starting from a structure that is designed to cover all of the abstract&rsquo;s responsibilities.</p>

<p>In 1993, <a href="https://plg.uwaterloo.ca/~migod/research/beckOOPSLA.html">Kent Beck appeared on a panel</a> on how to get a paper accepted at OOPSLA.  OOPSLA (now called <a href="http://2015.splashcon.org">SPLASH</a>) was an academic conference on research and development related to object-oriented programming languages, systems and environments to support object-oriented programming, and applications developed using these technologies.  This is a particularly broad mandate, and because OOPSLA attracted so many papers on a wide range of topics, it had an extremely low acceptance rate.  (This is probably why they held a panel on getting papers accepted, but it also makes OOPSLA a good analogy for contemporary practice-focused technical conferences that often cross several areas of specialization, e.g., data processing, distributed computing, and machine learning.)</p>

<p>Beck&rsquo;s advice is worth reading even if you aren&rsquo;t writing an academic conference paper.  In particular, he suggests that you start by identifying a single &ldquo;startling sentence&rdquo; that summarizes your work and can grab the attention of the program committee.  From there, Beck advises that you adopt the following four-sentence model to structure your abstract:</p>

<ol>
<li>The first sentence is the problem you&rsquo;re trying to solve,</li>
<li>The second sentence provides context for the problem or explains its impact,</li>
<li>The third sentence is the &ldquo;startling sentence&rdquo; that is the key insight or contribution of your work, and</li>
<li>The fourth sentence shows how the key contribution of your work affects the problem.</li>
</ol>


<p>I&rsquo;ve used this template in almost every abstract I&rsquo;ve written for many years, although I sometimes devote more than a single sentence to each step.  It has successfully helped me refine abstracts for both industry conference talks and academic papers, and it more or less ensures that each abstract accomplishes what it needs to.  (If you&rsquo;re writing a talk abstract, as opposed to a paper abstract, it&rsquo;s sometimes also a good idea to add a sentence or two covering what the audience should expect to take away from your talk and why you&rsquo;re qualified to give it.)  If I am sure to consider my audience &mdash; first, an overworked program committee member, and second, a jetlagged and overstimulated conference attendee &mdash; I am far more likely to explain things clearly and eschew jargon.  As a bonus, starting from a fairly rigid structure frees me from wasting time worrying about how best to arrange my prose.</p>

<p>If we avoid jargon and start from Beck&rsquo;s structure, we can transform the mediocre example abstract from the beginning of this post into something far more effective:</p>

<blockquote><p> Contemporary multiple-track industry conferences attract speakers and attendees who specialize in distinct but related parts of the practice.  Since many authors adopt ineffective patterns from other technical abstracts they&rsquo;ve read, they may unwittingly submit talk proposals that are at best rhetorically impotent and at worst nonsensical to people who don&rsquo;t share their specialization.  By starting from a simple template, prospective speakers can dramatically improve their chances of being understood, accepted, and attended, while also streamlining the abstract-writing process.  Excellent abstracts benefit the entire community, because more people will be motivated to learn about interesting work that is outside of their immediate area of expertise.  In this talk, delivered by someone who has delivered many talks without any serious train wrecks and has also helped other people get talks accepted, you&rsquo;ll learn a straightforward technique for designing abstracts that communicate effectively to a general audience, sell your talk to the program committee, and motivate your peers to attend your talk.</p></blockquote>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>See also <a href="http://www.cs.cmu.edu/~jrs/sins.html">Jonathan Shewchuk on &ldquo;grandmothering&rdquo;</a> or <a href="http://www.exampler.com/testing-com/writings/final-vocabulary.html">Brian Marick on Rorty&rsquo;s concept of &ldquo;final vocabulary.&rdquo;</a><a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.4.1 released! ( October 27, 2015 )]]></title>
      <link href="manual/v8.4.1/10_3Stable_Release.html"/>
      <updated>2015-10-27T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.4.1.
A stable series release contains significant bug fixes.  This release
contains all of the bug fixes from the recent HTCondor 8.2.10 release.

Highlights of this release are:
four new policy metaknobs to make configuration easier;
a bug fix to prevent condor daemons from crashing on reconfiguration;
an option natural sorting option on condor_status;
support of admin to mount certain directories into Docker containers;
many other bug fixes, consult the version history.

Further details can be found in the
Version History.
HTCondor 8.4.1 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.2.10 released! ( October 22, 2015 )]]></title>
      <link href="manual/v8.2.10/10_3Stable_Release.html"/>
      <updated>2015-10-22T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.2.10.
A stable series release contains significant bug fixes.

Highlights of this release are:
an updated RPM to work with SELinux on EL7 platforms;
fixes to the condor_kbdd authentication to the X server;
a fix to allow the condor_kbdd to work with shared port enabled;
avoid crashes when using more than 1024 file descriptors on EL7;
fixed a memory leak in the ClassAd split() function;
condor_vacate will error out rather than ignore conflicting arguments;
a bug fix to the JobRouter to properly process the queue on restart;
a bug fix to prevent sending spurious data on a SOAP file transfer;
a bug fix to always present jobs in order in condor_history.

A complete list of fixed bugs can be found in the
Version History.
HTCondor 8.2.10 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Pacing technical talks]]></title>
      <link href="http://chapeau.freevariable.com/2015/10/pacing-technical-talks.html"/>
      <updated>2015-10-21T16:17:01Z</updated>
      <id>http://chapeau.freevariable.com/2015/10/pacing-technical-talks</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Delivering a technical talk has a lot in common with running a half-marathon or biking a 40k time trial.  You&rsquo;re excited and maybe a little nervous, you&rsquo;re prepared to go relatively hard for a relatively long time, and you&rsquo;re acutely aware of the clock.  In both situations, you might be tempted to take off right from the gun, diving into your hardest effort (or most technical material), but this is a bad strategy.</p>

<p>By going out too hard in the half-marathon, you&rsquo;ll be running on adrenaline instead of on your aerobic metabolism, will burn matches by working hard before warming up fully, and ultimately won&rsquo;t be able to maintain your best possible pace because you&rsquo;ll be spent by the second half of the race.  Similarly, in the talk, your impulse might be to get right to the most elegant and intricate parts of your work immediately after introducing yourself, but if you get there without warming up the audience first, you&rsquo;ll lose most of them along the way.  In both cases, your perception of what you&rsquo;re doing is warped by energy and nerves; the <em>right</em> pace will feel sluggish and awkward; and starting too fast will put you in a hole that will be nearly impossible to recover from.</p>

<p>Delivering a technical talk successfully has a lot in common with choosing an appropriate pacing strategy for an endurance event:  <a href="http://www.runnersworld.com/ask-coach-jenny/how-to-pace-your-first-half-or-full-marathon">by starting out slower than you think you need to, you&rsquo;ll be able to go faster at the end</a>.  Most runners<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> will be able to maintain a higher average pace by doing <a href="https://en.wikipedia.org/wiki/Negative_split">negative splits</a>.  In a race, this means you start out slower than your desired average pace and gradually ramp up over the course of the race so that by the end, you&rsquo;re going faster than your desired average pace.  By starting out easy, your cardiovascular system will warm up, your connective tissue will get used to the stress of pounding on the pavement, and your muscles will start buffering lactic acid; this will reduce muscle fatigue and save your anaerobic energy for the final sprint.</p>

<p>You can apply the general strategy of negative splits to a talk as well.  Instead of warming up cold muscles and your aerobic energy systems before making them work, you&rsquo;re preparing a group of smart people to learn why they should care about your topic before making them think about it too much.  Start off slow:  provide background, context, and examples.  Unless you&rsquo;re a very experienced speaker, this will feel agonizingly slow at first.</p>

<p>It&rsquo;s understandable that it might feel remedial and boring to you to explain why your work is relevant.  After all, you&rsquo;re deep in your topic and have probably long since forgotten what it was like to learn about it for the first time.  Examples and visual explanations might seem like a waste of time before you get to your clever implementation, elegant proof, or sophisticated model.  You have some <em>serious detail</em> to cover, after all!  Your audience, however, isn&rsquo;t prepared for that detail yet.  If you skip the warm-up and go straight to that detail, you&rsquo;ll lose audience engagement, and it&rsquo;s nearly impossible to recover from that; it&rsquo;ll certainly prevent you from covering as much as you might have otherwise wanted to.</p>

<p>Remember that your audience is made up of smart people who chose to attend your talk instead of sitting out in the hall.  They&rsquo;d probably rather be learning something from you than halfheartedly reading email.  But they also almost certainly don&rsquo;t know as much about your topic as you do.  Ease them in to it, warm them up, and give them plenty of context first.  You&rsquo;ll be able to cover more ground that way.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Pacing in cycling time trials can be a little more complicated depending on the terrain and wind but in general being able to finish stronger than you started is still desirable.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Notes from Flink Forward]]></title>
      <link href="http://chapeau.freevariable.com/2015/10/notes-from-flink-forward.html"/>
      <updated>2015-10-20T15:48:44Z</updated>
      <id>http://chapeau.freevariable.com/2015/10/notes-from-flink-forward</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/willb/22238437291/in/dateposted-public/" title="Brandenburger Tor lightshow"><img src="https://farm1.staticflickr.com/739/22238437291_22636e4a72_b.jpg" width="1024" height="819" alt="Brandenburger Tor lightshow"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>I was in Berlin last week for <a href="http://flink-forward.org">Flink Forward</a>, the inaugural Apache Flink conference.  I&rsquo;m still learning about Flink, and Flink Forward was a great place to learn more.  In this post, I&rsquo;ll share some of what I consider its coolest features and highlight some of the talks I especially enjoyed.  Videos of the talks should all be online soon, so you&rsquo;ll be able to check them out as well.</p>

<h2>Background</h2>

<p>Apache Flink is a data processing framework for the JVM that is most popular for streaming workloads with high throughput and low latency, although it is also general enough to support batch processing.  Flink has a pleasant collection-style API, offers stateful elementwise transformations on streams (think of a <code>fold</code> function), can be configured to support fault-tolerance with exactly-once delivery, and does all of this while achieving extremely high performance.  Flink is especially attractive for use in contemporary multitenant environments because it manages its own memory and thus Flink jobs can run well in containers on overprovisioned systems (where CPU cycles may be relatively abundant but memory may be strictly constrained).</p>

<h2>Keynotes and lightning talks</h2>

<p>Kostas Tzoumas and Stephan Ewan (both of data Artisans) shared a keynote in which they presented the advancements in Flink 0.10 (to be released soon) and shared the roadmap for the next release, which will be Flink 1.0.  The most interesting parts of this keynote for me were the <a href="http://data-artisans.com/batch-is-a-special-case-of-streaming/">philosophical arguments for the generality and importance of stream processing in contemporary event-driven data applications</a>.  Many users of batch-processing systems simulate streaming workflows by explicitly encoding windows in the structure of their input data (e.g., by using one physical file or directory to correspond to a day, month, or year worth of records) or by using various workarounds inspired by technical limitations (e.g., the &ldquo;lambda architecture&rdquo; or bespoke but narrowly-applicable stream processors).  However, mature stream processing frameworks not only enable a wide range of applications that process live events, but they also are general enough to handle batch workloads as a special case (i.e., by processing a stream with only one window).<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>Of course, the workarounds that data engineers have had to adopt to handle streaming data in batch systems are only necessary given an absence of mature stream processing frameworks.  The streaming space has improved a great deal recently, and this talk gave a clear argument that Flink was mature enough for demanding and complex applications.  Flink offers a flexible treatment of time: events can be processed immediately (one at a time), in windows based on when the events arrived at the processor, or in windows based on when the events were actually generated (even if they arrived out of order).  Flink supports failure recovery with exactly-once delivery but also offers extremely high throughput and low latency:  a basic Flink stream processing application offers two orders of magnitude more throughput than an equivalent Storm application.  Flink also provides a batch-oriented API with a collection-style interface and an optimizing query planner.</p>

<p>After the keynote, there were several lightning talks.  Lightning talks at many events are self-contained (and often speculative, provocative, or describing promising work in progress).  However, these lightning talks were abbreviated versions of talks on the regular program.  In essence, they were ads for talks to see later (think of how academic CS conference talks are really ads for papers to read later).  This was a cool idea and definitely helped me navigate a two-track program that was full of interesting abstracts.</p>

<h2>Everyday Flink</h2>

<p>Michael Häusler of ResearchGate gave a talk in which he talked about the process of evaluating new data processing frameworks, focusing in particular on determining whether a framework makes simple tasks simple.  (Another step, following Alan Kay&rsquo;s famous formulation, is determining whether or not a framework makes complex tasks possible.)  The &ldquo;simple task&rdquo; that Häusler set out to solve was finding the top 5 coauthors for every author in a database of publications; he implemented this task in Hive (running on Tez), Hadoop MapReduce, and Flink.  Careful readers will note that this is not really a fair fight:  SQL and HiveQL do not admit straightforward implementations of top-<em>k</em> queries and MapReduce applications are not known for elegant and terse codebases; indeed, Häusler acknowledged as much.  However, it was still impressive to see how little code was necessary to solve this problem with Flink, especially when contrasted with the boilerplate of MapReduce or all of the machinery to implement a user-defined aggregate function to support top-<em>k</em> in Hive.  The Flink solution was also twice as fast as the custom MapReduce implementation, which was in turn faster than Hive on Tez.</p>

<h2>Declarative Machine Learning with the Samsara DSL</h2>

<p>Sebastian Schelter introduced Samsara, a DSL for machine learning and linear algebra.  Samsara supports in-memory vectors (both dense and sparse), in-memory matrices, and distributed row matrices, and provides an R-like syntax embedded in Scala for operations.  The distributed row matrices are a unique feature of Samsara; they support only a subset of matrix operations (i.e., ones that admit efficient distributed implementations) and go through a process of algebraic optimization (including generating logical and physical plans) to minimize communication during execution.  Samsara can target Flink, Spark, and H2O.</p>

<h2>Streaming and parallel decision trees in Flink</h2>

<p>Training decision trees in batch frameworks requires a view of the entire learning set (and sufficient training data to generate a useful tree).  In streaming applications, each event is seen only once, the classifier must be available immediately (even if there is little data to train on) and the classifier should take feedback into account in real time.  In this talk, Anwar Rizal of Amadeus presented a technique for training decision trees on streaming data by building and aggregating approximate histograms for incoming features and labels.</p>

<h2>Juggling with bits and bytes &mdash; how Apache Flink operates on binary data</h2>

<p>Applications using the Java heap often exhibit appalling memory efficiency; the heap footprint of Java library data structures can be <a href="https://www.cs.virginia.edu/kim/publicity/pldi09tutorials/memory-efficient-java-tutorial.pdf">75% overhead or more</a>.  Since data processing applications frequently create, manipulate, and serialize many objects &mdash; some of which may be quite short-lived &mdash; there are potentially significant performance pitfalls to using the JVM directly for memory allocation.  In this talk, Fabian Hueske of data Artisans presented Flink&rsquo;s approach:  combining a custom memory-management and serialization stack with algorithms that operate directly on compressed data.  Flink jobs are thus more memory-efficient than programs that use the Java heap directly, exhibit predictable space usage, and handle running out of memory gracefully by spilling intermediate results to disk.  In addition, Flink&rsquo;s use of database-style algorithms to sort, filter, and join compressed data reduces computation and communication costs.</p>

<h2>Stateful Stream Processing</h2>

<p>Data processing frameworks like Flink and Spark support collection-style APIs where distributed collections or streams can be processed with operations like <code>map</code>, <code>filter</code>, and so on.  In addition to these, it is useful to support transformations that include <em>state</em>, analogously to the <code>fold</code> function on local collections.  Of course, <code>fold</code> by itself is fairly straightforward, but a reliable <code>fold</code>-style operation that can recover in the face of worker failures is more interesting.  In this talk, Márton Balassi and Gábor Hermann presented an overview of several different approaches to supporting reliable stream processing with state:  the approaches used by Flink (both versions 0.9.1 and 0.10), Spark Streaming, Samza, and Trident.  As one might imagine, Spark Streaming and Samza get a lot of mileage out of delegating to underlying models (immutable RDDs in Spark&rsquo;s case and a reliable unified log in Samza&rsquo;s).  Flink&rsquo;s approach of using distributed snapshots exhibits good performance and enables exactly-once semantics, but it also seems simpler to use than alternatives.  This has become a recurring theme in my investigation of Flink:  technical decisions that are advertised as improving performance (latency, throughput, etc.) also, by happy coincidence, admit a more elegant programming model.</p>

<h2>Fault-tolerance and job recovery in Apache Flink</h2>

<p>This talk was an apt chaser for the Stateful Stream Processing talk.  Till Rohrmann presented Flink&rsquo;s approaches to checkpointing and recovery, showing how Flink can be configured to support at-most-once delivery (the weakest guarantee), at-least-once delivery, or exactly-once delivery (the strongest guarantee).  The basic approach Flink uses for checkpointing operator state is the <a href="https://en.wikipedia.org/wiki/Snapshot_algorithm">Chandy-Lamport snapshot algorithm</a>, which enables consistent distributed snapshots in a way that is transparent to the application programmer.  This approach also enables configurable tradeoffs between throughput and snapshot interval, but it&rsquo;s far faster (and nicer to use) than Storm&rsquo;s approach in any case.  Recovering operator state is only part of the fault-tolerance picture, though; Till&rsquo;s talk also introduced Flink&rsquo;s approach for supporting a highly-available Job Manager.</p>

<h2>Other talks worth checking out</h2>

<p>Here are a few talks that I&rsquo;d like to briefly call out as worth watching:</p>

<ul>
<li><a href="http://flink-forward.org/?session=automatic-detection-of-web-trackers-at-telefonica-research">&ldquo;Automatic detection of web trackers&rdquo;</a>, presented by Vasia Kalavri, was a cool application of graph processing in Flink.</li>
<li><a href="http://flink-forward.org/?session=applying-kappa-architecture-in-the-telecom-industry">&ldquo;Applying Kappa architecture in the telecom industry&rdquo;</a>, presented by Ignacio Mulas Viela, showed how to put a realistic streaming topology into production.</li>
<li>In <a href="http://flink-forward.org/?session=a-tale-of-squirrels-and-storms">&ldquo;A tale of squirrels and storms&rdquo;</a>, Matthias Sax introduced the Storm compatibility layer for Flink, enabling users to run Storm topologies on Flink with minimal code changes.</li>
<li><a href="http://flink-forward.org/?session=notions-of-time-how-apache-flink-handles-time-and-windows">Aljoscha Krettek&rsquo;s talk</a> covered the different approaches Flink supports for defining windows over streams.</li>
<li>My colleague <a href="https://www.flickr.com/photos/willb/22227982835/">Suneel Marthi</a> presented on a <a href="http://flink-forward.org/?session=tbd-3">Flink port of the BigPetStore big data application blueprints</a>.</li>
</ul>


<h2>General notes</h2>

<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/willb/22322707802/in/dateposted-public/" title="Kulturbrauerei"><img src="https://farm1.staticflickr.com/771/22322707802_8b4fa7662e_b.jpg" width="1024" height="820" alt="Kulturbrauerei"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>The data Artisans team and the Flink community clearly put a lot of hard work towards making this a really successful conference.  The <a href="https://en.wikipedia.org/wiki/Kulturbrauerei">venue</a> (pictured above) was unique and cool, the overall vibe was friendly and technical, and I didn&rsquo;t see a single talk that I regretted attending.  (This is high praise indeed for a technical conference; I may have been lucky, but I suspect it&rsquo;s more likely that the committee picked a good program.)  I especially appreciated the depth of technical detail in the talks by Flink contributors on the second afternoon, covering both design tradeoffs and implementation decisions.  I&rsquo;m hoping to be back for a future iteration.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Indeed, <a href="http://flink-forward.org/?session=stream-and-batch-processing-in-one-system-apache-flinks-streaming-data-flow-engine">as we saw later in the conference</a>, the difference between &ldquo;batch&rdquo; workloads and &ldquo;streaming&rdquo; workloads can be as simple as a set of policy decisions by the scheduler.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.5.0 released! ( October 12, 2015 )]]></title>
      <link href="manual/v8.5.0/10_3Development_Release.html"/>
      <updated>2015-10-12T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.5.0.
This development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.4.0
stable release.

Enhancements in the release include:
multiple enhancements to the python bindings;
the condor_schedd no longer changes the ownership of spooled job files;
spooled job files are visible to only the user account by default;
the condor_startd records when jobs are evicted by preemption or draining.

Further details can be found in the
Version History.
HTCondor 8.5.0 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Library of Binary Tree Algorithms as Mixable Scala Traits]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/"/>
      <updated>2015-09-26T19:43:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I am going to describe some work I've done recently on a system of Scala traits that support tree-based collection algorithms prefix-sum, nearest key query and value increment in a mixable format, all backed by Red-Black balanced tree logic, which is also a fully inheritable trait. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.4.0 released! ( September 14, 2015 )]]></title>
      <link href="manual/v8.4.0/10_3Stable_Release.html"/>
      <updated>2015-09-14T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor version 8.4.0.
After a year of development, this is the first release of the new stable series.

This version contains:
a Docker Universe to run a Docker container as an HTCondor job;
the submit file can queue a job for each file found;
the submit file can contain macros;
a dry-run option to condor_submit to test the submit file without any actions;
HTCondor pools can use IPv4 and IPv6 simultaneously;
execute directories can be encrypted upon user or administrator request;
Vanilla Universe jobs can utilize periodic application-level checkpoints;
the administrator can establish job requirements;
numerous scalability changes.

Further details can be found in the
Version History.
HTCondor 8.4.0 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Lightweight Non-Negative Numerics for Better Scala Type Signatures]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/"/>
      <updated>2015-08-19T00:42:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I want to discuss several advantages of defining lightweight non-negative numeric types in Scala, whose primary benefit is that they allow improved type signatures for Scala functions and methods.  I'll first describe the simple class definition, and then demonstrate how it can be used in function signatures and the benefits of doing so. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Reservoir Sampling Gap Distribution]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution/"/>
      <updated>2015-08-17T14:35:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2014/09/11/faster-random-samples-with-gap-sampling/">previous post</a>, I showed that random Bernoulli and Poisson sampling could be made much faster by modeling the <em>sampling gap distribution</em> - that is, directly drawing random samples from the distribution of how many elements would be skipped over between actual samples taken. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Generalizing Kendall's Tau]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/14/generalizing-kendalls-tau/"/>
      <updated>2015-08-14T21:35:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/14/generalizing-kendalls-tau</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Recently I have been applying <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient">Kendall's Tau</a> as an evaluation metric to assess how well a regression model ranks input samples, with respect to a known correct ranking. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[GPUs and adding new resources types to the HTCondor-CE]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/08/gpus-and-adding-new-resources-types-to.html"/>
      <updated>2015-08-07T21:45:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-6301136022425730449</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The more things change, the more they stay the same]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/07/the-more-things-change-more-they-stay.html"/>
      <updated>2015-07-28T15:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-8394942129716842708</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[fedmsg talk at Spark Summit]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/summit-fedmsg.html"/>
      <updated>2015-06-15T15:05:27Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/summit-fedmsg</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I&rsquo;m speaking at Spark Summit today about using Spark to analyze operational data from the Fedora project.  Here are some links to further resources related to my talk: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Spark ML Pipeline transformers]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers.html"/>
      <updated>2015-06-14T00:07:58Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post, we&rsquo;ll see how to make a simple transformer for <a href="https://spark.apache.org/docs/latest/ml-guide.html">Spark ML Pipelines</a>.  The transformer we&rsquo;ll design will generate a sparse binary feature vector from an array-valued field representing a set. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Parallel K-Medoids Using Scala ParSeq]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/"/>
      <updated>2015-05-06T23:33:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Scala supplies a <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections library</a> that was designed to make it easy for a programmer to add parallel computing over the elements in a collection.  In this post, I will describe a case study of applying Scala's parallel collections to cleanly implement multithreading support for training a K-Medoids clustering model. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[HTCondor CacheD: Caching for HTC - Part 2]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/htcondor-cached-caching-for-htc-part-2.html"/>
      <updated>2015-01-25T15:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-5260378956420164105</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Condor CacheD: Caching for HTC - Part 1]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/condor-cached-caching-for-htc-part-1.html"/>
      <updated>2015-01-22T16:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1889975382858537261</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
</feed>
