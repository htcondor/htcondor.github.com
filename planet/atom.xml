<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2013-04-20T05:38:20-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[Installing Spark on Fedora 18]]></title>
      <link href="http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html"/>
      <updated>2013-04-11T21:37:28Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.39</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[
        <p>The <a href="http://spark-project.org">Spark</a> project is an actively-developed open-source engine for data analytics on clusters using Scala, Python, or Java.  It offers map, filter, and reduce operations over in-memory collections, data from local files, or data taken from HDFS, but unlike standard map-reduce frameworks, it offers the opportunity to cache intermediate results across the cluster (and can thus offer orders-of-magnitude improvements over standard map-reduce when implementing iterative algorithms).  I&#8217;ve been using it lately and have been really impressed.  However &#8212; as with many cool projects in the &#8220;big data&#8221; space &#8212; the chain of dependencies to get a working installation can be daunting.</p>

<p>In this post, we&#8217;ll walk through setting up Spark to run on a stock Fedora 18 installation.  We&#8217;ll also build the Mesos cluster manager so that we can run Spark jobs under Mesos, and we&#8217;ll build Hadoop with support for Mesos (so that we&#8217;ll have the option to run standard Hadoop MapReduce jobs under Mesos as well).  By following these steps, you should be up and running with Spark quickly and painlessly.</p>

        <h3>Preliminary steps</h3>

<p>You&#8217;ll first need to install some packages so that you&#8217;ll have all of the build dependencies for the packages you&#8217;ll want to install.  You may have some of these already installed, depending on what Fedora installation type you&#8217;ve used and what packages you&#8217;ve already installed, but this list should cover bringing you from a minimal Fedora installation to one that can support building Mesos, Hadoop, and Spark.</p>

<p>First, we&#8217;ll install some essential tools that might not already be on your system:</p>

<pre><code>sudo yum install -y git wget patch tar autoconf automake autotools libtool bzip2
</code></pre>

<p>Then, we&#8217;ll install some compilers, language environments, build tools, and support libraries:</p>

<pre><code>sudo yum install -y gcc gcc-c++ python scala
sudo yum install -y java-devel python-devel zlib-devel libcurl-devel openssl-devel
sudo yum install -y ant maven maven2
</code></pre>

<p>We should now have all of the dependencies installed to build Mesos, Hadoop, and Spark.</p>

<h3>Building Mesos</h3>

<p>Set <code>JAVA_HOME</code> in your environment:</p>

<pre><code>export JAVA_HOME=/usr/lib/jvm/java-1.7.0/
</code></pre>

<p>Then create a working directory and clone the Mesos source repository.  This will take a little while, since it&#8217;s a large (~180mb) repository:</p>

<pre><code>mkdir ~/build
cd ~/build
git clone https://github.com/apache/mesos.git
</code></pre>

<p>We&#8217;re going to be working from the <code>0.12.x</code> branch of the Mesos repository.  Check that out:</p>

<pre><code>cd mesos
git checkout 0.12.x
</code></pre>

<p>Now we can actually build Mesos:</p>

<pre><code>./bootstrap
./configure --with-webui --with-included-zookeeper --disable-perftools
make &amp;&amp; sudo make install
</code></pre>

<h3>Building and running Hadoop</h3>

<p>You can run Spark jobs under Mesos without using Hadoop at all, and Spark running under Mesos can get data from HDFS even if the HDFS service isn&#8217;t itself running under Mesos.  However, in order to run Hadoop MapReduce jobs under Mesos, we&#8217;ll need to build a patched version of Hadoop.  If you already have Hadoop installed and running and are interested simply in running Spark against data in HDFS, you can skip this step, but if you don&#8217;t have Hadoop installed, installing it this way is simple and will give you greater flexibility in the future.</p>

<p>Building the patched Hadoop is straightforward, since patches and build scripts are bundled with Mesos.  Simply run the following command from within your <code>mesos</code> directory and follow the prompts:</p>

<pre><code>./hadoop/TUTORIAL.sh
</code></pre>

<p>It will explain what it is doing while downloading, patching, and building Hadoop.  It will then run an example Hadoop MapReduce job to make sure everything is working properly and remind you that you&#8217;ll need to make changes to the MapReduce configuration before running MapReduce jobs on your Mesos cluster.  Since we aren&#8217;t going to be running Hadoop MapReduce jobs under Mesos right away, we&#8217;ll skip that step for now.  However, we will be making some minor configuration changes.</p>

<p>First, while you&#8217;re still in the <code>mesos</code> directory, change to the directory where you built your patched Hadoop:</p>

<pre><code>cd hadoop/hadoop-0.20.205.0/
</code></pre>

<p>Then edit <code>conf/hadoop-env.sh</code> with your favorite editor, replacing the commented-out line that sets <code>JAVA_HOME</code> with the following:</p>

<pre><code>export JAVA_HOME=/usr/lib/jvm/java-1.7.0/
</code></pre>

<p>Finally, edit <code>conf/core-site.xml</code> and add the following property:</p>

<pre><code>&lt;property&gt;
  &lt;name&gt;fs.default.name&lt;/name&gt;
  &lt;value&gt;hdfs://localhost:9100&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>Now we&#8217;re ready to run Hadoop.  Check to make sure that you can <code>ssh</code> to your local machine without a password, since the Hadoop startup scripts will do this several times and you will get tired of typing your password.  If you can&#8217;t and you already have a SSH key pair, append your public key to your <code>authorized_keys</code> file and make sure it&#8217;s only readable by you.  If you don&#8217;t already have a SSH key pair on your machine, you can simply type in the following commands for a local-only setup:</p>

<pre><code>ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
</code></pre>

<p>Now you&#8217;re ready to format your HDFS storage:</p>

<pre><code>./bin/hadoop namenode -format
</code></pre>

<p>Next, start all of the Hadoop daemons:</p>

<pre><code>cd ~/build/mesos/hadoop/hadoop-0.20.205.0/
./bin/start-all.sh
</code></pre>

<p>If you&#8217;re running as <code>root</code> (shame on you!), you&#8217;ll get an error that the <code>-jvm</code> option isn&#8217;t supported.  You can work around this error by running <code>sed -i 's/jvm //' bin/hadoop</code> or &#8212; if you prefer to do things manually &#8212; editing <code>bin/hadoop</code> and replacing the line that reads</p>

<pre><code>HADOOP_OPTS="$HADOOP_OPTS -jvm server $HADOOP_DATANODE_OPTS"
</code></pre>

<p>with this line:</p>

<pre><code>HADOOP_OPTS="$HADOOP_OPTS -server $HADOOP_DATANODE_OPTS"
</code></pre>

<p>If you had to make this change, run <code>bin/stop-all.sh</code> and then <code>bin/start-all.sh</code> again.</p>

<h3>Storing an input file to HDFS</h3>

<p>As long as we&#8217;re still thinking about Hadoop, let&#8217;s put some data there so we can process it after we&#8217;ve built Spark.  For our Spark example, we&#8217;ll work with a <a href="http://en.wikipedia.org/wiki/Common_Log_Format">Common Log Format</a> file (like an Apache HTTPD <code>AccessLog</code>).  (You probably have one sitting around somewhere.)  Mine is called <code>~/access_log</code>.  Here&#8217;s how I&#8217;ll load it in to HDFS:</p>

<pre><code>./bin/hadoop fs -mkdir input
./bin/hadoop fs -put ~/access_log input
</code></pre>

<p>I can check that it&#8217;s actually there:</p>

<pre><code>./bin/hadoop fs -ls input | grep access_log
</code></pre>

<p>and, sure enough, I&#8217;ll get something like this in return:</p>

<pre><code>-rw-r--r--   3 root supergroup  792036736 2013-04-10 14:32 /user/root/input/access_log
</code></pre>

<p>Shame on me, too, I guess.  Now we&#8217;re ready to build Spark and run some example jobs against these data.</p>

<h3>Building Spark</h3>

<p>First, fetch the source tarball:</p>

<pre><code>wget http://spark-project.org/files/spark-0.7.0-sources.tgz
tar -xzvf spark-0.7.0-sources.tgz
cd spark-0.7.0
</code></pre>

<p>In order to be able to fetch input data from HDFS, Spark needs to know what version of Hadoop you&#8217;re running before you build it.  To do this, either open <code>project/SparkBuild.scala</code> in your favorite editor or run the following command:</p>

<pre><code>sed -i 's/= "1.0.4"/= "0.20.205.0"/' project/SparkBuild.scala
</code></pre>

<p>Now we&#8217;ll use the Scala build tool to compile Spark:</p>

<pre><code>./sbt/sbt package
</code></pre>

<p>We can now run a simple job to make sure Spark works.  The <code>SparkPi</code> example uses a Monte Carlo method to approximate Pi:</p>

<pre><code>export SCALA_HOME=/usr/share/scala
./run spark.examples.SparkPi local 1000
</code></pre>

<p>Now you should have a working Spark installation and can run some jobs locally.  We&#8217;ll look at an example interaction with Spark next.</p>

<h3>Running an example Spark job</h3>

<p>The Spark shells use the <code>MASTER</code> environment variable to determine how to run jobs.  Set it to <code>local</code> for now:</p>

<pre><code>export MASTER=local
</code></pre>

<p>This will run your jobs locally, using only one thread.  We&#8217;ll also want to enable Spark to use more memory if we&#8217;re going to work with a large dataset:</p>

<pre><code>export SPARK_MEM=2g
</code></pre>

<p>If you want to use more or less than 2 gigabytes, change that setting appropriately; it uses the same format as Java heap size arguments.  Now we&#8217;ll start up the Python Spark environment:</p>

<pre><code>./pyspark
</code></pre>

<p>You&#8217;ll find yourself in a Python REPL with a <a href="http://spark-project.org/docs/latest/api/pyspark/pyspark.context.SparkContext-class.html"><code>SparkContext</code></a> object initialized in the <code>sc</code> variable.  Now, create a Spark <a href="http://spark-project.org/docs/latest/api/pyspark/pyspark.rdd.RDD-class.html"><em>resilient distributed dataset</em></a> from the lines in the log file we uploaded to HDFS (noting, of course, that your URL may be different depending on how you stored the file):</p>

<pre><code>log_entries = sc.textFile("hdfs://localhost:9100/user/root/input/access_log")
</code></pre>

<p>We&#8217;ll then write a short series of operations to count the number of log entries for each remote host:</p>

<pre><code>ips = log_entries.map(lambda s: s.split()[0])
ips.map(lambda ip: (ip, 1)).reduceByKey(lambda a, b: a + b).collect()
</code></pre>

<p>This example won&#8217;t benefit all that much from Spark&#8217;s caching support, but it will run faster in parallel.  If you have many cores in your machine, try using them!  Here&#8217;s how you&#8217;d set <code>MASTER</code> if you wanted to use 8 threads:</p>

<pre><code>export MASTER='local[8]'
</code></pre>

<p>Exit out of <code>pyspark</code> and try running the example again with more threads, if you feel so inclined.</p>

<h3>Next steps</h3>

<p>Now that you have Spark up and running, here are some things to consider trying:</p>

<ul>
<li>learn more about Spark by working through some <a href="http://spark-project.org/examples/">examples</a></li>
<li>read up on the <a href="http://spark-project.org/docs/latest/python-programming-guide.html">Python</a> or <a href="http://spark-project.org/docs/latest/scala-programming-guide.html">Scala</a> interfaces to programming Spark</li>
<li>run <a href="http://spark-project.org/docs/latest/running-on-mesos.html">Spark under Mesos</a> or <a href="http://spark-project.org/docs/latest/spark-standalone.html">across several nodes without Mesos</a></li>
<li>check out some other cool projects that work with Spark, like <a href="http://shark.cs.berkeley.edu">Shark</a> (an implementation of Apache Hive that uses Spark in the query planner) and <a href="http://spark-project.org/docs/latest/bagel-programming-guide.html">Bagel</a> (an implementation of Google&#8217;s Pregel system for graph processing)</li>
</ul>

    ]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Reprocessing CMS events with Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/04/reprocessing-cms-events-with-bosco.html"/>
      <updated>2013-04-02T19:38:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9221383956864186778</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[Prior to the <a href="http://home.web.cern.ch/about/updates/2013/02/long-shutdown-1-exciting-times-ahead">LHC long shutdown</a>, the CMS experiment increased the trigger rate of the detector, therefore increasing the data coming off the detector. &nbsp;The Tier-0 was unable to process all of the events coming off of the detector, therefore the events where only stored and not processed. &nbsp;After the run, the experiment wanted to process the backlog of events, but didn't have the computing power available to do it. &nbsp;So they turned to opportunistic computing and <a href="http://bosco.opensciencegrid.org/">Bosco</a>.<br /><br />The CMS collaborators at UCSD worked with the <a href="http://www.sdsc.edu/">San Diego Supercomputing Resource</a> to run the processing on the <a href="http://www.sdsc.edu/News%20Items/PR030512_gordon.html">Gordon</a> supercomputer. &nbsp;Gordon is an <a href="https://www.xsede.org/web/guest/sdsc-gordon">XSEDE resource</a>&nbsp;and&nbsp;does not include a traditional OSG Globus Gatekeeper. &nbsp;Also, we did not have root access to the cluster to install a gatekeeper. &nbsp;Therefore, Bosco was used to submit and manage the <a href="http://www.uscms.org/SoftwareComputing/Grid/WMS/glideinWMS/doc.prd/index.html">GlidienWMS</a>&nbsp;Condor glideins to the resource.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td><a href="http://3.bp.blogspot.com/-Iu-KOlNG1-s/UVswQYykYoI/AAAAAAAAB5A/0nsceq8Rumk/s1600/sdsc_jobs.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="480" src="http://3.bp.blogspot.com/-Iu-KOlNG1-s/UVswQYykYoI/AAAAAAAAB5A/0nsceq8Rumk/s640/sdsc_jobs.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="font-size: 13px;">Running jobs at Gordon, the SDSC supercomputer</td></tr></tbody></table><br /><br />As you can see from the graph, we reached nearly 4,000 CMS processing jobs on Gordon. &nbsp;4k cores is larger than most CMS Tier 2's, and as big as a European Tier-1. &nbsp;With Bosco, overnight, Gordon became one of the largest CMS clusters in the world.<br /><br />Full details will be written in a submitted paper to <a href="http://www.chep2013.org/">CHEP '13</a> in Amsterdam, and Bosco will be presented in a poster (and paper) as well. &nbsp;I hope to see you there!<br /><br />(If I got any details wrong about the CMS side of this run, please let me know. &nbsp;I have intimate knowledge of the Gordon side, but not so much the CMS side).<br /><br /><br /><center> <a href="http://bosco.opensciencegrid.org/download/">     <img alt="Bosco Download" src="https://raw.github.com/osg-bosco/bosco-download-images/master/images/download-orange.png" style="border-width: 0;" /> </a>   </center><br />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 7.8.8 released! ( March 28, 2013 )]]></title>
      <link href="manual/v7.8/9_3Stable_Release.html"/>
      <updated>2013-03-28T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 7.8.8.
This release contains bug fixes for reconnection failure when using CCB, 
introduces automatic retries for some glexec errors, 
and fixes several other grid related bugs.
A complete list of bugs fixed can be found in the
Version History. HTCondor 7.8.8 binaries
and source code are available from our Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Impact of Negotiator Cycle Cadence on Slot Loading]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading/"/>
      <updated>2013-03-21T22:10:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_1Introduction.html#8555">HTCondor negotiator</a> assigns jobs (resource requests) to slots (compute resources) at regular intervals, configured by the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#20544">NEGOTIATOR_INTERVAL</a> parameter.  This interval (the cycle <em>cadence</em>) has a fundamental impact on a pool <em>loading factor</em> -- the fraction of time that slots are being productively utilized.</p>

<p>Consider the following diagram, which illustrates the utilization of a slot over the lifetime of a job.  When a job completes, its slot will remain empty until it can be assigned a new job on the next negotiation cycle.</p>

<p><img src="/assets/images/slot_load_study/loading_factor_diagram.png" width="750"></p>

<p>As the diagram above shows, the loading factor for a slot can be expressed as D/Z, where D is the duration of the job, and Z is the total time until the next cycle occurring after the job completes.  We can also write Z = D+I, where I is the "idle time" from job completion to the start of the next negotiation cycle.   Loading factor is always &lt;= 1, where a value of 1 corresponds to ideal loading -- every slot is utilized 100% of the time.  In general, loading will be &lt; 1, as jobs rarely complete exactly on a cycle boundary.</p>

<p>It is worth briefly noting that the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#18202">claim reuse</a> feature was developed to help address this problem.  However, claim re-use is not compatible with all other features -- for example enabling claim re-use can cause accounting group starvation -- and so what follows remains relevant to many HTCondor configurations.</p>

<p>Given a particular negotiation cycle cadence, how does a slot's loading factor behave, as a function of job duration?  The loading factor can be expressed as:</p>

<div markdown="0">
\\[
\\text{Loading Factor} = \\frac{D}{C \\left( q + \\lceil r \\rceil \\right)} \\\\
 \\\\
\\text{where:} \\\\
D = \\text{job duration} \\\\
C = \\text{cycle cadence} \\\\
q = \\lfloor D / C \\rfloor \\\\
r = \\left( D / C \\right) - q \\\\
\\]
</div>


<p>The following plot illustrates how the loading factor changes with job duration, assuming a cadence of 300 seconds (5 minutes):</p>

<p><img src="/assets/images/slot_load_study/load_factor_300s.png" width="750"></p>

<p>We immediately see that there is a saw-tooth pattern to the plot.  As the job duration increases towards the boundary of a cycle, there is less and less idle time until the next cycle, and so the loading approaches 1.0.  However, once the job's end crosses the thresold to <em>just past</em> the start of the cycle, it immediately drops to the worse possible case: the slot will be idle for nearly an entire cycle.</p>

<p>The other important pattern is that the bottom of the saw-tooth gradually increases.  As a job's duration occupies more whole negotiation cycles, the idle time at the end of the last cycle represents a decreasing fraction of the total time.</p>

<p>Observe that the most important 'unit' in this plot is the number of negotiation cycles.  Since the saw-toothing scales with the cycle interval, we can express the same plot in units of cycles instead of seconds:</p>

<p><img src="/assets/images/slot_load_study/load_factor_cu.png" width="750"></p>

<p>The results above suggest a couple possible approaches for tuning negotiator cycle cadence to optimize slot loading in an HTCondor pool.  The first is to configure the negotiator interval to be small relative to a typical job duration, as the lower-bound on loading factor increases with the number of cycles a job's duration occupies.  For example, if a typical job duration is 10 minutes, then a cycle cadence of 60 seconds ensures that in general 9 out of 10 cycles will be fully utilized, and so loading will be around 90%.  However, if one has mostly very short jobs, this can be difficult, as negotiation cycle cadences much less than 60 seconds may risk causing performance problems even on a moderately loaded pool.</p>

<p>A second approach is to try and tune the cadence so that as many jobs as possible complete <em>near the end</em> of a cycle, thus minimizing delay until the next cycle.  For example, if job durations are relatively consistent, say close to 90 seconds, then setting the negotiator interval to something like 50 seconds will induce those jobs to finish near the end of the 2nd negotiation cycle (at t+100 seconds), for a loading factor around 90%.  The caveat here is that job durations are frequently <em>not</em> that consistent, and as job duration spread increases, one's ability to play this game <a href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/">rapidly evaporates</a>.</p>

<p>In this post, I have focused on the behavior of individual jobs and individual slots.  An obvious next question is what happens to aggregate pool loading when job durations are treated as population sampling from random variables, which I plan to explore in future posts.</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Smooth Gradients for Cubic Hermite Splines]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/"/>
      <updated>2013-03-16T14:39:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, ... m_{n-1} \) at knot-points: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Examining the Modulus of Random Variables]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/"/>
      <updated>2013-03-15T19:03:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h3>Motivation</h3> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ Paradyn/HTCondor Week 2013 registration open (March 8, 2013)]]></title>
      <link href="http://research.cs.wisc.edu/htcondor/HTCondorWeek2013/"/>
      <updated>2013-03-08T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[We want to invite you to 
HTCondor Week 2013
, our annual HTCondor user conference, in beautiful Madison, WI April 29-May 3, 2013. (HTCondor Week was formerly named Condor Week, matching 
a name change for the software.) We will again host HTCondor Week at the Wisconsin Institutes for Discovery, a state of the art facility for academic and private research specifically designed to foster private and public collaboration. It provides HTCondor Week attendees a compelling environment to attend tutorials and talks from HTCondor developers and users like you. It also provides many comfortable spaces for one-on-one or small group collaborations throughout the week. This year we continue our partnership with the Paradyn Tools Project, making this year Paradyn/HTCondor Week 2013. There will be a full slate of tutorials and talk for both HTCondor and Paradyn.

Our current development series, 7.9, is well underway toward our upcoming production release. When you attend, you will learn how to take advantage of the latest features such as per-job PID namespaces, cgroup enforced resource limits, Python bindings, CPU affinity, BOSCO for submitting jobs to remote batch systems without administrator assistance, EC2 spot instance support, and a variety of speed and memory optimizations. You'll also get a peek into our longer term development plans--something you can only get at HTCondor Week!

We will have a variety of in-depth tutorials, talks, and panels where you can not only learn more about HTCondor, but you can also learn how other people are using and deploying HTCondor. Best of all you can establish contacts and learn best practices from people in industry, government and academia who are using HTCondor to solve hard problems, many of which may be similar to those facing you.

Speaking of learning from the community, we'd love to have you give a talk at HTCondor Week. Talks are 20 minutes long and are a great way share your ideas and get feedback from the community. If you have a compelling use of HTCondor you'd like to share, let Alan De Smet know (adesmet@cs.wisc.edu) and he'll help you out. 

More information on speaking at HTCondor Week is available at the HTCondor Week web site.

You can register, get the hotel details and see the agenda overview on  
the HTCondor Week 2013 site. See you soon in Madison! 
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Running Quantum Espresso on the OSG]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/03/running-quantum-espresso-on-osg.html"/>
      <updated>2013-03-05T18:53:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-2337400839561942722</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Per-Process Mount Namespaces]]></title>
      <link href="http://timothysc.github.com/blog/2013/02/22/perprocess/"/>
      <updated>2013-02-22T16:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/02/22/perprocess</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 7.9.4 released! (February 20, 2013)]]></title>
      <link href="manual/v7.9/9_3Development_Release.html"/>
      <updated>2013-02-20T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 7.9.4.
This release supports per job PID namespaces for Linux RHEL 6, improvements
to the resource usage of the EC2 GAHP, support for capping the size of input
and output file transfer, and new analysis modes for condor_q -analyze.
A complete list of bugs fixed and features can be found in the
Version History. HTCondor 7.9.4 binaries
and source code are available from our Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Statistic changes in HTCondor 7.7]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/12/statistic-changes-in-htcondor-7-7/"/>
      <updated>2013-02-12T11:56:04Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=925</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Notice to HTCondor 7.8 users - Statistics implemented during the 7.5 series that landed in 7.7.0 were rewritten by the time 7.8 was released. If you were using the original statistics for monitoring and/or reporting, here is a table to help you map old (left column) to new (right column). See – 7.6 -&#62; 7.8 [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=925&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Bosco to submit to Amazon EC2]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/02/using-bosco-to-submit-to-amazon-ec2.html"/>
      <updated>2013-02-06T04:27:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-4538100752405939638</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[How accounting group configuration could work with Wallaby]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/05/how-accounting-group-configuration-could-work-with-wallaby/"/>
      <updated>2013-02-05T11:46:28Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=917</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Configuration of accounting groups in HTCondor is too often an expert task that requires coordination between administrators and their tools. Wallaby provides a coordination point, so long as a little convention is employed, and can provide a task specific interface to simplify configuration. Quick background, Wallaby provides semantic configuration for HTCondor. It models a pool [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=917&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Some htcondor-wiki stats]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/29/some-htcondor-wiki-stats/"/>
      <updated>2013-01-29T11:36:06Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=903</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[A few years ago I discovered Web Numbr, a service that will monitor a web page for a number and graph that number over time. I installed a handful of webnumbrs to track things at HTCondor&#8217;s gittrac instance. http://webnumbr.com/search?query=condor Thing such as - Tickets resolved with no destination: tickets that don&#8217;t indicate what version they [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=903&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Introducing the HTCondor-CE]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/introducing-htcondor-ce.html"/>
      <updated>2013-01-28T15:33:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1124494645797252707</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Concurrency Limits: Group defaults]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/21/concurrency-limits-group-defaults/"/>
      <updated>2013-01-21T12:47:07Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=895</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Concurrency limits allow for protecting resources by providing a way to cap the number of jobs requiring a specific resource that can run at one time. For instance, limit licenses and filer access at four regional data centers. Notice the repetition. In addition to the repetition, every license.* and filer.* must be known and recorded [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=895&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bosco 1.1.1 Release]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/01/bosco-111-release.html"/>
      <updated>2013-01-14T18:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1926902995750303001</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Your API is a feature, give it real resource management]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/14/your-api-is-a-feature-give-it-real-resource-management/"/>
      <updated>2013-01-14T12:17:29Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=872</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[So much these days is about distributed resource management. That&#8217;s anything that can be created and destroyed in the cloud[0]. Proper management is especially important when the resource&#8217;s existence is tied to a real economy, e.g. your user&#8217;s credit card[1]. Above is a state machine required to ensure that resources created in AWS EC2 are [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=872&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bosco 1.1 Release]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/01/bosco-11-release.html"/>
      <updated>2013-01-08T23:01:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-2171189043756995217</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Fun with ClassAds]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/fun-with-classads.html"/>
      <updated>2013-01-05T22:58:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1674994974092153801</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Mean of the Modulus Does Not Equal the Modulus of the Mean]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/"/>
      <updated>2013-01-02T15:55:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I've been considering models for the effects of HTCondor negotiation cycle cadence on pool loading and accounting group starvation, which led me to thinking about the effects of taking the modulus of a random variable, for reasons I plan to discuss in future posts. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Demonstration of Negotiator-Side Resource Consumption]]></title>
      <link href="http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption/"/>
      <updated>2012-12-03T15:25:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>HTCondor supports a notion of aggregate compute resources known as partitionable slots (p-slots), which may be consumed by multiple jobs.   Historically, at most one job could be matched against such a slot in a single negotiation cycle, which limited the rate at which partitionable slot resources could be utilized.  More recently, the scheduler has been enhanced with logic to allow it to acquire multiple claims against a partitionable slot, which increases the p-slot utilization rate. However, as this potentially bypasses the negotiator's accounting of global pool resources such as accounting group quotas and concurrency limits, it places some contraints on what jobs can can safely acquire multiple claims against any particular p-slot: for example, only other jobs on the same scheduler can be considered.  Additionally, candidate job requirements must match the requirements of the job that originally matched in the negotiator.  Another significant impact is that the negotiator is still forced to match an entire p-slot, which may have a large match cost (weight): these large match costs cause <a href="https://htcondor-wiki.cs.wisc.edu/index.cgi/tktview?tn=3013">accounting difficulties</a> when submitter shares and/or group quotas drop below the cost of a slot.  This particular problem is growing steadily larger, as machines with ever-larger numbers of cores and other resources appear in HTCondor pools. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Role enforcement in Cumin]]></title>
      <link href="http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin/"/>
      <updated>2012-11-12T20:20:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Roles in Cumin scope activities and content in the UI.  There are currently two roles defined in Cumin, <code>admin</code> and <code>user</code>.  The <code>admin</code> role is a superset of the <code>user</code> role, and every new account has the <code>user</code> role by default. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Override HTCondor installation with sudo]]></title>
      <link href="http://timothysc.github.com/blog/2012/11/12/condor-sudo/"/>
      <updated>2012-11-12T09:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/11/12/condor-sudo</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Best practices for Wallaby's default group]]></title>
      <link href="http://chapeau.freevariable.com/2012/11/best-practices-for-wallabys-default-group.html"/>
      <updated>2012-11-01T20:14:53Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.38</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Recall that Wallaby applies partial configurations to groups of nodes. Groups can be either explicit —- that is, a named subset of nodes created by the user, or special groups that are built-in to Wallaby; each node’s group memberships have...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Welcome To The HTCondor Project Github Site]]></title>
      <link href="http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site/"/>
      <updated>2012-10-29T20:15:00Z</updated>
      <id>http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site</id>
      <author>
        <name><![CDATA[HTCondor Team GitHub]]></name>
        <uri>http://htcondor.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Welcome to the HTCondor Project GitHub website!  This site is the github web and blog presence for the HTCondor project. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Configuring high-availability Condor central managers with Wallaby]]></title>
      <link href="http://chapeau.freevariable.com/2012/10/configuring-high-availability-condor-central-managers-with-wallaby.html"/>
      <updated>2012-10-23T04:34:58Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.37</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Rob Rati and I gave a tutorial on highly-available job queues at Condor Week this year. While it was not a Wallaby-specific tutorial, we did point out that configuring highly-available job queues is easier for users who manage and deploy...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Cluster Suite's GUI to configure High Availability Schedulers ]]></title>
      <link href="http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers/"/>
      <updated>2012-10-18T17:20:00Z</updated>
      <id>http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In an <a href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/">earlier post</a> I talked about using Cluster Suite
to manage high availability schedulers and referenced the command line tools
available perform the configuration.  I'd like to focus on using the GUI that
is part of Cluster Suite to configure an HA schedd.  It's a pretty simple
process but does require you run a wallaby shell command to complete the
configuration. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Credentials in LDAP URLs when Anonymous Search is Disabled]]></title>
      <link href="http://tmckayus.github.com/blog/2012/10/10/ldap-credentials/"/>
      <updated>2012-10-10T20:55:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/10/10/ldap-credentials</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Cumin authenticates logins against LDAP using a two step process: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Cluster Suite to Manage a High Availability Scheduler]]></title>
      <link href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/"/>
      <updated>2012-09-26T19:53:00Z</updated>
      <id>http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Condor provides simple and easy to configure HA functionality for the schedd
that relies upon shared storage (usually NFS).  The shared store is used to
store the job queue log and coordinate which node is running the schedd.  This
means that each node that can run a particular schedd not only have condor
configured but the node needs to be configured to access the shared storage. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Integrating Cumin with LDAP for Authentication]]></title>
      <link href="http://tmckayus.github.com/blog/2012/09/24/ldap-auth/"/>
      <updated>2012-09-24T16:41:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/09/24/ldap-auth</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Past versions of Cumin have relied on a local database for storing user accounts.  However, that solution adds extra maintenance for site administrators who already have or plan to have a central authentication mechanism for their users.  Consequently, development is ongoing to integrate Cumin with common central auth mechanisms.  LDAP integration is available now, with support for other technologies planned for the future. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[So What is Cumin Anyway?]]></title>
      <link href="http://tmckayus.github.com/blog/2012/09/24/new-post/"/>
      <updated>2012-09-24T16:07:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/09/24/new-post</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Cumin is a Python web UI developed in the Fedora community for managing Condor pools and Qpid messaging brokers.  It is packaged for Fedora but may be run from sources and would probably be easy to port to other Linux distributions (or just run Fedora on a node or two in a heterogeneous environment!)  The current development focus for Cumin is on expanding the Condor management facilities. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Elastic Grid with Condor and oVirt Integration]]></title>
      <link href="http://timothysc.github.com/blog/2012/09/21/condor-n-overt/"/>
      <updated>2012-09-21T08:50:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/09/21/condor-n-overt</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Putting It Together]]></title>
      <link href="http://rrati.github.com/blog/2012/09/18/putting-it-together/"/>
      <updated>2012-09-18T12:59:00Z</updated>
      <id>http://rrati.github.com/blog/2012/09/18/putting-it-together</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Authorization for Wallaby clients]]></title>
      <link href="http://getwallaby.com/2012/09/authorization-for-wallaby-clients/"/>
      <updated>2012-09-12T22:30:00Z</updated>
      <id>http://getwallaby.com/2012/09/authorization-for-wallaby-clients</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways.  This post will explain how the authorization support works and show how to get started using it.  If you just want to get started using Wallaby with authorization support as quickly as possible, skip ahead to the section titled &#8220;Getting Started&#8221; below.  Detailed information about which role is required for each Wallaby API method is <a href="http://getwallaby.com/api-roles/">available here</a>. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Authorization for Wallaby clients]]></title>
      <link href="http://chapeau.freevariable.com/2012/09/authorization-for-wallaby-clients.html"/>
      <updated>2012-09-12T22:23:18Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.36</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways. This post will explain how the authorization support works and show how to...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Dust off nuke it from orbit]]></title>
      <link href="http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit/"/>
      <updated>2012-09-12T09:12:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Highly-available configuration data with Wallaby]]></title>
      <link href="http://chapeau.freevariable.com/2012/08/highly-available-configuration-data-with-wallaby.html"/>
      <updated>2012-08-29T21:03:00Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.35</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Many Condor users are interested in high-availability (HA) services: they don't want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon. (See this talk that Rob Rati and...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Highly-available configuration data with Wallaby]]></title>
      <link href="http://getwallaby.com/2012/08/live-backup/"/>
      <updated>2012-08-29T14:40:00Z</updated>
      <id>http://getwallaby.com/2012/08/live-backup</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Many Condor users are interested in <em>high-availability</em> (HA) services:  they don&#8217;t want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon.  (See <a href="http://research.cs.wisc.edu/condor/CondorWeek2012/presentations/rati-benton-condor-ha.pdf">this talk</a> that Rob Rati and I gave at Condor Week this year for a couple of solutions to HA with the Condor <code>schedd</code>.)  So it&#8217;s only natural that Condor users who are interested in configuring their pools with <a href="http://getwallaby.com">Wallaby</a> might wonder how Wallaby responds in the face of failure. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using the skeleton group]]></title>
      <link href="http://getwallaby.com/2012/06/using-the-skeleton-group/"/>
      <updated>2012-06-15T17:46:00Z</updated>
      <id>http://getwallaby.com/2012/06/using-the-skeleton-group</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In Wallaby, Condor nodes are configured by applying <em>features</em> and <em>parameter</em> settings to <em>groups</em>.  In order for the group abstraction to be fully general, <a href="http://getwallaby.com/2011/05/using-wallaby-groups-to-implement-node-tagging/">Wallaby provides two kinds of <em>special groups</em></a>:  the <em>default group</em>, which contains every node (but which is the lowest-priority membership for each node), and a set of <em>identity groups</em>, each of which only contains a single node (and which is always its highest-priority membership, so that special settings applied to a node&#8217;s identity group always take precedence over settings from that node&#8217;s other memberships). [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Troubleshooting Condor with Wallaby]]></title>
      <link href="http://getwallaby.com/2012/06/troubleshooting/"/>
      <updated>2012-06-01T17:27:00Z</updated>
      <id>http://getwallaby.com/2012/06/troubleshooting</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Often, if you&#8217;re trying to reproduce a problem someone else is having with Condor, you&#8217;ll need their configuration.  Likewise, if you&#8217;re trying to help someone reproduce a problem you&#8217;re having, you&#8217;ll want to send along your configuration to aid them in replicating your setup.  For installations that use legacy flat-file configurations (optionally with a local configuration directory), this can be a pain, since you&#8217;ll need to copy several files from site to site (ensuring that you&#8217;ve included all the files necessary to replicate your configuration, perhaps across multiple machines on the site experiencing the problem). [...]</p>
]]></content>
    </entry>
  
</feed>
