<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2015-11-26T03:08:09-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[The 'prepare' operation considered harmful in Algebird aggregation]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/11/24/the-prepare-operation-considered-harmful-in-algebird/"/>
      <updated>2015-11-24T23:32:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/11/24/the-prepare-operation-considered-harmful-in-algebird</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I want to make an argument that the Algebird <a href="http://twitter.github.io/algebird/#com.twitter.algebird.Aggregator">Aggregator</a> design, in particular its use of the <code>prepare</code> operation in a map-reduce context, has substantial inefficiencies, compared to an equivalent formulation that is more directly suited to taking advantage of Scala's <a href="http://www.scala-lang.org/api/current/index.html#scala.collection.Seq">aggregate method on collections</a> method.</p>

<p>Consider the definition of aggregation in the Aggregator class:</p>

<p><code>scala
def apply(inputs: TraversableOnce[A]): C = present(reduce(inputs.map(prepare)))
</code></p>

<p>You can see that it is a standard map/reduce operation, where <code>reduce</code> is defined as a monoidal (or semigroup -- more on this later) operation. Under the hood, it boils down to an invocation of Scala's <code>reduceLeft</code> method.  The key thing to notice is that the role of <code>prepare</code> is to map a collection of data elements into the required monoids, which are then aggregated using that monoid's <code>plus</code> operation.  In other words, <code>prepare</code> converts data elements into "singleton" monoids each representing a data element.</p>

<p>Now, if the monoid in question is simple, say some numeric type, this conversion is free, or nearly so.  For example, the conversion of an integer into the "integer monoid" is a no-op.  However, there are other kinds of "non-trivial" monoids, for which the conversion of a data element into its corresponding monoid may be costly.  In this post, I will be using the monoid defined by Scala Set[Int], where the monoid <code>plus</code> operation is set union, and of course the <code>zero</code> element is the empty set.</p>

<p>Consider the process of defining an Algebird aggregator for the task of generating the set of unique elements in a data set.  The corresponding <code>prepare</code> operation is: <code>prepare(e: Int) = Set(e)</code>.  A monoid trait that encodes this idea might look like the following.  (the code I used in this post can be found <a href="https://gist.github.com/erikerlandson/d96dc553bc51e0eb5e4b">here</a>)</p>

<p>```scala
// an algebird-like monoid with the 'prepare' operation
trait PreparedMonoid[M, E] {
  val zero: M
  def plus(m1: M, m2: M): M
  def prepare(e: E): M
}</p>

<p>// a PreparedMonoid for a set of integers.  monoid operator is set union.
object intSetPrepared extends PreparedMonoid[Set[Int], Int] {
  val zero = Set.empty[Int]
  def plus(m1: Set[Int], m2: Set[Int]) = m1 ++ m2
  def prepare(e: Int) = Set(e)
}</p>

<p>implicit class SeqWithMapReduce<a href="seq:%20Seq[E]">E</a> {
  // algebird map/reduce Aggregator model
  def mrPrepared<a href="mon:%20PreparedMonoid[M,%20E]">M</a>: M = {</p>

<pre><code>seq.map(mon.prepare).reduceLeft(mon.plus)
</code></pre>

<p>  }
}
```</p>

<p>If we unpack the above code, as applied to <code>intSetPrepared</code>, we are instantiating a new Set object, containing a single value, for every single input data element.</p>

<p>But there is a potentially better model of aggregation, exemplified by the Scala <code>aggregate</code> method.  This method does not use a <code>prepare</code> operation.  It uses a zero value and a monoidal operator, which the Scala docs refer to as <code>combop</code>, but it also uses an "update" operation, that defines how to update the monoid object, directly, with a single element, referred to as <code>seqop</code> in Scala's documentation.  This idea can also be encoded as a flavor of monoid, enhanced with an <code>update</code> method:</p>

<p>```scala
// an algebird-like monoid with 'update' operation
trait UpdatedMonoid[M, E] {
  val zero: M
  def plus(m1: M, m2: M): M
  def update(m: M, e: E): M
}</p>

<p>// an equivalent UpdatedMonoid for a set of integers
object intSetUpdated extends UpdatedMonoid[Set[Int], Int] {
  val zero = Set.empty[Int]
  def plus(m1: Set[Int], m2: Set[Int]) = m1 ++ m2
  def update(m: Set[Int], e: Int) = m + e
}</p>

<p>implicit class SeqWithMapReduceUpdated<a href="seq:%20Seq[E]">E</a> {
  // map/reduce logic, taking advantage of scala 'aggregate'
  def mrUpdatedAggregate<a href="mon:%20UpdatedMonoid[M,%20E]">M</a>: M = {</p>

<pre><code>seq.aggregate(mon.zero)(mon.update, mon.plus)
</code></pre>

<p>  }
}
```</p>

<p>This arrangement promises more efficiency when aggregating w.r.t. nontrivial monoids, by avoiding the construction of "singleton" monoids for each data element.  The following demo confirms that for the Set-based monoid, it is over 10 times faster:</p>

<p>```scala
scala> :load /home/eje/scala/prepare.scala
Loading /home/eje/scala/prepare.scala...
defined module prepare</p>

<p>scala> import prepare.<em>
import prepare.</em></p>

<p>scala> val data = Vector.fill(1000000) { scala.util.Random.nextInt(10) }
data: scala.collection.immutable.Vector[Int] = Vector(7, 9, 4, 2, 7,...</p>

<p>// Verify that output is the same for both implementations:
scala> data.mrPrepared(intSetPrepared)
res0: Set[Int] = Set(0, 5, 1, 6, 9, 2, 7, 3, 8, 4)</p>

<p>// results are the same
scala> data.mrUpdatedAggregate(intSetUpdated)
res1: Set[Int] = Set(0, 5, 1, 6, 9, 2, 7, 3, 8, 4)</p>

<p>// Compare timings of prepare-based versus update-based aggregation
// (benchmark values are returned in seconds)
scala> benchmark(10) { data.mrPrepared(intSetPrepared) }
res2: Double = 0.2957673056</p>

<p>// update-based aggregation is 10 times faster
scala> benchmark(10) { data.mrUpdatedAggregate(intSetUpdated) }
res3: Double = 0.027041249300000004
```</p>

<p>It is also possible to apply Scala's <code>aggregate</code> to a monoid enhanced with <code>prepare</code>:</p>

<p>```scala
implicit class SeqWithMapReducePrepared<a href="seq:%20Seq[E]">E</a> {
  // using 'aggregate' with prepared op
  def mrPreparedAggregate<a href="mon:%20PreparedMonoid[M,%20E]">M</a>: M = {</p>

<pre><code>seq.aggregate(mon.zero)((m, e) =&gt; mon.plus(m, mon.prepare(e)), mon.plus)
</code></pre>

<p>  }
}
```</p>

<p>Although this turns out to be measurably faster than the literal map-reduce implementation, it is still not nearly as fast as the variation using <code>update</code>:</p>

<p><code>scala
scala&gt; benchmark(10) { data.mrPreparedAggregate(intSetPrepared) }
res2: Double = 0.1754636707
</code></p>

<p>Readers familiar with Algebird may be wondering about my use of monoids above, when the <code>Aggregator</code> interface is actually based on semigroups.  This is important, since building on Scala's <code>aggregate</code> function requires a zero element that semigroups do not have.  Although I believe it might be worth considering changing <code>Aggregator</code> to use monoids, another sensible option is to change the internal logic for the subclass <code>AggregatorMonoid</code>, which does require a monoid, or possibly just define a new <code>AggregatorMonoidUpdated</code> subclass.</p>

<p>A final note on compatability: note that any monoid enhanced with <code>prepare</code> can be converted into an equivalent monoid enhanced with <code>update</code>, as demonstrated by this factory function:</p>

<p>```scala
object UpdatedMonoid {
  // create an UpdatedMonoid from a PreparedMonoid
  def apply<a href="mon:%20PreparedMonoid[M,%20E]">M, E</a> = new UpdatedMonoid[M, E] {</p>

<pre><code>val zero = mon.zero
def plus(m1: M, m2: M) = mon.plus(m1, m2)
def update(m: M, e: E) = mon.plus(m, mon.prepare(e))
</code></pre>

<p>  }
}
```</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Very Fast Reservoir Sampling]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/11/20/very-fast-reservoir-sampling/"/>
      <updated>2015-11-20T18:27:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/11/20/very-fast-reservoir-sampling</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I will demonstrate how to do reservoir sampling orders of magnitude faster than the traditional "naive" reservoir sampling algorithm, using a fast high-fidelity approximation to the reservoir sampling-gap distribution.</p>

<blockquote><p>The code I used to collect the data for this post can be viewed <a href="https://github.com/erikerlandson/silex/blob/blog/reservoir/src/main/scala/com/redhat/et/silex/sample/reservoir/reservoir.scala">here</a>.  I generated the plots using the <a href="https://github.com/quantifind/wisp">quantifind WISP</a> project.</p></blockquote>

<p>In a <a href="http://erikerlandson.github.io/blog/2014/09/11/faster-random-samples-with-gap-sampling/">previous post</a>, I showed that random Bernoulli and Poisson sampling could be made much faster by modeling the <em>sampling gap distribution</em> for the corresponding sampling distributions.  More recently, I also began exploring whether <a href="https://en.wikipedia.org/wiki/Reservoir_sampling">reservoir sampling</a> might also be optimized using the gap sampling technique, by deriving the <a href="http://erikerlandson.github.io/blog/2015/08/17/the-reservoir-sampling-gap-distribution/">reservoir sampling gap distribution</a>.  For a sampling reservoir of size (R), starting at data element (j), the probability distribution of the sampling gap is:</p>

<p><img src="/assets/images/reservoir1/figure6.png" title="Figure 1" alt="Figure 1" /></p>

<p>Modeling a sampling gap distribution is a powerful tool for optimizing a sampling algorithm, but it presupposes that you can actually draw values from that distribution substantially faster than just applying a random process to drawing each data element.  I was unable to come up with a "direct" algorithm for drawing samples from P(k) above (I suspect none exists), however I also know the CDF F(k), so it <em>is</em> possible to apply <a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling">inversion sampling</a>, which runs in logarithmic time w.r.t the desired accuracy.  Although its logarithmic cost effectively guarantees that it will be a net efficiency win for sufficiently large (j), it still involves a substantial number of computations to yield its samples, and it seems unlikely to be competitive with straight "naive" reservoir sampling over many real-world data sizes, where (j) may never grow very large.</p>

<p>Well, if exact computations are too expensive, we can always look for a fast approximation.  Consider the original "first principles" formula for the sampling gap P(k):</p>

<p><img src="/assets/images/reservoir2/figure2.png" title="Figure 2" alt="Figure 2" /></p>

<p>As the figure above alludes to, if (j) is relatively large compared to (k), then values (j+1),(j+2)...(j+k) are all going to be effectively "close" to (j), and so we can replace them all with (j) as an approximation.  Note that the resulting approximation is just the PMF of the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">geometric distribution</a>, with probability of success p=(R/j), and we already saw how to efficiently draw values from a geometric distribution from our experience with Bernoulli sampling.</p>

<p>Do we have any reason to hope that this approximation will be useful?  For reasons that are similar to those for Bernoulli gap sampling, it will only be efficient to employ gap sampling when the probability (R/j) becomes small enough.  From our experiences with Bernoulli sampling that is <em>at least</em> j>=2R.  So, we have some assurance that (j) itself will be never be <em>very</em> small.  What about (k)?  Note that a geometric distribution "favors" smaller values of (k) -- that is, small values of (k) have the highest probabilities.  In fact, the smaller that (j) is, the larger the probability (R/j) is, and so the more likely that (k) values that are small relative to (j) will be the frequent ones.  It is also promising that the true distribution for P(k) <em>also</em> favors smaller values of (k) (in fact it favors them even a bit more strongly than the approximation).</p>

<p>Although it is encouraging, it is also clear that my argument above is limited to heuristic hand-waving.  What does this approximation really <em>look</em> like, compared to the true distribution?  Fortunately, it is easy to plot both distributions numerically, since we now know the formulas for both:</p>

<p><img src="/assets/images/reservoir2/CDFs_R=10.png" title="Figure 3" alt="Figure 3" /></p>

<p>The plot above shows that, in fact, the geometric approximation is a <em>surprisingly good</em> approximation to the true distribution!  Furthermore, the approximation remains good as both (j) and (k) grow larger.</p>

<p>Our numeric eye-balling looks quite promising.  Is there an effective way to <em>measure</em> how good this approximation is?  One useful measure is the <a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test">Kolmogorov-Smirnov D statistic</a>, which is just the maximum absolute error between two cumulative distributions.  Here is a plot of the D statistic for reservoir size R=10, as (j) varies across several magnitudes:</p>

<p><img src="/assets/images/reservoir2/R=10.png" title="Figure 4" alt="Figure 4" /></p>

<p>This plot is also good news: we can see that deviation, as measured by D, remains bounded at a small value (less than 0.0262).  As this is for the specific value R=10, we also want to know how things change as reservoir size changes:</p>

<p><img src="/assets/images/reservoir2/R=all.png" title="Figure 5" alt="Figure 5" /></p>

<p>The news is still good!  As reservoir size grows, the approximation only gets better: the D values get smaller as R increases, and remain asymptotically bounded as (j) increases.</p>

<p>Now we have some numeric assurance that the geometric approximation is a good one, and stays good as reservoir size grows and sampling runs get longer.  However, we should also verify that an actual implementation of the approximation works as expected.</p>

<p>Here is pseudocode for an implementation of reservoir sampling using the fast geometric approximation:</p>

<pre><code>// data is array to sample from
// R is the reservoir size
function reservoirFast(data: Array, R: Int) {
  n = data.length
  // Initialize reservoir with first R elements of data:
  res = data[0 until R]
  // Until this threshold, use traditional sampling.  This value may
  // depend on performance characteristics of random number generation and/or
  // numeric libraries:
  t = 4 * R
  j = 1 + R
  while (j &lt; n  &amp;&amp;  j &lt;= t) {
    k = randomInt(j) // random integer &gt;= 0 and &lt; j
    if (k &lt; R) res[k] = data[j]
    j = j + 1
  }
  // Once gaps become significant, it pays to do gap sampling
  while (j &lt; n) {
    // draw gap size (g) from geometric distribution with probability p = R/j
    p = R / j
    u = randomFloat() // random float &gt; 0 and &lt;= 1
    g = floor(log(u) / log(1-p))
    j = j + g
    if (j &lt; n) {
      k = randomInt(R)
      res[k] = data[j]
    }
    j = j + 1
  }
  // return the reservoir
  return res
}
</code></pre>

<p>Following is a plot that shows two-sample D statistics, comparing the distribution in sample gaps between runs of the exact "naive" reservoir sampling with the fast geometric approximation:</p>

<p><img src="/assets/images/reservoir2/D_naive_vs_fast.png" title="Figure 6" alt="Figure 6" /></p>

<p>As expected, the measured difference in sampling characteristics between naive and fast approximation are small, confirming the numeric predictions.</p>

<p>Since the point of this exercise was to achieve faster random sampling, it remains to measure what kind of speed improvements the fast approximation provides.  As a point of reference, here is a plot of run times for reservoir sampling over 10<sup>8</sup> integers:</p>

<p><img src="/assets/images/reservoir2/naive_sample_time_vs_R.png" title="Figure 7" alt="Figure 7" /></p>

<p>As expected, sample time remains constant at around 1.5 seconds, regardless of reservoir size, since the naive algorithm always samples from its RNG per each sample.</p>

<p>Compare this to the corresponding plot for the fast geometric approximation:</p>

<p><img src="/assets/images/reservoir2/gap_sample_times_vs_R.png" title="Figure 8" alt="Figure 8" /></p>

<p>Firstly, we see that the sampling times are <em>much faster</em>, as originally anticipated in my <a href="http://erikerlandson.github.io/blog/2015/08/17/the-reservoir-sampling-gap-distribution/">previous post</a> -- in the neighborhood of 3 orders of magnitude faster.  Secondly, we see that the sampling times do increase as a linear function of reservoir size.  Based on our experience with Bernoulli gap sampling, this is expected; the sampling probabilities are given by (R/j), and therefore the amount of sampling is proportional to R.</p>

<p>Another property anticipated in my previous post was that the efficiency of gap sampling should continue to increase as the amount of data sampled grows; the sampling probability being (R/j), the probability of sampling decreases as j gets larger, and so the corresponding gap sizes grow.  The following plot verifies this property, holding reservoir size R constant, and increasing the data size:</p>

<p><img src="/assets/images/reservoir2/gap_sampling_efficiency.png" title="Figure 9" alt="Figure 9" /></p>

<p>The sampling time (per million elements) decreases as the sample size grows, as predicted by the formula.</p>

<p>In conclusion, I have demonstrated that a geometric distribution can be used as a high quality approximation to the true sampling gap distribution for reservoir sampling, which allows reservoir sampling to be performed much faster than the naive algorithm while still retaining sampling quality.</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.4.2 released! ( November 17, 2015 )]]></title>
      <link href="manual/v8.4.2/10_3Stable_Release.html"/>
      <updated>2015-11-17T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.4.2.
A stable series release contains significant bug fixes.

Highlights of this release are:
a bug fix to prevent the condor_schedd from crashing;
a bug fix to honor TCP_FORWARDING_HOST;
Standard Universe works properly in RPM installations of HTCondor;
the RPM packages no longer claim to provide Globus libraries;
bug fixes to DAGMan's "maximum idle jobs" throttle;
several other bug fixes, consult the version history.


Further details can be found in the
Version History.
HTCondor 8.4.2 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Concrete advice about abstracts]]></title>
      <link href="http://chapeau.freevariable.com/2015/11/concrete-advice-about-abstracts.html"/>
      <updated>2015-11-16T15:43:49Z</updated>
      <id>http://chapeau.freevariable.com/2015/11/concrete-advice-about-abstracts</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Consider the following hypothetical conference session abstract:</p>

<blockquote><p>Much like major oral surgery, writing talk abstracts is universally acknowledged as difficult and painful.  This has never been more true than it is now, in our age of ubiquitous containerization technology.  Today&rsquo;s aggressively overprovisioned, multi-track conferences provide high-throughput information transfer in minimal venue space, but do so at a cost:  namely, they impose stingy abstract word limits.  The increasing prevalence of novel &ldquo;lightning talk&rdquo; tracks presents new challenges for aspiring presenters.  Indeed, the time it takes to read a lightning talk abstract may be a substantial fraction of the time it takes to deliver the talk!  The confluence of these factors, <em>inter alia</em>, presents an increasingly hostile environment for conference talk submissions in late 2015.  Your talk proposals must adapt to this changing landscape or face rejection.  Is there a solution?</p></blockquote>

<p>Hopefully, you recognize some key elements of subpar abstracts that you&rsquo;ve seen, reviewed, or &mdash; maybe, alas &mdash; even submitted in this example.</p>

<p>To identify what&rsquo;s <em>fundamentally</em> wrong with it, we should first consider what the primary rhetorical aims for an abstract are.  In particular, an abstract needs to</p>

<ol>
<li><em>provide context</em> so that a general audience can understand that the problem the talk addresses is interesting,</li>
<li><em>summarize</em> the content of a talk so that audiences and reviewers know what to expect, and</li>
<li><em>motivate</em> conference attendees to put the talk on their schedule (and, more immediately, motivate the program committee to accept the talk).</li>
</ol>


<p>The abstract above does none of these things, for both stylistic and structural reasons.</p>

<p>The example abstract&rsquo;s prose is generally clunky, but the main stylistic problem is its overuse of jargon and enthymemes.  If you don&rsquo;t already spend time in the same neighborhoods of the practice as the author, you probably don&rsquo;t understand all of these terms to mean the same things that the author does or agree with his or her sense of what is &ldquo;universally acknowledged.&rdquo;  It is easy to fall in to using jargon when you&rsquo;re deep in a particular problem domain:  after all, most of the people you interact with use these words and you all seem to understand each other.  However, jargon terms are essentially content-free:  they convey nothing new to specialists and are completely opaque to novices.  By propping up your writing on these empty terms instead of explaining yourself, you are excluding the cohort of your audience who doesn&rsquo;t already understand your problem and shamelessly pandering to the cohort that does.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>The main structural problem with the example abstract is that it doesn&rsquo;t actually make an argument for why the talk is interesting or worth attending; instead, it focuses on emphasizing the problems faced by abstract writers and ends with a cliffhanger.  (The cliffhanger strategy not only adds no additional content, it is also <a href="https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines">especially risky</a>.)  A surprising number of abstracts, even accepted ones, suffer because they focus on only one or two of an abstract&rsquo;s responsibilities, but it is possible to set your abstract up for success by starting from a structure that is designed to cover all of the abstract&rsquo;s responsibilities.</p>

<p>In 1993, <a href="https://plg.uwaterloo.ca/~migod/research/beckOOPSLA.html">Kent Beck appeared on a panel</a> on how to get a paper accepted at OOPSLA.  OOPSLA (now called <a href="http://2015.splashcon.org">SPLASH</a>) was an academic conference on research and development related to object-oriented programming languages, systems and environments to support object-oriented programming, and applications developed using these technologies.  This is a particularly broad mandate, and because OOPSLA attracted so many papers on a wide range of topics, it had an extremely low acceptance rate.  (This is probably why they held a panel on getting papers accepted, but it also makes OOPSLA a good analogy for contemporary practice-focused technical conferences that often cross several areas of specialization, e.g., data processing, distributed computing, and machine learning.)</p>

<p>Beck&rsquo;s advice is worth reading even if you aren&rsquo;t writing an academic conference paper.  In particular, he suggests that you start by identifying a single &ldquo;startling sentence&rdquo; that summarizes your work and can grab the attention of the program committee.  From there, Beck advises that you adopt the following four-sentence model to structure your abstract:</p>

<ol>
<li>The first sentence is the problem you&rsquo;re trying to solve,</li>
<li>The second sentence provides context for the problem or explains its impact,</li>
<li>The third sentence is the &ldquo;startling sentence&rdquo; that is the key insight or contribution of your work, and</li>
<li>The fourth sentence shows how the key contribution of your work affects the problem.</li>
</ol>


<p>I&rsquo;ve used this template in almost every abstract I&rsquo;ve written for many years, although I sometimes devote more than a single sentence to each step.  It has successfully helped me refine abstracts for both industry conference talks and academic papers, and it more or less ensures that each abstract accomplishes what it needs to.  (If you&rsquo;re writing a talk abstract, as opposed to a paper abstract, it&rsquo;s sometimes also a good idea to add a sentence or two covering what the audience should expect to take away from your talk and why you&rsquo;re qualified to give it.)  If I am sure to consider my audience &mdash; first, an overworked program committee member, and second, a jetlagged and overstimulated conference attendee &mdash; I am far more likely to explain things clearly and eschew jargon.  As a bonus, starting from a fairly rigid structure frees me from wasting time worrying about how best to arrange my prose.</p>

<p>If we avoid jargon and start from Beck&rsquo;s structure, we can transform the mediocre example abstract from the beginning of this post into something far more effective:</p>

<blockquote><p> Contemporary multiple-track industry conferences attract speakers and attendees who specialize in distinct but related parts of the practice.  Since many authors adopt ineffective patterns from other technical abstracts they&rsquo;ve read, they may unwittingly submit talk proposals that are at best rhetorically impotent and at worst nonsensical to people who don&rsquo;t share their specialization.  By starting from a simple template, prospective speakers can dramatically improve their chances of being understood, accepted, and attended, while also streamlining the abstract-writing process.  Excellent abstracts benefit the entire community, because more people will be motivated to learn about interesting work that is outside of their immediate area of expertise.  In this talk, delivered by someone who has delivered many talks without any serious train wrecks and has also helped other people get talks accepted, you&rsquo;ll learn a straightforward technique for designing abstracts that communicate effectively to a general audience, sell your talk to the program committee, and motivate your peers to attend your talk.</p></blockquote>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>See also <a href="http://www.cs.cmu.edu/~jrs/sins.html">Jonathan Shewchuk on &ldquo;grandmothering&rdquo;</a> or <a href="http://www.exampler.com/testing-com/writings/final-vocabulary.html">Brian Marick on Rorty&rsquo;s concept of &ldquo;final vocabulary.&rdquo;</a><a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.4.1 released! ( October 27, 2015 )]]></title>
      <link href="manual/v8.4.1/10_3Stable_Release.html"/>
      <updated>2015-10-27T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.4.1.
A stable series release contains significant bug fixes.  This release
contains all of the bug fixes from the recent HTCondor 8.2.10 release.

Highlights of this release are:
four new policy metaknobs to make configuration easier;
a bug fix to prevent condor daemons from crashing on reconfiguration;
an option natural sorting option on condor_status;
support of admin to mount certain directories into Docker containers;
many other bug fixes, consult the version history.

Further details can be found in the
Version History.
HTCondor 8.4.1 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.2.10 released! ( October 22, 2015 )]]></title>
      <link href="manual/v8.2.10/10_3Stable_Release.html"/>
      <updated>2015-10-22T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.2.10.
A stable series release contains significant bug fixes.

Highlights of this release are:
an updated RPM to work with SELinux on EL7 platforms;
fixes to the condor_kbdd authentication to the X server;
a fix to allow the condor_kbdd to work with shared port enabled;
avoid crashes when using more than 1024 file descriptors on EL7;
fixed a memory leak in the ClassAd split() function;
condor_vacate will error out rather than ignore conflicting arguments;
a bug fix to the JobRouter to properly process the queue on restart;
a bug fix to prevent sending spurious data on a SOAP file transfer;
a bug fix to always present jobs in order in condor_history.

A complete list of fixed bugs can be found in the
Version History.
HTCondor 8.2.10 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Pacing technical talks]]></title>
      <link href="http://chapeau.freevariable.com/2015/10/pacing-technical-talks.html"/>
      <updated>2015-10-21T16:17:01Z</updated>
      <id>http://chapeau.freevariable.com/2015/10/pacing-technical-talks</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Delivering a technical talk has a lot in common with running a half-marathon or biking a 40k time trial.  You&rsquo;re excited and maybe a little nervous, you&rsquo;re prepared to go relatively hard for a relatively long time, and you&rsquo;re acutely aware of the clock.  In both situations, you might be tempted to take off right from the gun, diving into your hardest effort (or most technical material), but this is a bad strategy. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Notes from Flink Forward]]></title>
      <link href="http://chapeau.freevariable.com/2015/10/notes-from-flink-forward.html"/>
      <updated>2015-10-20T15:48:44Z</updated>
      <id>http://chapeau.freevariable.com/2015/10/notes-from-flink-forward</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/willb/22238437291/in/dateposted-public/" title="Brandenburger Tor lightshow"><img src="https://farm1.staticflickr.com/739/22238437291_22636e4a72_b.jpg" width="1024" height="819" alt="Brandenburger Tor lightshow"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script> [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.5.0 released! ( October 12, 2015 )]]></title>
      <link href="manual/v8.5.0/10_3Development_Release.html"/>
      <updated>2015-10-12T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.5.0.
This development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.4.0
stable release.

Enhancements in the release include:
multiple enhancements to the python bindings;
the condor_schedd no longer changes the ownership of spooled job files;
spooled job files are visible to only the user account by default;
the condor_startd records when jobs are evicted by preemption or draining.

Further details can be found in the
Version History.
HTCondor 8.5.0 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Library of Binary Tree Algorithms as Mixable Scala Traits]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/"/>
      <updated>2015-09-26T19:43:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I am going to describe some work I've done recently on a system of Scala traits that support tree-based collection algorithms prefix-sum, nearest key query and value increment in a mixable format, all backed by Red-Black balanced tree logic, which is also a fully inheritable trait. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.4.0 released! ( September 14, 2015 )]]></title>
      <link href="manual/v8.4.0/10_3Stable_Release.html"/>
      <updated>2015-09-14T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor version 8.4.0.
After a year of development, this is the first release of the new stable series.

This version contains:
a Docker Universe to run a Docker container as an HTCondor job;
the submit file can queue a job for each file found;
the submit file can contain macros;
a dry-run option to condor_submit to test the submit file without any actions;
HTCondor pools can use IPv4 and IPv6 simultaneously;
execute directories can be encrypted upon user or administrator request;
Vanilla Universe jobs can utilize periodic application-level checkpoints;
the administrator can establish job requirements;
numerous scalability changes.

Further details can be found in the
Version History.
HTCondor 8.4.0 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Lightweight Non-Negative Numerics for Better Scala Type Signatures]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/"/>
      <updated>2015-08-19T00:42:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I want to discuss several advantages of defining lightweight non-negative numeric types in Scala, whose primary benefit is that they allow improved type signatures for Scala functions and methods.  I'll first describe the simple class definition, and then demonstrate how it can be used in function signatures and the benefits of doing so. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Reservoir Sampling Gap Distribution]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution/"/>
      <updated>2015-08-17T14:35:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2014/09/11/faster-random-samples-with-gap-sampling/">previous post</a>, I showed that random Bernoulli and Poisson sampling could be made much faster by modeling the <em>sampling gap distribution</em> - that is, directly drawing random samples from the distribution of how many elements would be skipped over between actual samples taken. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[GPUs and adding new resources types to the HTCondor-CE]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/08/gpus-and-adding-new-resources-types-to.html"/>
      <updated>2015-08-07T21:45:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-6301136022425730449</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The more things change, the more they stay the same]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/07/the-more-things-change-more-they-stay.html"/>
      <updated>2015-07-28T15:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-8394942129716842708</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[fedmsg talk at Spark Summit]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/summit-fedmsg.html"/>
      <updated>2015-06-15T15:05:27Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/summit-fedmsg</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I&rsquo;m speaking at Spark Summit today about using Spark to analyze operational data from the Fedora project.  Here are some links to further resources related to my talk: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Spark ML Pipeline transformers]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers.html"/>
      <updated>2015-06-14T00:07:58Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post, we&rsquo;ll see how to make a simple transformer for <a href="https://spark.apache.org/docs/latest/ml-guide.html">Spark ML Pipelines</a>.  The transformer we&rsquo;ll design will generate a sparse binary feature vector from an array-valued field representing a set. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[HTCondor CacheD: Caching for HTC - Part 2]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/htcondor-cached-caching-for-htc-part-2.html"/>
      <updated>2015-01-25T15:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-5260378956420164105</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Condor CacheD: Caching for HTC - Part 1]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/condor-cached-caching-for-htc-part-1.html"/>
      <updated>2015-01-22T16:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1889975382858537261</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
</feed>
