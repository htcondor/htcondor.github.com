<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2014-03-08T03:11:19-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[Moving from a Globus to an HTCondor Compute Element]]></title>
      <link href="http://derekweitzel.blogspot.com/2014/02/moving-from-globus-to-htcondor-compute.html"/>
      <updated>2014-02-27T23:05:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-7950648301232917905</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[<div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-Cgs0xXtU0VU/Uw-7PMjMnRI/AAAAAAAACKo/xJ89GEg-JSc/s1600/GlobusVSCondor.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-Cgs0xXtU0VU/Uw-7PMjMnRI/AAAAAAAACKo/xJ89GEg-JSc/s1600/GlobusVSCondor.png" height="63" width="320" /></a></div><div class="separator" style="clear: both; text-align: center;"><br /></div>A few weeks ago, we moved our opportunistic clusters,&nbsp;<a href="https://hcc-docs.unl.edu/display/HCCDOC/Crane%2C+Tusker+and+Sandhills">Crane and Tusker</a>,&nbsp;from <a href="http://dev.globus.org/wiki/GRAM">Globus GRAM</a> gatekeepers to the new <a href="http://osgtech.blogspot.com/2013/01/introducing-htcondor-ce.html">HTCondor-CE</a>. &nbsp;We moved to the HTCondor-CE in order to solve performance issues we experienced with the GRAM when using the&nbsp;Slurm&nbsp;scheduler.<br /><br />When we switched Tusker from PBS to&nbsp;Slurm, we knew that we would have issues with the grid software.&nbsp;&nbsp;With PBS, Globus would use the scheduler event generator to efficiently watch for state changes in jobs, ie idle -&gt; running, running -&gt; completed.. &nbsp;But Globus does not have a scheduler event generator for Slurm, therefore it must query each job every few seconds in order to retrieve the current status. &nbsp;This caused a tremendous load on the scheduler, and on the machine.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-GH1ZkSWqZaI/Uw-4rBm2hSI/AAAAAAAACKc/n2P8yCaswrc/s1600/YearUsageGraph.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://3.bp.blogspot.com/-GH1ZkSWqZaI/Uw-4rBm2hSI/AAAAAAAACKc/n2P8yCaswrc/s1600/YearUsageGraph.png" height="344" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Load graph on the gatekeeper</td></tr></tbody></table>We switched to the HTCondor-CE in order to alleviate some of this querying load. &nbsp;The HTCondor-CE provides configuration options to change how often it queries for job status, and can provide system wide throttles for job status querying.<br /><br />The HTCondor-CE also provides much better transparency to aid in administration. &nbsp;For example, there is no single command in Globus to view the status of the jobs. &nbsp;In the HTCondor-CE, there is, <span style="font-family: Courier New, Courier, monospace;">condor_ce_q</span>. &nbsp;This command will tell you exactly what jobs the CE is monitoring, and what it believes is their job status. &nbsp;Or if you want to know which jobs are currently transferring input files, they will have the <span style="font-family: Courier New, Courier, monospace;">&lt;</span>&nbsp;or <span style="font-family: Courier New, Courier, monospace;">&gt;</span>&nbsp;symbols for incoming or outgoing, respectively, in their job state column.<br /><br />The HTCondor-CE uses the same authentication and authorization methods as Globus. &nbsp;You still need a certificate, and you still need to be part of a VO. &nbsp;The job submission file looks a little different, instead of gt5 as your grid resource, it is condor:<br /><div class="gistLoad" data-id="9261269" id="gist-9261269">Loading ....</div><br /><h3>Improvements for the future</h3><div>The HTCondor-CE could be improved. &nbsp;For example, each real job has 2 entries in the <span style="font-family: Courier New, Courier, monospace;">condor_ce_q</span> output. &nbsp;This is due to the job routing from the incoming job to the scheduler specific job. &nbsp;The <span style="font-family: Courier New, Courier, monospace;">condor_ce_q</span> command could be improved to show linking between the 2 jobs, similar to the dag output of the <span style="font-family: Courier New, Courier, monospace;">condor_q</span> command.</div><div><br /></div><div>The job submission file is removed after a successful or unsuccessful submission to the local batch system (Slurm). &nbsp;This can make debugging very difficult if the job submission fails for any reason. &nbsp;Further, the gatekeeper doesn't propagate stdout / stderr of the submission command into the logs.</div><h3>Final Thoughts</h3><div>The initial impressions of the HTCondor-CE have been very good. &nbsp;Since installing the new CE, we have had ~100,000 production jobs run through the gatekeeper from many different users.<br /><br />And now for the obligatory accounting graphs:<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/--Zy3N1M9BKI/Uw_CxKkEd0I/AAAAAAAACLA/T7iM8bQlhpA/s1600/glidein_dn_hours_bar.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://2.bp.blogspot.com/--Zy3N1M9BKI/Uw_CxKkEd0I/AAAAAAAACLA/T7iM8bQlhpA/s1600/glidein_dn_hours_bar.png" height="400" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Usage of Tusker as reported by GlideinWMS probes.</td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-cIMIhyJDmkw/Uw_EFHdblWI/AAAAAAAACLM/7cNjdmFLGxw/s1600/osg_vo_hours.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://3.bp.blogspot.com/-cIMIhyJDmkw/Uw_EFHdblWI/AAAAAAAACLM/7cNjdmFLGxw/s1600/osg_vo_hours.png" height="400" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Wall Hours by VO on Tusker since the transition to the HTCondor-CE</td></tr></tbody></table><br /></div><div><br /></div><div><br /></div><script src="https://raw.github.com/moski/gist-Blogger/master/public/gistLoader.js" type="text/javascript"></script>]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.1.4 released! ( February 27, 2014 )]]></title>
      <link href="manual/v8.1.4/10_3Development_Release.html"/>
      <updated>2014-02-27T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor Team is pleased to announce the release of HTCondor version 8.1.4.
This development release contains all the bug fixes from the stable release version 8.0.6.
Major new features include:
added grid universe support for Google Compute Engine;
support for defining custom resources that easily manage GPUs;
a new tool that does GPU discovery;
improved scalability when using the shared port service;
Python 3 support;
enhanced resilience due to the prompt detection of network failures.
A complete list of bugs fixed and features can be found in the
Version History.
HTCondor 8.1.4 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Bi-directional Variation of the O(NP) Edit Distance Algorithm]]></title>
      <link href="http://erikerlandson.github.com/blog/2014/02/20/a-bi-directional-variation-of-the-o-np-edit-distance-algorithm/"/>
      <updated>2014-02-21T02:51:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2014/02/20/a-bi-directional-variation-of-the-o-np-edit-distance-algorithm</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The O(ND) edit distance algorithm <a href="#ref1">[1]</a> is a standard for efficient computation of the edit distance between two sequences, appearing in applications such as the GNU diff tool.  There is also a variation <a href="#ref2">[2]</a> that operates in O(NP) time, where P is the number of deletions in the shortest edit path.  This O(NP) algorithm has a lower computational cost, since P &lt;= D/2 (and may be &lt;&lt; D/2 in some circumstances) <a href="#ref3">[3]</a>.  In order to apply these algorithms to obtain an <em>edit script</em> in linear space, they must be adapted into a bidirectional form that enables recursive divide-and-conquer.   The basic principles of a bidirectional adaptation of the O(ND) algorithm are described in <a href="#ref1">[1]</a>.   However, no such discussion of a bidirectional O(NP) algorithm is provided in <a href="#ref2">[2]</a>.  Understanding this adaptation involves some observations that aren't immediately obvious.  In this post, I will describe these key observations.</p>

<h3>Notation</h3>

<p>My code segments are written as C/C++, however written in a simplified style I hope will be clear regardless of what languages the reader is familiar with.  If you wish to port this (pseudo-ish)code, it may be worth keeping in mind that indexing is zero-based in C/C++.</p>

<h3>Sequence Lengths</h3>

<p><a name="anchor3" id="ref3">[3] </a>A brief note on the O(NP) algorithm and sequence lengths: the algorithm assumes that the length of its second sequence argument is >= its first (that is, N >= M).  Observe that total edit distance D = P+H, where P is the number of deletions and H is the number of insertions.   Note also that deletions are w.r.t. the 1st sequence, and insertions are w.r.t. the second.  Therefore, by always applying the algorithm such that N >= M, we keep P &lt;= H and hence P &lt;= D/2.  In cases where N >> M, then we see that P &lt;&lt; H and also P &lt;&lt; D/2.</p>

<p>In the following discussions, I will also assume that N >= M for simplicity, however the modification to address N &lt; M is relatively easy, and can be seen in the references to actual source code below.</p>

<h3>Indexing</h3>

<p>A note on naming:  In <a href="#ref2">[2]</a>, the authors use 'fp' for the name of the array holding path endpoints.  I will use 'Vf' for the array holding forward endpoints, and 'Vr' for the corresponding array holding reverse endpoints.</p>

<p>The O(ND) and O(NP) algorithms operate by iteratively extending the frontier of edit paths through the implicit graph of possible paths, where each iteration is computed as a function of the previous.  In the O(NP) algorithm, this computation has to proceed from the outside in, as described in the paper:</p>

<pre><code>for (k = -P;  k &lt; delta;  k += 1) {
    y = max(Vf[k-1] + 1, Vf[k+1]);
    Vf[k] = snake(y-k, y);
}
for (k = P + delta;  k &gt;= delta;  k -= 1) {
    y = max(Vf[k-1] + 1, Vf[k+1]);
    Vf[k] = snake(y-k, y);
}
</code></pre>

<p>In order to implement a bi-directional algorithm, we must also run the algorithm in reverse, beginning at the "lower right corner" of the graph (M,N) and working backward to the origin (0,0).  The indexing is the mirror image of the above:</p>

<pre><code>for (k = P+delta;  k &gt; 0;  k -= 1) {
    y = min(Vr[k-1], Vr[k+1] - 1);
    Vr[k] = rsnake(y-k, y);
}
for (k = -P;  k &lt;= 0;  k += 1) {
    y = min(Vr[k-1], Vr[k+1] - 1);
    Vr[k] = rsnake(y-k, y);
}
</code></pre>

<p>In the above, 'rsnake' is the reverse-direction snake function.  A note on initialization:  whereas the forward algorithm initializes its Vf array to (-1), the symmetric initial value for the reverse algorithm Vr array is (N+1) (In the general case, 1 plus the length of the longest sequence).</p>

<h3>Detecting Path Overlap</h3>

<p>The uni-directional O(NP) algorithm halts when Vf[delta] == N.  However, the bi-directional algorithms halt when shortest opposing paths meet -- or overlap -- each other, as described in the O(ND) paper <a href="#ref1">[1]</a>.  The semantics of storing paths in working arrays is the same in both algorithms, with the exception that in the O(NP) algorithm it is the (y) values that are stored.  Myers describes the predicate for detecting meeting paths in O(ND) as: (x >= u)  &amp;&amp;  (x-y == u-v), where (x,y) are forward endpoints and (u,v) are reverse endpoints.  Observe that since y = x-k, then (x-y == u-v) is equivalent to "forward-k == reverse-k".  However, in operation one always checks the opposing path with the <em>same</em> k index, and so this clause is redundant.  It is sufficient to check that (x >= u), or in the case of O(NP), that (y >= v).  In the code, this looks something like:</p>

<pre><code>y = max(Vf[k-1] + 1, Vf[k+1]);
if (y &gt;= Vr[k]) {
    // overlapping paths detected 
}
</code></pre>

<p>The other checks for forward and reverse are similar.  Note that these checks happen at the <em>beginning</em> of each 'snake', that is prior to invoking the snake extension logic.  The semantic is that the opposing path overlaps the run (snake) one is about to start.</p>

<h3>Computing Distance</h3>

<p>When two overlapping paths are detected, we must compute the path distance associated with their union.  In the O(ND) algorithm, we know that distance implicitly, as the paths are extended over successive iterations of D.  In the O(NP) algorithm, however, the current path endpoints are associated with a particular value of P, and so we must consider how to obtain the actual distance.</p>

<p>A little algebra comes to the rescue.  At iteration P, consider the number of deletions along the forward-path at the kth endpoint, which I will denote as 'vf' (the authors refer to it as V(x,y)).  In <a href="#ref2">[2]</a>, the authors show that P == vf when k &lt; delta, and P == vf+k-delta, when k > delta (note that either formula applies for k == delta).  Solving for vf, we have:   vf == P for k &lt; delta and vf == P+delta-k for k > delta.  The authors also show that: vf = (df-k)/2, where df is the total edit distance along the path up to the current endpoint (the authors refer to df as D(x,y)).   Therefore, we have: df = 2(vf)+k, where we can obtain vf from the expression we just derived.</p>

<p>It remains to derive the expressions for the reverse direction, where we want 'vr' and 'dr'.  Here, I note that the mirror-image indexing of the reverse algorithm implies that the expressions above work if we transform k --> delta-k.  Making that transform gives us:   vr == P for k > 0 and vr == P+k for k &lt; 0 (again, either applies for k == 0).  And dr = 2(vr)+delta-k.</p>

<p>And so the actual edit distance covered by our overlapping paths is:  d == (df+dr) == 2(vf+vr)+delta.  Note now pleasing this is, as vf+vr is the number of deletions of the combined paths, and so this corresponds to the original formula D == 2P+delta, where P is the number of deletions over the entire pathway.  We also see from the above that at a given Pth iteration, P does <em>not</em> equal the number of deletions in all paths with endpoints at the current iteration.  The true number of deletions for a given endpoint is a function of P, k and delta.</p>

<p>A note on implementation: when one is advancing forward paths, an overlapping reverse-path will be from previous iteration (P-1), as the reverse paths for (P) have not happened yet.  That will show up in the distance formula for (vr) by using (P-1) in place of P, as in this example code:</p>

<pre><code>y = max(Vf[k-1] + 1, Vf[k+1]);
if (y &gt;= Vr[k]) {
    // we found overlapping path, so compute corresponding edit distance
    vf = (k&gt;delta) ? (P + delta - k) : P;
    // use (P-1) for reverse paths:
    vr = (k&lt;0) ? (P-1 + k) : P-1;
    d = 2*(vf+vr)+delta;
}

// ....

y = min(Vr[k-1], Vr[k+1] - 1);
if (y &lt;= Vf[k]) {
    // we can use P for both since forward-paths have been advanced:
    vf = (k&gt;delta) ? (P + delta - k) : P;
    vr = (k&lt;0) ? (P + k) : P;
    d = 2*(vf+vr)+delta;
}
</code></pre>

<h3>Shortest Path</h3>

<p>With respect to halting conditions, the O(NP) algorithm differs in one imporant way from the O(ND) algorithm: The O(ND) algorithm maintains path endpoints corresponding to increasing <em>distance</em> (D) values.  Therefore, when two paths meet, they form a shortest-distance path by definition, and the algorithm can halt on the first such overlap it detects.</p>

<p>The same is <em>not true</em> for the O(NP) algorithm.  It stores endpoints at a particular P value.  However, at a given value of P, actual <em>distances</em> may vary considerably.  On a given iteration over P, actual path distances may vary from 2(P-1)+delta up to 4P+delta.</p>

<p>This problem is dealt with by maintaining a best-known distance, 'Dbest', which is initialized to its maximum possible value of N+M, the sum of both sequence lengths.  Whenever two overlapping paths are detected, their corresponding distance 'd' is computed as described earlier, and the running minimum is maintainted:  Dbest = min(Dbest,d).  As mentioned above, we know that the mimimum possible distance at a given iteration is Dmin = 2(P-1)+delta, and so when Dmin >= Dbest, we halt and return Dbest as our result.</p>

<h3>Loop Bounding</h3>

<p>Some important computational efficiency can be obtained by reorganizing the looping over the endpoints.   As mentioned above, conceptually the looping proceeds from the outside, inward.  Suppose we organize the looping over k values such that we explore k = {-P, P+delta, -P+1, P+delta-1, -P+2, P+delta-2 ... }  Note that the symmetry breaks a bit when we get to k==delta, as here we stop iterating backward, but continue iterating forward until we hit delta from below.  In the code, this looping pattern looks something like:</p>

<pre><code>// advance forward paths: reverse path looping is similar
for (ku = -P, kd = P+delta;  ku &lt;= delta;  ku += 1) {
    // advance diagonals from -P, upwards:
    y = max(1+Vf[ku-1], Vf[ku+1]);

    // check for overlapping path

    Vf[ku] = snake(y-ku, y);

    // stop searching backward past here:
    if (kd &lt;= delta) continue;

    // advance diagonals from P+delta, downwards:
    y = max(1+Vf[kd-1], Vf[kd+1]);

    // check for overlapping path

    Vf[kd] = snake(y-kd, y);
    kd -= 1;
}
</code></pre>

<p>There is method to this madness.  Observe that for any particular P value, the smallest edit distances are at the outside, and get larger as one moves inward.  The minimum distance 2P+delta is always when k == -P, and k == P+delta.  As we proceed inward, the corresponding edit distance increases towards its maximum of 4P+delta.   This allows <em>two</em> optimizations.  The first is that if we hit an overlapping path, we can now exit the loop immediately, as we know that any other such overlapping paths to our inside will have a larger edit distance, and so do not need to be considered.</p>

<p>The second optimization is to recall that path distances are a function of P, k and delta.  We can use this information to solve for k and obtain a useful adaptive bound on how far we loop.  From previous sections, also recall we are keeping a best-known distance Dbest.  We know that we do not have to explore any paths whose distance is >= Dbest.  So, we can set up the following inequality: 2(vf+vr)+delta &lt; Dbest, where vf = P, and vr = (P-1)+k, where k &lt; 0, which is the region where distance is growing.  Therefore, we have 2(P+(P-1)+k)+delta &lt; Dbest.  Solving for k, we have:  k &lt; ((Dbest-delta)/2)-2P+1.  The looping wants to use '&lt;=', so we can rewrite as: k &lt;= ((Dbest-delta-1)/2)-2P+1.  For the reverse-path looping, we can set up a similar inequality:  2(P+P+delta-k)+delta &lt; Dbest, which yields:  k >= ((1+delta-Dbest)/2)+delta+2P.</p>

<p>Note that if these bound expressions evaluate to a value past the nominal bound, then the nominal bound remains in effect: e.g. the operative forward looping bound = min(delta, ((Dbest-delta)/2)-2P).   Also note that these constraints do not break the computation of the endpoints, because when the bounds move, they always retreat toward the outside by 2 on each iteration of P.  Since computation proceeds outside in, that means the necessary values are always correctly populated from the previous iteration.</p>

<p>In the code, the forward path looping looks like this:</p>

<pre><code>// compute our adaptive loop bound (using P-1 for reverse)
bound = min(delta, ((Dbest-delta-1)/2)-(2*P)+1);

// constrain our search by bound:
for (ku = -P, kd = P+delta;  ku &lt;= bound;  ku += 1) {
    y = max(1+Vf[ku-1], Vf[ku+1]);
    if (y &gt;= Vr[k]) {
        vf = (k&gt;delta) ? (P + delta - k) : P;
        vr = (k&lt;0) ? (P-1 + k) : P-1;

        // maintain minimum distance:
        Dbest = min(Dbest, 2*(vf+vr)+delta);

        // we can now halt this loop immediately:
        break;
    }

    Vf[ku] = snake(y-ku, y);

    if (kd &lt;= delta) continue;

    y = max(1+Vf[kd-1], Vf[kd+1]);
    if (y &gt;= Vr[k]) {
        vf = (k&gt;delta) ? (P + delta - k) : P;
        vr = (k&lt;0) ? (P-1 + k) : P-1;

        // maintain minimum distance:
        Dbest = min(Dbest, 2*(vf+vr)+delta);

        // we can now halt this loop immediately:
        break;
    }

    Vf[kd] = snake(y-kd, y);
    kd -= 1;
}
</code></pre>

<h3>Implementation</h3>

<p>In conclusion, I will display a code segment with all of the ideas presented above, coming together.  This segment was taken from my <a href="https://github.com/erikerlandson/algorithm/blob/order_np_alg/include/boost/algorithm/sequence/detail/edit_distance.hpp#L342">working prototype code</a>, with some syntactic clutter removed and variable names changed to conform a bit more closely to <a href="#ref2">[2]</a>.  The implementation of O(NP) below is performing about 25% faster than the corresponding O(ND) algorithm in my benchmarking tests, and also uses substantially less memory.</p>

<pre><code>// initialize this with the maximum possible distance:
Dbest = M+N;

P = 0;
while (true) {
    // the minimum possible distance for the current P value
    Dmin = 2*(P-1) + delta;

    // if the minimum possible distance is &gt;= our best-known distance, we can halt
    if (Dmin &gt;= Dbest) return Dbest;

    // adaptive bound for the forward looping
    bound = min(delta, ((Dbest-delta-1)/2)-(2*P)+1);

    // advance forward diagonals
    for (ku = -P, kd = P+delta;  ku &lt;= bound;  ku += 1) {
        y = max(1+Vf[ku-1], Vf[ku+1]);
        x = y-ku;

        // path overlap detected
        if (y &gt;= Vr[ku]) {
            vf = (ku&gt;delta) ? (P + delta - ku) : P;
            vr = (ku&lt;0) ? (P-1 + ku) : P-1;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend forward snake
        if (N &gt;= M) {
            while (x &lt; M  &amp;&amp;  y &lt; N  &amp;&amp;  equal(S1[x], S2[y])) { x += 1;  y += 1; }
        } else {
            while (x &lt; N  &amp;&amp;  y &lt; M  &amp;&amp;  equal(S1[y], S2[x])) { x += 1;  y += 1; }
        }

        Vf[ku] = y;

        if (kd &lt;= delta) continue;

        y = max(1+Vf[kd-1], Vf[kd+1]);
        x = y-kd;

        // path overlap detected
        if (y &gt;= Vr[kd]) {
            vf = (kd&gt;delta) ? (P + delta - kd) : P;
            vr = (kd&lt;0) ? (P-1 + kd) : P-1;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend forward snake
        if (N &gt;= M) {
            while (x &lt; M  &amp;&amp;  y &lt; N  &amp;&amp;  equal(S1[x], S2[y])) { x += 1;  y += 1; }
        } else {
            while (x &lt; N  &amp;&amp;  y &lt; M  &amp;&amp;  equal(S1[y], S2[x])) { x += 1;  y += 1; }
        }

        Vf[kd] = y;
        kd -= 1;
    }

    // adaptive bound for the reverse looping
    bound = max(0, ((1+delta-Dbest)/2)+delta+(2*P));

    // advance reverse-path diagonals:
    for (kd=P+delta, ku=-P;  kd &gt;= bound;  kd -= 1) {
        y = min(Vr[kd-1], Vr[kd+1]-1);
        x = y-kd;

        // path overlap detected
        if (y &lt;= Vf[kd]) {
            vf = (kd&gt;delta) ? (P + delta - kd) : P;
            vr = (kd&lt;0) ? (P + kd) : P;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend reverse snake
        if (N &gt;= M) {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[x-1], S2[y-1])) { x -= 1;  y -= 1; }
        } else {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[y-1], S2[x-1])) { x -= 1;  y -= 1; }
        }

        Vr[kd] = y;

        if (ku &gt;= 0) continue;

        y = min(Vr[ku-1], Vr[ku+1]-1);
        x = y-ku;

        // path overlap detected
        if (y &lt;= Vf[ku]) {
            vf = (ku&gt;delta) ? (P + delta - ku) : P;
            vr = (ku&lt;0) ? (P + ku) : P;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend reverse snake
        if (N &gt;= M) {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[x-1], S2[y-1])) { x -= 1;  y -= 1; }
        } else {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[y-1], S2[x-1])) { x -= 1;  y -= 1; }
        }

        Vr[ku] = y;
        ku += 1;
    }
}
</code></pre>

<h3>References</h3>

<p><a name="anchor1" id="ref1">[1] </a><a href="http://www.xmailserver.org/diff2.pdf">An O(ND) Difference Algorithm and its Variations</a>, Eugene W. Myers<br>
<a name="anchor2" id="ref2">[2] </a><a href="http://www.itu.dk/stud/speciale/bepjea/xwebtex/litt/an-onp-sequence-comparison-algorithm.pdf">An O(NP) Sequence Comparison Algorithm</a>, Sun Wu, Udi Manber, Gene Myers</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[sbt is in Fedora 20]]></title>
      <link href="http://chapeau.freevariable.com/2014/02/sbt-is-in-fedora-20.html"/>
      <updated>2014-02-20T22:27:57Z</updated>
      <id>tag:chapeau.freevariable.com,2014://1.44</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[
        <p>Longtime Chapeau readers may recall <a href="http://chapeau.freevariable.com/2013/08/making-fedora-a-better-place-for-scala.html">last summer&#8217;s lament</a> about the state of the Scala ecosystem in Fedora.  We&#8217;ve taken a lot of steps since then.  After a rough patch for the Fedora Scala package, <a href="https://github.com/willb/scala-packaging">Scala 2.10 is available</a> and works again on all current Fedora releases and Rawhide.  We&#8217;ve added more Scala packages to Fedora as well, including <a href="https://admin.fedoraproject.org/pkgdb/acls/name/scalacheck">scalacheck</a>, <a href="https://admin.fedoraproject.org/pkgdb/acls/name/sbinary">sbinary</a>, and <a href="https://admin.fedoraproject.org/pkgdb/acls/name/test-interface">test-interface</a>.  Today I&#8217;m especially pleased to announce that, by the time you read this, <a href="https://admin.fedoraproject.org/updates/sbt-0.13.1-4.fc20"><code>sbt</code> 0.13.1 will be available in Fedora 20 testing</a>.</p>

<p>Having <code>sbt</code> available in Fedora means that we can start packaging more of the Scala ecosystem in Fedora.  In fact, the <code>sbt</code> package in Fedora is primarily intended for use building Scala packages for Fedora.  While you&#8217;ll be able to use it for general Scala development, it has several important limitations in order to comply with the Fedora packaging guidelines:  most notably, you won&#8217;t be able to cross-compile libraries for different Scala versions with it or launch different versions of <code>sbt</code> for different projects.  (I use <a href="https://github.com/paulp/sbt-extras"><code>sbt-extras</code></a>, which I&#8217;ve renamed to <code>xsbt</code>, for my general Scala development.)</p>

<p>In the future (i.e. F21 and on), <code>sbt</code>-based Fedora builds will be greatly streamlined by improved Ivy support in an upcoming version of <code>xmvn</code>.  For now, we have to manage dependencies somewhat manually using scripts and macros, but it&#8217;s absolutely straightforward.    To get started building Scala projects for Fedora right now, <a href="https://fedoraproject.org/wiki/SIGs/bigdata/packaging/Sbt">check out these guidelines I wrote up for the Big Data SIG</a> and let me know if you have any trouble.  There are many example spec files using <code>sbt</code> available <a href="https://github.com/willb/">among my Github repositories</a>.</p>

<p>This was a big effort and thanks are due to several people, including Mark Harrah, who offered a lot of advice on <code>sbt</code> itself and gave prompt and thorough feedback on my patches; Mikołaj Izdebski, who helped a lot with my understanding of Java dependency resolution in Fedora and implemented improved support for Ivy resolution in <code>xmvn</code>; Rob Rati, who took on the task of reviewing the <code>sbt</code> package and did a thoughtful and careful job; and the Fedora Packaging Committee for their quick and helpful response to my request for a bootstrap-binary exception.</p>

<p>I&#8217;m looking forward to seeing new Scala projects packaged for Fedora soon!</p>

        

    ]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ Consider presenting your work at HTCondor Week 2014 ( February 20, 2014 )]]></title>
      <link href="http://research.cs.wisc.edu/htcondor/HTCondorWeek2014/speaker_info.html"/>
      <updated>2014-02-20T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[HTCondor Week attendees are interested in hearing about your efforts during
our annual meeting, April 28-30.
Please consider presenting.
Details for adding your talk to the schedule are given in this page of
Information for HTCondor Week Speakers.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[One weird trick to eviscerate open source licenses]]></title>
      <link href="http://chapeau.freevariable.com/2014/02/one-weird-trick-to-eviscerate-open-source-licenses.html"/>
      <updated>2014-02-19T17:26:28Z</updated>
      <id>tag:chapeau.freevariable.com,2014://1.43</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[
        <p>The GNU project&#8217;s <a href="http://www.gnu.org/philosophy/free-sw.html">Four Freedoms</a> present the essential components of Free software:  freedom to use the program for any purpose, freedom to study and change the program&#8217;s source code, freedom to redistribute the author&#8217;s version of the code, and freedom to distribute your modifications.  While not everyone who publishes their source code for others to use cares about freedom as the FSF defines it, these principles also <a href="http://opensource.org/docs/osd">motivate common open-source licenses</a>.  This post will discuss a surprisingly common obstacle to software freedom and show how you can avoid it in your own projects.</p>

        <p>Most open-source licenses are designed to ensure freedom.  However, some developers insist on publishing their work under licenses that start from a well-known license and tack on some behavioral incentives.  These certainly don&#8217;t actually prevent software users from engaging in the proscribed behaviors; rather, they just prevent people — even those who are unlikely to be affected by the behavioral incentives — from using these projects.  These clauses are essentially flourishes of ego, pauses for laugh lines that are intended to force us to stop and acknowledge how clever the author is.  It&#8217;s not funny, though, that projects distributed under these novelty license agreements — and projects that depend on libraries so distributed — are unavailable to any users or developers who care about freedom (or those who care about the liability induced by vague contractual terms).</p>

<h4>Some examples</h4>

<p>Probably the most infamous example is the JSON.org license, which adds &#8220;This Software should be used for Good, not Evil&#8221; to the MIT license, and which <a href="http://innuendopoly.org/arch/functor/licensing">Douglas Crockford apparently intended as a joke about the absolutist moral language used to promote Bush-era foreign policy</a>.  (One must note that this joke was almost stale when he wrote the license in 2002; it certainly appears dated in 2014, now that American drone killings have been full of sophisticated nuance for years.)  I can&#8217;t imagine that this clause has prevented anyone from doing evil with serialized Javascript objects; rather, it just motivated attorneys to ask for exceptions to the license, forced other <a href="https://fedoraproject.org/wiki/Licensing:Main?rd=Licensing#Bad_Licenses">developers to eschew Crockford&#8217;s library</a>, and inspired <a href="https://android.googlesource.com/platform/libcore/+/master/json">wheel-reinvention</a>.</p>

<p>A more insidious example is the long-abandoned (but <a href="http://mvnrepository.com/artifact/colt/colt/1.2.0">surprisingly ubiquitous</a>) <a href="http://acs.lbl.gov/software/colt/">Colt library</a>, which bundles an old fork of the FreeHEP AIDA library that was apparently initially distributed under the LGPL with usage restrictions.  Since Colt isn&#8217;t compatible with the current upstream AIDA interfaces and since the usage restrictions make the license for Colt non-free, there is no way to include Colt or projects that require it in Fedora.  (As an aside, you obviously can&#8217;t add usage restrictions when redistributing something originally licensed under the LGPL; additional restrictions are incompatible with the LGPL.  If your goal is to distribute a new work with usage restrictions, the LGPL is probably an inappropriate starting point.)</p>

<p>Finally, <a href="https://twitter.com/hguemar/status/435873770805264384">Haïkel Guemar reminds me</a> of an <a href="https://github.com/landondyer/kasm/blob/master/LICENSE">especially silly software license</a>, which allows completely unrestricted rights to everyone except Richard Stallman.  Stallman, however, is explicitly prohibited from using the software for any purpose.  (I&#8217;m sure Stallman is heartbroken that he&#8217;s unable to use a toy 6502 assembler.)</p>

<h4>Conclusions</h4>

<p>Behavioral incentives and other morality clauses have no place in open-source licensing.  (Put another way, if you can&#8217;t use the software for any purpose, why do you care whether or not you can distribute derivative works?)  If you care about making your work freely available, you should recoil at behavioral incentives in putatively open-source licenses in the same way you&#8217;d be horrified by:</p>

<ol>
<li>proprietary licenses for development tools that <a href="http://en.wikipedia.org/wiki/BitKeeper#License_concerns">prohibit you from working on certain kinds of software</a>,</li>
<li>proprietary licenses for systems software that <a href="http://en.wikipedia.org/wiki/David_DeWitt#The_.22DeWitt_Clause.22">forbid you from talking about how well the system works</a> without clearing it with the manufacturer first, or</li>
<li>laws that <a href="http://en.wikipedia.org/wiki/Digital_Millennium_Copyright_Act">make trivial programs illegal</a> if they could be used to circumvent copy-protection measures.</li>
</ol>

<p>To ensure that anyone can freely use and build on your work, if that is your aim, don&#8217;t introduce incentives or morality clauses into your license.  License it under a free and open-source license.  Use a well-known license with well-understood legal implications; your bespoke license is unlikely to solve any new problems, but is likely to be vague enough to create uncertainty and inhibit adoption of your work.  Do not bundle code or libraries distributed under restrictive licenses.  (Not bundling code <em>at all</em> is actually a good practice.)  Finally, only (transitively or immediately) depend on libraries that are freely licensed.</p>

    ]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Hot Rod Hadoop with Tachyon on Fedora 21 (Rawhide)]]></title>
      <link href="http://timothysc.github.com/blog/2014/02/17/bdas-tachyon/"/>
      <updated>2014-02-17T16:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2014/02/17/bdas-tachyon</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><img class="left" src="http://timothysc.github.com/images/Tachyon.jpg" title="" ></p>

<h2>Background</h2>

<p>Within the last couple of years we&#8217;ve witnessed a natural evolution in
the &#8220;Big Data&#8221; ecosystem.  Where the common theme that you&#8217;ve probably heard in the
community that, &#8220;Memory is King&#8221;, and it is.  Therefore, if you are looking for performance
optimization in your stack, an &#8220;in memory&#8221; layer should be part of
the equation.  Enter <em>Tachyon</em>, which provides reliable file sharing across cluster
frameworks.</p>

<p>Tachyon can be used to support different framworks, as well as different filesystems.
So to bound the scope of this post, we will outline how to setup Tachyon on a local installation
to boost performance of map-reduce application whose data is stored in HDFS on Fedora 21.</p>

<hr />

<h2>Special Thanks</h2>

<p>Tachyon is a recent addition to the Fedora channels, and it would not have been possible
without the efforts of <a href="https://github.com/haoyuan">Haoyuan Li</a>, Gil Cattaneo,
and <a href="http://chapeau.freevariable.com/">William Benton</a></p>

<hr />

<h2>References</h2>

<ul>
<li><a href="https://amplab.cs.berkeley.edu/software/">BDAS Stack</a></li>
<li><a href="http://youtu.be/4lMAsd2LNEE">YouTube - Introduction to Tachyon</a></li>
<li><a href="http://tachyon-project.org/">Tachyon project</a></li>
<li><a href="https://fedoraproject.org/wiki/SIGs/bigdata">Fedora BIG Data SIG</a></li>
<li><a href="http://labs.ericsson.com/blog/going-beyond-hadoop-some-insights-for-big-data-platforms">Going beyond Hadoop</a></li>
</ul>


<hr />

<h2>Prerequisites</h2>

<ul>
<li><a href="http://fedoraproject.org/en/get-fedora">Latest Fedora Machine</a></li>
<li><a href="http://timothysc.github.io/blog/2013/09/14/hadoop-mapreduce/">Bootstrapping Your MapReduce 2.X Programming on Fedora 20</a></li>
</ul>


<hr />

<h2>Installation and Setup</h2>

<p>Prior to installing Tachyon please ensure that you have setup your hadoop installation
as outlined in the pre-reqs.</p>

<p>First you will need to install the tachyon package:</p>

<pre><code>$ sudo yum install amplab-tachyon
</code></pre>

<p>Now you will need to update /etc/hadoop/core-site.xml configuration for hadoop to
enable map-reduce to take advantage of tachyon, by appending the following snippet:</p>

<pre><code>&lt;property&gt;
  &lt;name&gt;fs.tachyon.impl&lt;/name&gt;
  &lt;value&gt;tachyon.hadoop.TFS&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>Now that all the plumbing is in place you can restart hadoop</p>

<pre><code>systemctl restart hadoop-namenode hadoop-datanode hadoop-nodemanager hadoop-resourcemanager
</code></pre>

<p>Next, make certain your local HDFS instance is up and running, then
you will need to perform a tachyon format.</p>

<pre><code>$ sudo runuser hdfs -s /bin/bash /bin/bash -c "tachyon.sh format"
&gt; Formatting Tachyon @ localhost
&gt; Deleting /var/lib/tachyon/journal/
&gt; Formatting hdfs://localhost:8020/tachyon/data
&gt; Formatting hdfs://localhost:8020/tachyon/workers
</code></pre>

<hr />

<h3>Initialization</h3>

<p>Prior to running the daemons you will need to mount the in-memory filesystem.</p>

<pre><code>$ sudo tachyon-mount.sh SudoMount
</code></pre>

<p>Now you can start the daemons.</p>

<pre><code>$ sudo systemctl start tachyon-master tachyon-slave
</code></pre>

<p>For completeness you can inspect the logs which are located in the standard system location</p>

<pre><code>$ ls -la /var/log/tachyon
</code></pre>

<hr />

<h3>Operation</h3>

<p>Once you&#8217;ve verified tachyon is up and running, you can run a simple mapreduce application
as seen below:</p>

<pre><code>$ hadoop jar /usr/share/java/hadoop/hadoop-mapreduce-examples.jar wordcount
  tachyon://localhost:19998/user/tstclair/input/constitution.txt
  tachyon://localhost:19998/test1
</code></pre>

<p>You&#8217;ll notice tha tachyon prefix attached to the input and output locations.  This enables
hadoop to start the TFS shim which will load and write to tachyon.  To verify you can run the following:</p>

<pre><code>$ sudo runuser hdfs -s /bin/bash /bin/bash -c "tachyon.sh tfs ls /test1"
&gt; 16.65 KB  02-17-2014 15:41:11:849  In Memory      /test1/part-r-00000
&gt; 0.00 B    02-17-2014 15:41:12:366  In Memory      /test1/_SUCCESS
</code></pre>

<p>If you&#8217;re interested in grok&#8217;ing further you can probably find the part file under /mnt/ramdisk.</p>

<h2>Summary</h2>

<p>Tachyon provides reliable in memory file sharing across cluster frameworks, as we have seen
in our simple example. It also enables some very interesting prospects for other back end filesystems.</p>

<p>In future posts we&#8217;ll explore more elaborate configurations using tachyon atop different frameworks and filesystems.</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.0.6 released! ( February 11, 2014 )]]></title>
      <link href="manual/v8.0.6/10_3Stable_Release.html"/>
      <updated>2014-02-11T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.0.6.
This new version contains a port of HTCondor for Red Hat Enterprise Linux 7.0 Beta on the x86_64 architecture that includes support for the standard universe.
It also contains bug fixes for:
transferring files larger then 4 GiB on Windows and 32-bit platforms;
using a minimum of 1024-bit keys on proxy certificates generated by HTCondor;
accepting DAG input files larger then 2 GiB;
the Windows MSI installer setting up a proper configuration for the VM universe;
honoring CPU affinity on Windows platforms;
issues with a failing condor_schedd daemon, when HTCondor is compiled with gcc 4.8+, the default compiler on recent Fedora releases.
A complete list of bugs fixed can be found in the
Version History.
HTCondor 8.0.6 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor Week 2014 Announced: April 28-30 (January 10, 2014)]]></title>
      <link href="http://research.cs.wisc.edu/htcondor/HTCondorWeek2014/index.html"/>
      <updated>2014-01-10T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[
HTCondor Week 2014, our annual HTCondor user conference, is
scheduled for April 28-April 30, 2014.  We will again host
HTCondor Week at the Wisconsin Institutes for Discovery in
beautiful Madison, Wisconsin.

In a change from previous years, technical talks will begin on
Monday.  See the web site for current details.

At HTCondor Week, you can look forward to:


Technical talks on usage and deployment from developers and
  your fellow users
Talks and tutorials on new HTCondor features
Talks on future plans for HTCondor
Introductory tutorials on using and administrating HTCondor
The opportunity to meet with HTCondor developers and other users

	Information on registration and scheduling will be available soon.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.1.3 released! ( December 23, 2013 )]]></title>
      <link href="manual/v8.1.3/10_3Development_Release.html"/>
      <updated>2013-12-23T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor Team is pleased to announce the release of HTCondor version 8.1.3.
This development release contains all the bug fixes from the stable release version 8.0.5.
Major new features include:
the parsing of configuration has changed such that comments are permitted within multi-line definitions;
the condor_sos tool helps administrators manage overloaded daemons by causing commands to be handled with a higher priority;
a new Python binding reads event logs.
A complete list of bugs fixed and features can be found in the 
Version History.
HTCondor 8.1.3 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A simple machine learning app with Spark]]></title>
      <link href="http://chapeau.freevariable.com/2013/12/a-simple-machine-learning-app-with-spark.html"/>
      <updated>2013-12-04T13:47:26Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.42</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[I'm currently on my way back from the first-ever Spark Summit, where I presented a talk on some of my work with the Fedora Big Data SIG to package Apache Spark and its infrastructure for Fedora. (My slides are online,...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Apache Thrift in Fedora]]></title>
      <link href="http://chapeau.freevariable.com/2013/10/apache-thrift-in-fedora.html"/>
      <updated>2013-10-16T19:58:16Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.41</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[You probably already know that Apache Thrift is a framework for developing distributed services and clients to access these in multiple languages. You probably also knew that Thrift is extremely popular among the sorts of cool projects that those of...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bootstrapping your MapReduce 2.X programming on Fedora 20]]></title>
      <link href="http://timothysc.github.com/blog/2013/09/14/hadoop-mapreduce/"/>
      <updated>2013-09-14T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/09/14/hadoop-mapreduce</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><img src="http://timothysc.github.com/images/ElephantCowboy.jpg" alt="Picture Courtesy of Mauro Flores jr"/> [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Making Fedora a better place for Scala]]></title>
      <link href="http://chapeau.freevariable.com/2013/08/making-fedora-a-better-place-for-scala.html"/>
      <updated>2013-08-05T17:14:10Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.40</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Scala combines a lot of excellent features (functional-style pattern matching, an expressive type system, closures, etc.) with JVM compatibility and a very interesting developer ecosystem (e.g., Akka, Play, Lift, scalacheck, and Spark, just to name a few notable projects). Fedora...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Creating a native Mac Installer for Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/07/creating-native-mac-installer-for-bosco.html"/>
      <updated>2013-07-11T20:34:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9151105712164146929</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Leveraging systemd cgroup integration to provide SLAs on Fedora 18 & 19]]></title>
      <link href="http://timothysc.github.com/blog/2013/06/14/systemd-cgroup-sla/"/>
      <updated>2013-06-14T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/06/14/systemd-cgroup-sla</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Submitting R jobs with Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/05/submitting-r-jobs-with-bosco.html"/>
      <updated>2013-05-20T14:51:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9067247722276578550</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Configuring a Personal Hadoop Development Environment on Fedora 18]]></title>
      <link href="http://timothysc.github.com/blog/2013/04/22/personalhadoop/"/>
      <updated>2013-04-22T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/04/22/personalhadoop</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Reprocessing CMS events with Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/04/reprocessing-cms-events-with-bosco.html"/>
      <updated>2013-04-02T19:38:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9221383956864186778</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Impact of Negotiator Cycle Cadence on Slot Loading]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading/"/>
      <updated>2013-03-21T22:10:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_1Introduction.html#8555">HTCondor negotiator</a> assigns jobs (resource requests) to slots (compute resources) at regular intervals, configured by the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#20544">NEGOTIATOR_INTERVAL</a> parameter.  This interval (the cycle <em>cadence</em>) has a fundamental impact on a pool <em>loading factor</em> -- the fraction of time that slots are being productively utilized. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Smooth Gradients for Cubic Hermite Splines]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/"/>
      <updated>2013-03-16T14:39:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, ... m_{n-1} \) at knot-points: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Examining the Modulus of Random Variables]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/"/>
      <updated>2013-03-15T19:03:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h3>Motivation</h3> [...]
]]></content>
    </entry>
  
</feed>
