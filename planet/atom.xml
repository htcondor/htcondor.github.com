<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2016-04-02T03:30:13-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[ Join us at HTCondor Week 2016! ( March 30, 2016 )]]></title>
      <link href="http://research.cs.wisc.edu/htcondor/HTCondorWeek2016/"/>
      <updated>2016-03-30T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[We want to invite you to

HTCondor Week 2016, our annual HTCondor user
conference, in beautiful Madison, Wisconsin, May 17-20, 2016. We will
again host HTCondor Week at the Wisconsin Institutes for Discovery, a
state-of-the-art facility for academic and private research specifically
designed to foster private and public collaboration. It provides HTCondor Week
attendees with a compelling environment in which to attend tutorials and talks
from HTCondor developers and users like you. It also provides many comfortable
spaces for one-on-one or small group collaborations throughout the week.

Our current development series, 8.5, is well underway toward our upcoming
production release. When you attend, you will learn how to take advantage of
the latest features. You'll also get a peek into our longer term development
plans--something you can only get at HTCondor Week!

We will have a variety of in-depth tutorials and talks where you can not
only learn more about HTCondor, but you can also learn how other people are
using and deploying HTCondor. Best of all, you can establish contacts and
learn best practices from people in industry, government, and academia who
are using HTCondor to solve hard problems, many of which may be similar to
those you are facing.

Speaking of learning from the community, we'd love to have you give
a talk at HTCondor Week. Talks are 15-20 minutes long and are a great
way share your ideas and get feedback from the community. If you have a
compelling use of HTCondor you'd like to share, see our

speaker's page.

You can register, get hotel details, and see the
agenda overview on the
HTCondor Week 2016 site.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Computing Simplex Vertex Locations From Pairwise Object Distances]]></title>
      <link href="http://erikerlandson.github.com/blog/2016/03/26/computing-simplex-vertex-locations-from-pairwise-vertex-distances/"/>
      <updated>2016-03-26T23:22:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2016/03/26/computing-simplex-vertex-locations-from-pairwise-vertex-distances</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Suppose I have a collection of (N) objects, and distances d(j,k) between each pair of objects (j) and (k); that is, my objects are members of a <a href="https://en.wikipedia.org/wiki/Metric_space">metric space</a>.  I have no knowledge about my objects, beyond these pair-wise distances.  These objects could be construed as vertices in an (N-1) dimensional <a href="https://en.wikipedia.org/wiki/Simplex">simplex</a>.  However, since I have no spatial information about my objects, I first need a way to assign spatial locations to each object, in vector space R<sup>(N-1),</sup> with only my object distances to work with.</p>

<p>In this post I will derive an algorithm for assigning vertex locations in R<sup>(N-1)</sup> for each of N objects, using only pairwise object distances.</p>

<p>I will assume that N >= 2, since at least two object are required to define a pairwise distance.  The case N=2 is easy, as I can assign vertex 1 to the origin, and vertex 2 to the point d(1,2), to form a 1-simplex (i.e. a line segment) whose single edge is just the distance between the two objects.  I will also assume that my N objects are distinct; that is, each pair has a non-zero distance.</p>

<p>Next consider an arbitrary N, and suppose I have already added vertices 1 through k.  The next vertex (k+1) must obey the pairwise distance relations, as follows:</p>

<p><img src="http://mathurl.com/jm56vxq.png" alt="figure 1" /></p>

<p>Adding the new vertex (k+1) involves adding another dimension (k) to the simplex.  I define this new kth coordinate x(k) to be zero for the existing k vertices, as annotated above; only the new vertex (k+1) will have a non-zero kth coordinate.  Expanding the quadratic terms on the left yields the following form:</p>

<p><img src="http://mathurl.com/jtm7dpq.png" alt="figure 2" /></p>

<p>The squared terms for the coordinates of the new vertex (k+1) are inconvenient, however I can get rid of them by subtracting pairs of equations above.  For example, if I subtract equation 1 from the remaining k-1 equations (2 through k), these squared terms disappear, leaving me with the following system of k-1 equations, which we can see is linear in the 1st k-1 coordinates of the new vertex.  Therefore, I know I'll be able to solve for those coordinates.  I can solve for the remaining kth coordinate by plugging it into the first distance equation:</p>

<p><img src="http://mathurl.com/haovm32.png" alt="figure 3" /></p>

<p>To clarify matters, the equations above can be re-written as the following matrix equation, solveable by any linear systems library:</p>

<p><img src="http://mathurl.com/h6qdtms.png" alt="figure 4" /></p>

<p>This gives me a recusion relation for adding a new vertex (k+1), given that I have already added the first k vertices.  The basis case of adding the first two vertices was already described above.  And so I can iteratively add all my vertices one at a time by applying the recursion relation.</p>

<p>As a corollary, assume that I have constructed a simplex having k vertices, as shown above, and I would like to assign a spatial location to a new object, (y), given its k distances to each vertex.  The corresponding distance relations are given by:</p>

<p><img src="http://mathurl.com/zdw9uv8.png" alt="figure 5" /></p>

<p>I can apply a derivation very similar to the one above, to obtain the following linear equation for the (k-1) coordinates of (y):</p>

<p><img src="http://mathurl.com/zvr5jre.png" alt="figure 6" /></p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor was critical to the discovery of Einsteins's gravitational waves at LIGO ( March 24, 2016 )]]></title>
      <link href="http://newuniversedaily.com/2016/03/08/the-cyber-brain-behind-ligos-gravitational-waves-discovery/"/>
      <updated>2016-03-24T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[This  New Universe Daily news article
discusses the collaboration between the HTCondor team at UW-Madison
and the LIGO team at UW-Milwaukee, and how the HTCondor software was
critical to the discovery of gravitational waves and will continue
to be vital as LIGO moves forward.  "For 20 years, LIGO
was trying to find a needle in a haystack. Now weâre going to build a
needle detection factory,â said Peter Couvares, a Senior Scientist
with the LIGO project.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.5.3 released! ( March 24, 2016 )]]></title>
      <link href="manual/v8.5.3/10_2Development_Release.html"/>
      <updated>2016-03-24T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.5.3.
This development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.4.5
stable release.

Enhancements in the release include:
Use IPv6 (and IPv4) interfaces if they are detected;
Prefer IPv4 addresses when both are available;
Count Idle and Running jobs in Submitter Ads for Local and Scheduler universes;
Can submit jobs to SLURM with the new "slurm" type in the Grid universe;
HTCondor is built and linked with Globus 6.0.

Further details can be found in the
Version History.
HTCondor 8.5.3 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.4.5 released! ( March 22, 2016 )]]></title>
      <link href="manual/v8.4.5/10_3Stable_Release.html"/>
      <updated>2016-03-22T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.4.5.
A stable series release contains significant bug fixes.

Highlights of this release are:
fixed a bug that would cause the condor_schedd to send no flocked jobs;
fixed a bug that caused a 60 second delay using tools when DNS lookup failed;
prevent using accounting groups with embedded spaces that crash the negotiator;
fixed a bug that could cause use of ports outside the port range on Windows;
fixed a bug that could prevent dynamic slot reuse when using many slots;
fixed a bug that prevented correct utilization reports from the job router;
tune kernel when using cgroups to avoid OOM killing of jobs doing heavy I/O;
a few other bug fixes, consult the version history.

Further details can be found in the
Version History.
HTCondor 8.4.5 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor helps LIGO confirm last unproven Albert Einstein theory ( March 8, 2016 )]]></title>
      <link href="https://morgridge.org/newsarticle/high-throughput-computing-helps-ligo-confirm-einsteins-last-unproven-theory/"/>
      <updated>2016-03-08T06:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[This  Morgridge Institute news article
explains the rich back-story of HTCondor's role behind the recent announcement that
scientists from the Laser Interferometer Gravitational-Wave Observatory (LIGO) unlocked the final
door to Einstein's Theory of Relativity. More than 700 LIGO scientists have used HTCondor
to run complex data analysis workflows, accumulating 50 million core-hours 
in the past six months alone.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Dimensionality reduction in Spark]]></title>
      <link href="https://chapeau.freevariable.com/2016/02/dimensionality-reduction-in-spark.html"/>
      <updated>2016-02-17T01:23:17Z</updated>
      <id>https://chapeau.freevariable.com/2016/02/dimensionality-reduction-in-spark</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>https://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Here&rsquo;s a quick video I put together introducing infrastructure log processing in Spark.  At the end, there are a couple of nice graphs contrasting PCA and t-SNE for embedding high-dimensional log metadata into two dimensions. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Efficient Multiplexing for Spark RDDs]]></title>
      <link href="http://erikerlandson.github.com/blog/2016/02/08/efficient-multiplexing-for-spark-rdds/"/>
      <updated>2016-02-08T17:09:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2016/02/08/efficient-multiplexing-for-spark-rdds</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I'm going to propose a new abstract operation on <a href="http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds">Spark RDDs</a> -- <strong>multiplexing</strong> -- that makes some categories of operations on RDDs both easier to program and in many cases much faster. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using word2vec on logs]]></title>
      <link href="https://chapeau.freevariable.com/2015/12/using-word2vec-on-log-messages.html"/>
      <updated>2015-12-11T17:51:36Z</updated>
      <id>https://chapeau.freevariable.com/2015/12/using-word2vec-on-log-messages</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>https://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Lately, I&rsquo;ve been experimenting with <a href="http://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec">Spark&rsquo;s implementation</a> of word2vec.  Since most of the natural-language data I have sitting around these days are service and system logs from machines at work, I thought it would be fun to see how well word2vec worked if we trained it on the text of log messages.  This is obviously pretty far from an ideal training corpus, but these brief, rich messages seem like they should have some minable content.  In the rest of this post, I&rsquo;ll show some interesting results from the model and also describe some concrete preprocessing steps to get more useful results for extracting words from the odd dialect of natural language that appears in log messages. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The 'prepare' operation considered harmful in Algebird aggregation]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/11/24/the-prepare-operation-considered-harmful-in-algebird/"/>
      <updated>2015-11-24T23:32:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/11/24/the-prepare-operation-considered-harmful-in-algebird</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I want to make an argument that the Algebird <a href="http://twitter.github.io/algebird/#com.twitter.algebird.Aggregator">Aggregator</a> design, in particular its use of the <code>prepare</code> operation in a map-reduce context, has substantial inefficiencies, compared to an equivalent formulation that is more directly suited to taking advantage of Scala's <a href="http://www.scala-lang.org/api/current/index.html#scala.collection.Seq">aggregate method on collections</a> method. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Very Fast Reservoir Sampling]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/11/20/very-fast-reservoir-sampling/"/>
      <updated>2015-11-20T18:27:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/11/20/very-fast-reservoir-sampling</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I will demonstrate how to do reservoir sampling orders of magnitude faster than the traditional "naive" reservoir sampling algorithm, using a fast high-fidelity approximation to the reservoir sampling-gap distribution. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Concrete advice about abstracts]]></title>
      <link href="https://chapeau.freevariable.com/2015/11/concrete-advice-about-abstracts.html"/>
      <updated>2015-11-16T15:43:49Z</updated>
      <id>https://chapeau.freevariable.com/2015/11/concrete-advice-about-abstracts</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>https://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Consider the following hypothetical conference session abstract: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Pacing technical talks]]></title>
      <link href="https://chapeau.freevariable.com/2015/10/pacing-technical-talks.html"/>
      <updated>2015-10-21T16:17:01Z</updated>
      <id>https://chapeau.freevariable.com/2015/10/pacing-technical-talks</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>https://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Delivering a technical talk has a lot in common with running a half-marathon or biking a 40k time trial.  You&rsquo;re excited and maybe a little nervous, you&rsquo;re prepared to go relatively hard for a relatively long time, and you&rsquo;re acutely aware of the clock.  In both situations, you might be tempted to take off right from the gun, diving into your hardest effort (or most technical material), but this is a bad strategy. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Notes from Flink Forward]]></title>
      <link href="https://chapeau.freevariable.com/2015/10/notes-from-flink-forward.html"/>
      <updated>2015-10-20T15:48:44Z</updated>
      <id>https://chapeau.freevariable.com/2015/10/notes-from-flink-forward</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>https://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/willb/22238437291/in/dateposted-public/" title="Brandenburger Tor lightshow"><img src="https://farm1.staticflickr.com/739/22238437291_22636e4a72_b.jpg" width="1024" height="819" alt="Brandenburger Tor lightshow"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script> [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Library of Binary Tree Algorithms as Mixable Scala Traits]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/"/>
      <updated>2015-09-26T19:43:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I am going to describe some work I've done recently on a system of Scala traits that support tree-based collection algorithms prefix-sum, nearest key query and value increment in a mixable format, all backed by Red-Black balanced tree logic, which is also a fully inheritable trait. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[GPUs and adding new resources types to the HTCondor-CE]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/08/gpus-and-adding-new-resources-types-to.html"/>
      <updated>2015-08-07T21:45:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-6301136022425730449</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The more things change, the more they stay the same]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/07/the-more-things-change-more-they-stay.html"/>
      <updated>2015-07-28T15:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-8394942129716842708</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
</feed>
