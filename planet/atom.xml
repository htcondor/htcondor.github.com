<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2015-06-28T16:09:33-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.6 released! ( June 23, 2015 )]]></title>
      <link href="manual/v8.3.6/10_3Development_Release.html"/>
      <updated>2015-06-23T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.6.
This development series release contains new features that are under
development.

Enhancements in the release include:
initial Docker universe support;
IPv4/IPv6 mixed mode support.

Further details can be found in the
Version History.
HTCondor 8.3.6 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[fedmsg talk at Spark Summit]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/summit-fedmsg.html"/>
      <updated>2015-06-15T15:05:27Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/summit-fedmsg</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I&rsquo;m speaking at Spark Summit today about using Spark to analyze operational data from the Fedora project.  Here are some links to further resources related to my talk:</p>

<ul>
<li><a href="http://chapeau.freevariable.com/static/201506/fedmsg-spark.pdf">My talk slides are online</a>; the online deck includes some extra slides that I skipped in the talk as delivered</li>
<li>An earlier post provides <a href="http://chapeau.freevariable.com/2014/10/fedmsg-and-spark.html">some background on fedmsg and Spark</a></li>
<li>You may also be interested in <a href="http://chapeau.freevariable.com/2014/11/algebraic-types.html">a higher-level discussion of issues with schema inference</a> from the perspective of type theory</li>
<li>Here&rsquo;s the annotated <a href="http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers.html">source code for the ML pipeline transformer</a> I discussed in my talk</li>
</ul>


<p>You should also check out my team&rsquo;s <a href="http://silex.freevariable.com">Silex library</a>, which contains useful code factored out of real Spark applications we&rsquo;ve built in Red Hat&rsquo;s Emerging Technology group.  It includes a lot of cool functionality, but the part I mentioned in the talk is <a href="http://silex.freevariable.com/latest/api/#com.redhat.et.silex.rdd.json.JSONTransform$">this handy interface</a> for preprocessing JSON data before inferring a schema.</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Spark ML Pipeline transformers]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers.html"/>
      <updated>2015-06-14T00:07:58Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post, we&rsquo;ll see how to make a simple transformer for <a href="https://spark.apache.org/docs/latest/ml-guide.html">Spark ML Pipelines</a>.  The transformer we&rsquo;ll design will generate a sparse binary feature vector from an array-valued field representing a set.</p>

<h3>Preliminaries</h3>

<p>The first thing we&rsquo;ll need to do is expose Spark&rsquo;s user-defined type for vectors.  This will enable us to write a user-defined data frame function that returns a Spark vector.  (We could also implement our own user-defined type, but reusing Spark&rsquo;s, which is currently private to Spark, will save us some time.  By the time you read this, the type may be part of Spark&rsquo;s public API &mdash; be sure to double-check!)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">package</span> <span class="nn">org.apache.spark.hacks</span> <span class="o">{</span>
</span><span class='line'>  <span class="c1">// make VectorUDT available outside of Spark code</span>
</span><span class='line'>  <span class="k">type</span> <span class="kt">VectorType</span> <span class="o">=</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">mllib</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="nc">VectorUDT</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Imports</h3>

<p>Here are the imports we&rsquo;ll need for the transformer and support code.  I&rsquo;ll use <code>VEC</code> for Spark vectors to avoid confusion with Scala&rsquo;s <code>Vector</code> type.  We&rsquo;ll assume that the <code>VectorType</code> code from above is available on your project&rsquo;s classpath.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.sql._</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.sql.types._</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.sql.functions._</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.ml.param._</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.ml.Transformer</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.</span><span class="o">{</span><span class="nc">Vector</span> <span class="k">=&gt;</span> <span class="nc">VEC</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">}</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.sql.types._</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.hacks.VectorType</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Transformer and support code</h3>

<p>Most of the ML pipeline classes distributed with Spark follow the convention of putting groups of related pipeline stage parameters in a trait.  We&rsquo;ll do this as well, declaring a trait for the three parameters that our transformer will use:  the name of the input column, the name of the output column, and the maximum number of elements our sparse vector can hold.  We&rsquo;ll also define a convenience method to return a triple of the parameter values we care about.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">trait</span> <span class="nc">SVParams</span> <span class="k">extends</span> <span class="nc">Params</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">inputCol</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Param</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="k">this</span><span class="o">,</span> <span class="s">&quot;inputCol&quot;</span><span class="o">,</span> <span class="s">&quot;input column&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">outputCol</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Param</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="k">this</span><span class="o">,</span> <span class="s">&quot;outputCol&quot;</span><span class="o">,</span> <span class="s">&quot;output column&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">vecSize</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IntParam</span><span class="o">(</span><span class="k">this</span><span class="o">,</span> <span class="s">&quot;vecSize&quot;</span><span class="o">,</span> <span class="s">&quot;maximum sparse vector size&quot;</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">pvals</span><span class="o">(</span><span class="n">pm</span><span class="k">:</span> <span class="kt">ParamMap</span><span class="o">)</span> <span class="k">=</span> <span class="o">(</span>
</span><span class='line'>    <span class="c1">// this code can be cleaner in versions of Spark after 1.3</span>
</span><span class='line'>    <span class="n">paramMap</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="n">inputCol</span><span class="o">).</span><span class="n">getOrElse</span><span class="o">(</span><span class="s">&quot;topicSet&quot;</span><span class="o">),</span>
</span><span class='line'>    <span class="n">paramMap</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="n">outputCol</span><span class="o">).</span><span class="n">getOrElse</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">),</span>
</span><span class='line'>    <span class="n">paramMap</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="n">vecSize</span><span class="o">).</span><span class="n">getOrElse</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
</span><span class='line'>  <span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that Spark 1.4 supports calling <code>getOrElse</code> directly on a <code>ParamMap</code> instance, so you can slightly simplify the code in <code>pvals</code> if you don&rsquo;t care about source compatibility with Spark 1.3.</p>

<p>Here&rsquo;s what the actual transformer implementation looks like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">SetVectorizer</span><span class="o">(</span><span class="k">override</span> <span class="k">val</span> <span class="n">uid</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>
</span><span class='line'>    <span class="k">extends</span> <span class="nc">Transformer</span> <span class="k">with</span> <span class="nc">SVParams</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">val</span> <span class="nc">VT</span> <span class="k">=</span> <span class="k">new</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">hacks</span><span class="o">.</span><span class="nc">VectorType</span><span class="o">()</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">transformSchema</span><span class="o">(</span><span class="n">schema</span><span class="k">:</span> <span class="kt">StructType</span><span class="o">,</span> <span class="n">params</span><span class="k">:</span> <span class="kt">ParamMap</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">outc</span> <span class="k">=</span> <span class="n">paramMap</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="n">outputCol</span><span class="o">).</span><span class="n">getOrElse</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
</span><span class='line'>    <span class="nc">StructType</span><span class="o">(</span><span class="n">schema</span><span class="o">.</span><span class="n">fields</span> <span class="o">++</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">StructField</span><span class="o">(</span><span class="n">outc</span><span class="o">,</span> <span class="nc">VT</span><span class="o">,</span> <span class="kc">true</span><span class="o">)))</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="k">:</span> <span class="kt">DataFrame</span><span class="o">,</span> <span class="n">params</span><span class="k">:</span> <span class="kt">ParamMap</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="o">(</span><span class="n">inCol</span><span class="o">,</span> <span class="n">outCol</span><span class="o">,</span> <span class="n">maxSize</span><span class="o">)</span> <span class="k">=</span> <span class="n">pvals</span><span class="o">(</span><span class="n">paramMap</span><span class="o">)</span>
</span><span class='line'>    <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="n">outCol</span><span class="o">,</span> <span class="n">callUDF</span><span class="o">({</span> <span class="n">a</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=&gt;</span>
</span><span class='line'>      <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="n">maxSize</span><span class="o">,</span> <span class="n">a</span><span class="o">.</span><span class="n">toArray</span><span class="o">,</span> <span class="nc">Array</span><span class="o">.</span><span class="n">fill</span><span class="o">(</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="o">)(</span><span class="mf">1.0</span><span class="o">))</span>
</span><span class='line'>    <span class="o">},</span> <span class="nc">VT</span><span class="o">,</span> <span class="n">df</span><span class="o">(</span><span class="n">inCol</span><span class="o">)))</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The first thing we do in the transformer class is declare an instance of <code>VectorType</code> to use in other data frame type declarations later in the class.  The <code>transformSchema</code> method returns the schema after applying this transformer to a given data frame; it creates a new data frame schema that includes all of the fields from the original frame as well as a <code>Vector</code>-valued field whose name is the parameter specified in the <code>outputCol</code> parameter.  Finally, the <code>transform</code> method creates a new data frame with an additional column (again, named with the value of the <code>outputCol</code> parameter); its values result of applying a user-defined function to each row in the data frame, taking arguments from the input column.  The function itself simply creates a sparse binary vector from an array-backed set, so that the array-backed set <code>Array(1,2,4,8)</code> would become a sparse vector with the first, second, fourth, and eighth elements set to 1 and everything else set to 0.</p>

<p>The code above is a reasonable starting point for your own transformers, but you&rsquo;ll want to add error checking to code you use in production:  at a minimum, you&rsquo;d need to validate the schema of the input data frame (to ensure that expected columns exist and are of the correct type), verify that the output column name doesn&rsquo;t already exist in the data frame, and make sure no input array has more than <code>vecSize</code> elements.  I hope this code is helpful as you develop your own pipeline stages!</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bokeh plots from Spark]]></title>
      <link href="http://chapeau.freevariable.com/2015/05/bokeh-plots-from-spark.html"/>
      <updated>2015-05-21T16:05:10Z</updated>
      <id>http://chapeau.freevariable.com/2015/05/bokeh-plots-from-spark</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>This post will show you an extremely simple way to make quick-and-dirty <a href="http://bokeh.pydata.org/en/latest/">Bokeh</a> plots from data you&rsquo;ve generated in Spark, but the basic technique is generally applicable to any data that you&rsquo;re generating in some application that doesn&rsquo;t necessarily link in the Bokeh libraries. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Planning your career like a racing season]]></title>
      <link href="http://chapeau.freevariable.com/2015/05/process-goals.html"/>
      <updated>2015-05-14T21:04:20Z</updated>
      <id>http://chapeau.freevariable.com/2015/05/process-goals</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Most people set personal and professional goals.  If you work in software, your near-term professional goals might sound like this: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Parallel K-Medoids Using Scala ParSeq]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/"/>
      <updated>2015-05-06T23:33:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Scala supplies a <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections library</a> that was designed to make it easy for a programmer to add parallel computing over the elements in a collection.  In this post, I will describe a case study of applying Scala's parallel collections to cleanly implement multithreading support for training a K-Medoids clustering model. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Elasticsearch and Spark 1.3]]></title>
      <link href="http://chapeau.freevariable.com/2015/04/elasticsearch-and-spark-1-dot-3.html"/>
      <updated>2015-04-30T20:34:37Z</updated>
      <id>http://chapeau.freevariable.com/2015/04/elasticsearch-and-spark-1-dot-3</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a> has offered Hadoop <code>InputFormat</code> and <code>OutputFormat</code> implementations for quite some time.  These made it possible to process Elasticsearch indices with Spark just as you would any other Hadoop data source.  Here&rsquo;s an example of this in action, taken from <a href="http://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html">Elastic&rsquo;s documentation</a>: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.5 released! ( April 20, 2015 )]]></title>
      <link href="manual/v8.3.5/10_3Development_Release.html"/>
      <updated>2015-04-20T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.5.
A development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.2.8
stable release.
A few of the enhancements in this release include:
new features that increase the power of job specification in the
submit description file;
RPMs for Red Hat Enterprise Linux 6 and 7 are modularized and only
distributed via our YUM repository;
The new condor-all RPM requires
the other HTCondor RPMs of a typical HTCondor installation.
Further details can be found in the
Version History.
HTCondor 8.3.5 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.2.8 released! ( April 7, 2015 )]]></title>
      <link href="manual/v8.2.8/10_3Stable_Release.html"/>
      <updated>2015-04-07T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor version 8.2.8.
A stable series release contains significant bug and security fixes.
This version contains:
a bug fix to reconnect a TCP session when an HTCondorView collector restarts;
a bug fix to avoid starting too many jobs, only to kill some chosen at random.
A complete list of fixed bugs can be found in the
Version History.
HTCondor 8.2.8 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Hygienic Closures for Scala Function Serialization]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization/"/>
      <updated>2015-03-31T13:06:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In most use cases of Scala closures, what you see is what you get, but there are exceptions where looks can be deceiving and this can have a big impact on closure serialization.  Closure serialization is of more than academic interest.  Tools like Apache Spark cannot operate without serializing functions over the network.  In this post I'll describe some scenarios where closures include more than what is evident in the code, and then a technique for preventing unwanted inclusions. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor helps astronomers with the hydrogen location problem ( March 26, 2015 )]]></title>
      <link href="http://www.news.wisc.edu/23594"/>
      <updated>2015-03-26T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[This  UW Madison news article discusses how a new computational approach permits evaluation of hydrogen data using software, which may replace the time consuming manual approach. Putting HTCondor into the mix scales well given the vast quantities of data expected as Square Kilometer Array radio telescope is realized.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor Week 2015 Registration Open (March 25, 2015 )]]></title>
      <link href="http://research.cs.wisc.edu/htcondor/HTCondorWeek2015/"/>
      <updated>2015-03-25T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[We invite HTCondor users, administrators, and developers to HTCondor Week 2015, our annual HTCondor user conference, in beautiful Madison, Wisconsin, May 19-22, 2015. HTCondor Week features tutorials and talks from HTCondor developers, administrators, and users.  It also provides an opportunity for one-on-one or small group collaborations throughout the week.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[HTCondor CacheD: Caching for HTC - Part 2]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/htcondor-cached-caching-for-htc-part-2.html"/>
      <updated>2015-01-25T15:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-5260378956420164105</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Monadic 'break' and 'continue' for Scala Sequence Comprehensions]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions/"/>
      <updated>2015-01-24T18:54:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Author's note: I've since received some excellent feedback from the Scala community, which I included in some <a href="#notes">end notes</a>. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Condor CacheD: Caching for HTC - Part 1]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/condor-cached-caching-for-htc-part-1.html"/>
      <updated>2015-01-22T16:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1889975382858537261</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Faster Random Samples With Gap Sampling]]></title>
      <link href="http://erikerlandson.github.com/blog/2014/09/11/faster-random-samples-with-gap-sampling/"/>
      <updated>2014-09-11T14:57:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2014/09/11/faster-random-samples-with-gap-sampling</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Generating a random sample of a collection is, logically, a O(np) operation, where (n) is the sample size and (p) is the sampling probability.  For example, extracting a random sample, without replacement, from an array might look like this in pseudocode: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Getting Started with Mesos on Fedora 21 and CentOS 7]]></title>
      <link href="http://timothysc.github.com/blog/2014/09/08/mesos-breeze/"/>
      <updated>2014-09-08T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2014/09/08/mesos-breeze</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><img class="left" src="http://timothysc.github.com/images/mesos_logo.png"> [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Scala Iterator 'drop' Method Generates a Matryoshka Class Nesting]]></title>
      <link href="http://erikerlandson.github.com/blog/2014/09/03/matryoshka-class-construction-from-the-scala-iterator-drop-method/"/>
      <updated>2014-09-04T00:23:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2014/09/03/matryoshka-class-construction-from-the-scala-iterator-drop-method</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The Scala Iterator <code>drop</code> method has a complexity bug that shows up when one calls <code>drop</code> repeatedly, for example when traversing over an iterator in a loop. [...]</p>
]]></content>
    </entry>
  
</feed>
