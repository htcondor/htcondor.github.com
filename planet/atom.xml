<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2015-10-11T08:15:43-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[A Library of Binary Tree Algorithms as Mixable Scala Traits]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/"/>
      <updated>2015-09-26T19:43:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I am going to describe some work I've done recently on a system of Scala traits that support tree-based collection algorithms prefix-sum, nearest key query and value increment in a mixable format, all backed by Red-Black balanced tree logic, which is also a fully inheritable trait.</p>

<p>This post eventually became a bit more sprawling and "tl/dr" than I was expecting, so by way of apology, here is a table of contents with links:</p>

<ol>
<li><a href="#motivation">Motivating Use Case</a></li>
<li><a href="#overview">Library Overview</a></li>
<li><a href="#redblack">A Red-Black Tree Base Class</a></li>
<li><a href="#nodemap">Node Inheritance Example: NodeMap[K,V]</a></li>
<li><a href="#orderedmaplike">Collection Trait Example: OrderedMapLike[K,V,IN,M]</a></li>
<li><a href="#orderedmap">Collection Example: OrderedMap[K,V]</a></li>
<li><a href="#mixing">Finale: Trait Mixing</a></li>
</ol>


<p><a name="motivation"></a></p>

<h5>A Motivating Use Case</h5>

<p>The skeptical programmer may be wondering what the point of Yet Another Map Collection really is, much less an entire class hierarchy.  The use case that inspired this work was my project of implementing the <a href="https://github.com/tdunning/t-digest/blob/master/docs/t-digest-paper/histo.pdf">t-digest algorithm</a>.  Discussion of t-digest is beyond the scope of this post, but suffice it to say that constructing a t-digest requires the maintenance of a collection of "cluster" objects, that needs to satisfy the following several properties:</p>

<ol>
<li>an entry contains one <strong>or more</strong> cluster objects at a given numeric location</li>
<li>entries are maintained in a numeric key order</li>
<li>entries will be frequently inserted and deleted, in arbitrary order</li>
<li>given a numeric key value, be able to find the entry nearest to that value</li>
<li>given a key, compute a <a href="https://en.wikipedia.org/wiki/Prefix_sum">prefix-sum</a> for that value</li>
<li>all of the above should be bounded by logarithmic time complexity</li>
</ol>


<p>Propreties 2,3 and 6 are commonly satisfied by a map structure backed by some variety of balanced tree representation, of which the best-known is the <a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree">Red-Black tree</a>.</p>

<p>Properties 1, 4 and 5 are more interesting.  Property 1 -- representing a collection of multiple objects at each entry -- can be accomplished in a generalizable way by noting that a collection is representable as a monoid, and so supporting values that can be incremented with respect to a <a href="http://twitter.github.io/algebird/index.html#com.twitter.algebird.Monoid">user-supplied monoid relation</a> can satisfy property-1, but also can support many other kinds of update, including but not limited to classical numeric incrementing operations.</p>

<p>Properties 4 and 5 -- nearest-entry queries and prefix-sum queries -- are also both supportable in logarithmic time using a tree data structure, provided that tree is balanced.  Again, the details of the algorithms are out of the current scope, however they are not extremely complex, and their implementations are available in the code.</p>

<p>A reader with their software engineering hat on will notice that these properties are <em>orthogonal</em>.  A programmer might be interested in a data structure supporting any one of them, or in some mixed combination.   This kind of situation fairly shouts "Scala traits" (or, alternatively, interfaces in Java, etc).  With that idea in mind, I designed a system of Scala collection traits that support all of the above properties, in a pure trait form that is fully "mixable" by the programmer, so that one can use exactly the properties needed, but not pay for anything else.</p>

<p><a name="overview"></a></p>

<h5>Library Overview</h5>

<p>The source files containing the code discussed in the remainder of this post are available <a href="https://github.com/erikerlandson/silex/tree/blog/rbtraits/src/main/scala/com/redhat/et/silex/maps">here</a>, and the unit testing files are <a href="https://github.com/erikerlandson/silex/tree/blog/rbtraits/src/test/scala/com/redhat/et/silex/maps">here</a>.  At the time of this post the tree algorithm trait system is a <a href="https://github.com/willb/silex/pull/35">PR against the silex project</a>.</p>

<p>The library consists broadly of 3 kinds of traits:</p>

<ul>
<li>tree node traits -- implement core tree support for some functionality</li>
<li>collection traits -- provide additional collection API methods the user</li>
<li>collections -- instantiate a usable incarnation of a collection</li>
</ul>


<p>For the programmer who wishes to either create a trait mixture, or add new mixable traits, the collections also function as reference implementations.</p>

<p>The three tables that follow summarize the currently available traits of each kind listed above.  They are (at the time of this posting) all under the package namespace <code>com.redhat.et.silex.maps</code>:</p>

<p><head><style>
table, th, td {
border: 1px solid black;
border-collapse: collapse;
}
th, td {
padding: 10px;
}
th {
text-align: center;
}
</style></head></p>

<table>
<caption>Tree Node Traits</caption>
<tr><td>trait</td><td>sub-package</td><td>description</td></tr>
<tr><td>Node[K]</td> <td>redblack.tree</td><td>Fundamental Red-Black tree functionality</td></tr>
<tr><td>NodeMap[K,V]</td><td>ordered.tree</td><td>Support a mapping from keys to values</td></tr>
<tr><td>NodeNear[K]</td><td>nearest.tree</td><td>Nearest-entry query (key-only)</td></tr>
<tr><td>NodeNearMap[K,V]</td><td>nearest.tree</td><td>Nearest-entry query for key/value maps</td></tr>
<tr><td>NodeInc[K,V]</td><td>increment.tree</td><td>Increment values w.r.t. a monoid</td></tr>
<tr><td>NodePS[K,V,P]</td><td>prefixsum.tree</td><td>Prefix sum queries by key (w.r.t. a monoid)</td></tr>
</table>




<br>


<table>
<caption>Collection Traits</caption>
<tr><td>trait</td><td>sub-package</td><td>description</td></tr>
<tr><td>OrderedSetLike[K,IN,M]</td><td>ordered</td><td>ordered set of keys</td></tr>
<tr><td>OrderedMapLike[K,V,IN,M]</td><td>ordered</td><td>ordered key/value map</td></tr>
<tr><td>NearestSetLike[K,IN,M]</td><td>nearest</td><td>nearest entry query on keys</td></tr>
<tr><td>NearestMapLike[K,V,IN,M]</td><td>nearest</td><td>nearest entry query on key/value map</td></tr>
<tr><td>IncrementMapLike[K,V,IN,M]</td><td>increment</td><td>increment values w.r.t a monoid</td></tr>
<tr><td>PrefixSumMapLike[K,V,P,IN,M]</td><td>prefixsum</td><td>prefix sum queries w.r.t. a monoid</td></tr>
</table>




<br>


<table>
<caption>Concrete Collections</caption>
<tr><td>trait</td><td>sub-package</td><td>description</td></tr>
<tr><td>OrderedSet[K]</td><td>ordered</td><td>ordered set</td></tr>
<tr><td>OrderedMap[K,V]</td><td>ordered</td><td>ordered key/value map</td></tr>
<tr><td>NearestSet[K]</td><td>nearest</td><td>ordered set with nearest-entry query</td></tr>
<tr><td>NearestMap[K,V]</td><td>nearest</td><td>ordred map with nearest-entry query</td></tr>
<tr><td>IncrementMap[K,V]</td><td>increment</td><td>ordered map with value increment w.r.t. a monoid</td></tr>
<tr><td>PrefixSumMap[K,V,P]</td><td>prefixsum</td><td>ordered map with prefix sum query w.r.t. a monoid</td></tr>
</table>




<br>


<p>The following diagram summarizes the organization and inheritance relationships of the classes.</p>

<p><img src="/assets/images/rbtraits/rbtraits.png" alt="diagram" /></p>

<p><a name="redblack"></a></p>

<h5>A Red/Black Tree Base Class</h5>

<p>The most fundamental trait in this hierarchy is the trait that embodies Red-Black balancing; a "red-black-ness" trait, as it were.  This trait supplies the axiomatic tree operations of insertion, deletion and key lookup, where the Red-Black balancing operations are encapsulated for insertion (due to <a href="http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=44273">Chris Okasaki</a>) and deletion (due to <a href="http://www.cs.kent.ac.uk/people/staff/smk/redblack/rb.html">Stefan Kahrs</a>)  Note that Red-Black trees do not assume a separate value, as in a map, but require only keys (thus implementing an ordered set over the key type):</p>

<p>``` scala
object tree {
  /<em>* The color (red or black) of a node in a Red/Black tree </em>/
  sealed trait Color
  case object R extends Color
  case object B extends Color</p>

<p>  /<em>* Defines the data payload of a tree node </em>/
  trait Data[K] {</p>

<pre><code>/** The axiomatic unit of data for R/B trees is a key */
val key: K
</code></pre>

<p>  }</p>

<p>  /** Base class of a Red/Black tree node</p>

<pre><code>* @tparam K The key type
*/
</code></pre>

<p>  trait Node[K] {</p>

<pre><code>/** The ordering that is applied to key values */
val keyOrdering: Ordering[K]

/** Instantiate an internal node. */
protected def iNode(color: Color, d: Data[K], lsub: Node[K], rsub: Node[K]): INode[K]

// ... declarations for insertion, deletion and key lookup ...

// ... red-black balancing rules ...
</code></pre>

<p>  }</p>

<p>   /<em>* Represents a leaf node in the Red Black tree system </em>/
  trait LNode[K] extends Node[K] {</p>

<pre><code>// ... basis case insertion, deletion, lookup ...
</code></pre>

<p>  }</p>

<p>  /<em>* Represents an internal node (Red or Black) in the Red Black tree system </em>/
  trait INode[K] extends Node[K] {</p>

<pre><code>/** The Red/Black color of this node */
val color: Color
/** Including, but not limited to, the key */
val data: Data[K]
/** The left sub-tree */
val lsub: Node[K]
/** The right sub-tree */
val rsub: Node[K]

// ... implementations for insertion, deletion, lookup ...
</code></pre>

<p>  }
}
<code>``
I will assume most readers are familiar with basic binary tree operations, and the Red-Black rules are described elsewhere (I adapted them from the Scala red-black implementation).  For the purposes of this discussion, the most interesting feature is that this is a _pure Scala trait_.  All</code>val` declarations are abstract.  This trait, by itself, cannot function without a subclass to eventually perform dependency injection.   However, this abstraction allows the trait to be inherited freely -- any programmer can inherit from this trait and get a basic Red-Black balanced tree for (nearly) free, as long as a few basic principles are adhered to for proper dependency injection.</p>

<p>Another detail to call out is the abstraction of the usual <code>key</code> with a <code>Data</code> element.  This element represents any node payload that is moved around as a unit during tree structure manipulations, such as balancing pivots.  In the case of a map-like subclass, <code>Data</code> is extended to include a <code>value</code> field as well as a <code>key</code> field.</p>

<p>The other noteworthy detail is the abstract definition <code>def iNode(color: Color, d: Data[K], lsub: Node[K], rsub: Node[K]): INode[K]</code> - this is the function called to create any new tree node.  In fact, this function, when eventually instantiated, is what performs dependency injection of other tree node fields.</p>

<p><a name="nodemap"></a></p>

<h5>Node Inheritance Example: NodeMap[K,V]</h5>

<p>A relatively simple example of node inheritance is hopefully instructive.  Here is the definition for tree nodes supporting a key/value map:</p>

<p>``` scala
object tree {
  /<em>* Trees that back a map-like object have a value as well as a key </em>/
  trait DataMap[K, V] extends Data[K] {</p>

<pre><code>val value: V
</code></pre>

<p>  }</p>

<p>  /** Base class of ordered K/V tree node</p>

<pre><code>* @tparam K The key type
* @tparam V The value type
*/
</code></pre>

<p>  trait NodeMap[K, V] extends Node[K]</p>

<p>  trait LNodeMap[K, V] extends NodeMap[K, V] with LNode[K]</p>

<p>  trait INodeMap[K, V] extends NodeMap[K, V] with INode[K] {</p>

<pre><code>val data: DataMap[K, V]
</code></pre>

<p>  }
}
```</p>

<p>Note that in this case very little is added to the red/black functionality already provided by <code>Node[K]</code>.  A <code>DataMap[K,V]</code> trait is defined to add a <code>value</code> field in addition to the <code>key</code>, and the internal node <code>INodeMap[K,V]</code> refines the type of its <code>data</code> field to be <code>DataMap[K,V]</code>.  The semantics is little more than "tree nodes now carry a value in addition to a key."</p>

<p>A tree node trait inherits from its own parent class <em>and</em> the corresponding traits for any mixed-in functionality.  So for example <code>INodeMap[K,V]</code> inherits from <code>NodeMap[K,V]</code> but also <code>INode[K]</code>.</p>

<p><a name="orderedmaplike"></a></p>

<h5>Collection Trait Example: OrderedMapLike[K,V,IN,M]</h5>

<p>Continuing with the ordered map example, here is the definition of the collection trait for an ordered map:</p>

<p>``` scala
trait OrderedMapLike[K, V, IN &lt;: INodeMap[K, V], M &lt;: OrderedMapLike[K, V, IN, M]]</p>

<pre><code>extends NodeMap[K, V] with OrderedLike[K, IN, M] {
</code></pre>

<p>  /<em>* Obtain a new map with a (key, val) pair inserted </em>/
  def +(kv: (K, V)) = this.insert(</p>

<pre><code>new DataMap[K, V] {
  val key = kv._1
  val value = kv._2
}).asInstanceOf[M]
</code></pre>

<p>  /<em>* Get the value stored at a key, or None if key is not present </em>/
  def get(k: K) = this.getNode(k).map(_.data.value)</p>

<p>  /<em>* Iterator over (key,val) pairs, in key order </em>/
  def iterator = nodesIterator.map(n => ((n.data.key, n.data.value)))</p>

<p>  /<em>* Container of values, in key order </em>/
  def values = valuesIterator.toIterable</p>

<p>  /<em>* Iterator over values, in key order </em>/
  def valuesIterator = nodesIterator.map(_.data.value)
}
<code>``
You can see that this trait supplies collection API methods that a Scala programmer will recognize as being standard for any map-like collection.  Note that this trait also inherits other standard methods from</code>OrderedLike[K,IN,M]<code>(common to both sets and maps) and _also_ inherits from</code>NodeMap[K,V]<code>: In other words, a collection is effectively yet another kind of tree node, with additional collection API methods mixed in.   Note also the use of "self types" (the type parameter</code>M`), which allows the collection to return objects of its own kind.  This is crucial for allowing operations like data insertion to return an object that also supports node insertion, and to maintain consistency of type across operations.  The collection type is properly "closed" with respect to its own operations.</p>

<p><a name="orderedmap"></a></p>

<h5>Collection Example: OrderedMap[K,V]</h5>

<p>To conclude the ordered map example, consider the task of defining a concrete instantiation of an ordered map:
``` scala
sealed trait OrderedMap[K, V] extends OrderedMapLike[K, V, INodeMap[K, V], OrderedMap[K, V]] {
  override def toString =</p>

<pre><code>"OrderedMap(" +
  nodesIterator.map(n =&gt; s"${n.data.key} -&gt; ${n.data.value}").mkString(", ") +
")"
</code></pre>

<p>}
<code>``
You can see that (aside from a convenience override of</code>toString<code>) the trait</code>OrderedMap[K,V]<code>is nothing more than a vehicle for instantiating a particular concrete</code>OrderedMapLike[K,V,IN,M]<code>subtype, with particular concrete types for internal node (</code>INodeMap[K,V]`) and its own self-type.</p>

<p>Things become a little more interesting inside the companion object <code>OrderedMap</code>:
``` scala
object OrderedMap {
  def key<a href="implicit%20ord:%20Ordering[K]">K</a> = new AnyRef {</p>

<pre><code>def value[V]: OrderedMap[K, V] =
  new InjectMap[K, V](ord) with LNodeMap[K, V] with OrderedMap[K, V]
</code></pre>

<p>  }
}
<code>``
Note that the object returned by the factory method is upcast to</code>OrderedMap[K,V]<code>, but in fact has the more complicated type:</code>InjectMap[K,V] with LNodeMap[K,V] with OrderedMap[K,V]<code>.  There are a couple things going on here.  The trait</code>LNodeMap[K,V]` ensures that the new object is in particular a leaf node, which embodies a new empty tree in the Red-Black tree system.</p>

<p>The type <code>InjectMap[K,V]</code> has an even more interesting purpose.  Here is its definition:
``` scala
class InjectMap<a href="val%20keyOrdering:%20Ordering[K]">K, V</a> {
  def iNode(clr: Color, dat: Data[K], ls: Node[K], rs: Node[K]) =</p>

<pre><code>new InjectMap[K, V](keyOrdering) with INodeMap[K, V] with OrderedMap[K, V] {
  // INode
  val color = clr
  val lsub = ls
  val rsub = rs
  val data = dat.asInstanceOf[DataMap[K, V]]
}
</code></pre>

<p>}
<code>``
Firstly, note that it is a bona fide _class_, as opposed to a trait.  This class is where, finally, all things abstract are made real -- "dependency injection" in the parlance of Scala idioms.  You can see that it defines the implementation of abstract method</code>iNode<code>, and that it does this by returning yet _another_</code>InjectMap[K,V]<code>object, mixed with both</code>INodeMap[K,V]<code>and</code>OrderedMap[K,V]`, thus maintaining closure with respect to all three slices of functionality: dependency injection, the proper type of internal node, and map collection methods.</p>

<p>The various abstract <code>val</code> fields <code>color</code>, <code>data</code>, <code>lsub</code> and <code>rsub</code> are all given concrete values inside of <code>iNode</code>.  Here is where the value of concrete "reference" implementations manifests.  Any fields in the relevant internal-node type must be instantiated here, and the logic of instantiation cannot be inherited while still preserving the ability to mix abstract traits.  Therefore, any programmer wishing to create a new concrete sub-class must replicate the logic for instantiating all inherited in an internal node.</p>

<p>Another example makes the implications more clear.  Here is the definition of injection for a <a href="https://github.com/erikerlandson/silex/blob/blog/rbtraits/src/test/scala/com/redhat/et/silex/maps/mixed.scala">collection that mixes in all three traits</a> for incrementable values, nearest-key queries, and prefix-sum queries:</p>

<p>``` scala
  class Inject[K, V, P](</p>

<pre><code>val keyOrdering: Numeric[K],
val valueMonoid: Monoid[V],
val prefixMonoid: IncrementingMonoid[P, V]) {
  def iNode(clr: Color, dat: Data[K], ls: Node[K], rs: Node[K]) =
  new Inject[K, V, P](keyOrdering, valueMonoid, prefixMonoid)
      with INodeTD[K, V, P] with TDigestMap[K, V, P] {
    // INode[K]
    val color = clr
    val lsub = ls.asInstanceOf[NodeTD[K, V, P]]
    val rsub = rs.asInstanceOf[NodeTD[K, V, P]]
    val data = dat.asInstanceOf[DataMap[K, V]]
    // INodePS[K, V, P]
    val prefix = prefixMonoid.inc(prefixMonoid.plus(lsub.pfs, rsub.pfs), data.value)
    // INodeNear[K, V]
    val kmin = lsub match {
      case n: INodeTD[K, V, P] =&gt; n.kmin
      case _ =&gt; data.key
    }
    val kmax = rsub match {
      case n: INodeTD[K, V, P] =&gt; n.kmax
      case _ =&gt; data.key
    }
  }
</code></pre>

<p>  }
```
Here you can see that all logic for both "basic" internal nodes and also for maintaining prefix sums, and key min/max information for nearest-entry queries, must be supplied.  If there is a singularity in this design here is where it is.  The saving grace is that it is localized into a single well defined place, and any logic can be transcribed from a proper reference implementation of whatever traits are being mixed.</p>

<p><a name="mixing"></a></p>

<h5>Finale: Trait Mixing</h5>

<p>I will conclude by showing the code for mixing tree node traits and collection traits, which is elegant.  Here are type definitions for tree nodes and collection traits that inherit from incrementable values, nearest-key queries, and prefix-sum queries, and there is almost no code except the proper inheritances:</p>

<p>``` scala
object tree {
  import com.redhat.et.silex.maps.increment.tree.<em>
  import com.redhat.et.silex.maps.prefixsum.tree.</em>
  import com.redhat.et.silex.maps.nearest.tree._</p>

<p>  trait NodeTD[K, V, P] extends NodePS[K, V, P] with NodeInc[K, V] with NodeNearMap[K, V]</p>

<p>  trait LNodeTD[K, V, P] extends NodeTD[K, V, P]</p>

<pre><code>  with LNodePS[K, V, P] with LNodeInc[K, V] with LNodeNearMap[K, V]
</code></pre>

<p>  trait INodeTD[K, V, P] extends NodeTD[K, V, P]</p>

<pre><code>  with INodePS[K, V, P] with INodeInc[K, V] with INodeNearMap[K, V] {
val lsub: NodeTD[K, V, P]
val rsub: NodeTD[K, V, P]
</code></pre>

<p>  }
}</p>

<p>// ...</p>

<p>sealed trait TDigestMap[K, V, P]
  extends IncrementMapLike[K, V, INodeTD[K, V, P], TDigestMap[K, V, P]]
  with PrefixSumMapLike[K, V, P, INodeTD[K, V, P], TDigestMap[K, V, P]]
  with NearestMapLike[K, V, INodeTD[K, V, P], TDigestMap[K, V, P]] {</p>

<p>  override def toString = // ...
}
```</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.4.0 released! ( September 14, 2015 )]]></title>
      <link href="manual/v8.4.0/10_3Stable_Release.html"/>
      <updated>2015-09-14T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor version 8.4.0.
After a year of development, this is the first release of the new stable series.

This version contains:
a Docker Universe to run a Docker container as an HTCondor job;
the submit file can queue a job for each file found;
the submit file can contain macros;
a dry-run option to condor_submit to test the submit file without any actions;
HTCondor pools can use IPv4 and IPv6 simultaneously;
execute directories can be encrypted upon user or administrator request;
Vanilla Universe jobs can utilize periodic application-level checkpoints;
the administrator can establish job requirements;
numerous scalability changes.

Further details can be found in the
Version History.
HTCondor 8.4.0 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.8 released! ( August 27, 2015 )]]></title>
      <link href="manual/v8.3.8/10_3Development_Release.html"/>
      <updated>2015-08-27T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.8.
This development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.2.9
stable release.

Enhancements in the release include:
a script to tune Linux kernel parameters for better scalability;
support for python bindings on Windows platforms;
a mechanism to remove Docker images from the local machine.

Static analysis tools were used to identify and fix memory leaks and
other code deficiencies.

Further details can be found in the
Version History.
HTCondor 8.3.8 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Lightweight Non-Negative Numerics for Better Scala Type Signatures]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/"/>
      <updated>2015-08-19T00:42:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I want to discuss several advantages of defining lightweight non-negative numeric types in Scala, whose primary benefit is that they allow improved type signatures for Scala functions and methods.  I'll first describe the simple class definition, and then demonstrate how it can be used in function signatures and the benefits of doing so. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Reservoir Sampling Gap Distribution]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution/"/>
      <updated>2015-08-17T14:35:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2014/09/11/faster-random-samples-with-gap-sampling/">previous post</a>, I showed that random Bernoulli and Poisson sampling could be made much faster by modeling the <em>sampling gap distribution</em> - that is, directly drawing random samples from the distribution of how many elements would be skipped over between actual samples taken. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Generalizing Kendall's Tau]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/14/generalizing-kendalls-tau/"/>
      <updated>2015-08-14T21:35:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/14/generalizing-kendalls-tau</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Recently I have been applying <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient">Kendall's Tau</a> as an evaluation metric to assess how well a regression model ranks input samples, with respect to a known correct ranking. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.2.9 released! ( August 13, 2015 )]]></title>
      <link href="manual/v8.2.9/10_3Stable_Release.html"/>
      <updated>2015-08-13T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor version 8.2.9.
A stable series release contains significant bug and security fixes.
This version contains:
a mechanism for the preemption of dynamic slots, such that the
partitionable slot may use the dynamic slot in the match of a different job;
default configuration bug fixes for the desktop policy, such that
it can both start jobs and monitor the keyboard.

A complete list of fixed bugs can be found in the
Version History.
HTCondor 8.2.9 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[GPUs and adding new resources types to the HTCondor-CE]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/08/gpus-and-adding-new-resources-types-to.html"/>
      <updated>2015-08-07T21:45:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-6301136022425730449</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The more things change, the more they stay the same]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/07/the-more-things-change-more-they-stay.html"/>
      <updated>2015-07-28T15:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-8394942129716842708</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.7 released! ( July 27, 2015 )]]></title>
      <link href="manual/v8.3.7/10_3Development_Release.html"/>
      <updated>2015-07-27T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.7.
This development series release contains new features that are under
development.

Enhancements in the release include:
default configuration settings have been updated to reflect current usage;
the ability to preempt dynamic slots, such that a job may match with a partitionable slot;
the ability to limit the number of jobs per submission and the number of jobs per owner by setting configuration variables.

Further details can be found in the
Version History.
HTCondor 8.3.7 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.6 released! ( June 23, 2015 )]]></title>
      <link href="manual/v8.3.6/10_3Development_Release.html"/>
      <updated>2015-06-23T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.6.
This development series release contains new features that are under
development.

Enhancements in the release include:
initial Docker universe support;
IPv4/IPv6 mixed mode support.

Further details can be found in the
Version History.
HTCondor 8.3.6 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[fedmsg talk at Spark Summit]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/summit-fedmsg.html"/>
      <updated>2015-06-15T15:05:27Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/summit-fedmsg</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I&rsquo;m speaking at Spark Summit today about using Spark to analyze operational data from the Fedora project.  Here are some links to further resources related to my talk: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Spark ML Pipeline transformers]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers.html"/>
      <updated>2015-06-14T00:07:58Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post, we&rsquo;ll see how to make a simple transformer for <a href="https://spark.apache.org/docs/latest/ml-guide.html">Spark ML Pipelines</a>.  The transformer we&rsquo;ll design will generate a sparse binary feature vector from an array-valued field representing a set. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bokeh plots from Spark]]></title>
      <link href="http://chapeau.freevariable.com/2015/05/bokeh-plots-from-spark.html"/>
      <updated>2015-05-21T16:05:10Z</updated>
      <id>http://chapeau.freevariable.com/2015/05/bokeh-plots-from-spark</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>This post will show you an extremely simple way to make quick-and-dirty <a href="http://bokeh.pydata.org/en/latest/">Bokeh</a> plots from data you&rsquo;ve generated in Spark, but the basic technique is generally applicable to any data that you&rsquo;re generating in some application that doesn&rsquo;t necessarily link in the Bokeh libraries. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Planning your career like a racing season]]></title>
      <link href="http://chapeau.freevariable.com/2015/05/process-goals.html"/>
      <updated>2015-05-14T21:04:20Z</updated>
      <id>http://chapeau.freevariable.com/2015/05/process-goals</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Most people set personal and professional goals.  If you work in software, your near-term professional goals might sound like this: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Parallel K-Medoids Using Scala ParSeq]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/"/>
      <updated>2015-05-06T23:33:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Scala supplies a <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections library</a> that was designed to make it easy for a programmer to add parallel computing over the elements in a collection.  In this post, I will describe a case study of applying Scala's parallel collections to cleanly implement multithreading support for training a K-Medoids clustering model. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Elasticsearch and Spark 1.3]]></title>
      <link href="http://chapeau.freevariable.com/2015/04/elasticsearch-and-spark-1-dot-3.html"/>
      <updated>2015-04-30T20:34:37Z</updated>
      <id>http://chapeau.freevariable.com/2015/04/elasticsearch-and-spark-1-dot-3</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a> has offered Hadoop <code>InputFormat</code> and <code>OutputFormat</code> implementations for quite some time.  These made it possible to process Elasticsearch indices with Spark just as you would any other Hadoop data source.  Here&rsquo;s an example of this in action, taken from <a href="http://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html">Elastic&rsquo;s documentation</a>: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[HTCondor CacheD: Caching for HTC - Part 2]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/htcondor-cached-caching-for-htc-part-2.html"/>
      <updated>2015-01-25T15:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-5260378956420164105</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Condor CacheD: Caching for HTC - Part 1]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/condor-cached-caching-for-htc-part-1.html"/>
      <updated>2015-01-22T16:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1889975382858537261</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
</feed>
