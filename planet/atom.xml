<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2015-09-08T03:28:08-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.8 released! ( August 27, 2015 )]]></title>
      <link href="manual/v8.3.8/10_3Development_Release.html"/>
      <updated>2015-08-27T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.8.
This development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.2.9
stable release.

Enhancements in the release include:
a script to tune Linux kernel parameters for better scalability;
support for python bindings on Windows platforms;
a mechanism to remove Docker images from the local machine.

Static analysis tools were used to identify and fix memory leaks and
other code deficiencies.

Further details can be found in the
Version History.
HTCondor 8.3.8 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Lightweight Non-Negative Numerics for Better Scala Type Signatures]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/"/>
      <updated>2015-08-19T00:42:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post I want to discuss several advantages of defining lightweight non-negative numeric types in Scala, whose primary benefit is that they allow improved type signatures for Scala functions and methods.  I'll first describe the simple class definition, and then demonstrate how it can be used in function signatures and the benefits of doing so.</p>

<p>If the following ideas interest you at all, I highly recommend looking at the <a href="https://github.com/fthomas/refined">'refined' project</a> authored by <a href="http://timepit.eu/~frank/">Frank S. Thomas</a>, which generalizes on the ideas below and supports additional static checking functionalities via macros.</p>

<h5>A Non-Negative Integer Type</h5>

<p>As a working example, I'll discuss a non-negative integer type <code>NonNegInt</code>.  My proposed definition is sufficiently lightweight to view as a single code block:</p>

<p>``` scala
object nonneg {
  import scala.language.implicitConversions</p>

<p>  class NonNegInt private (val value: Int) extends AnyVal</p>

<p>  object NonNegInt {</p>

<pre><code>def apply(v: Int) = {
  require(v &gt;= 0, "NonNegInt forbids negative integer values")
  new NonNegInt(v)
}

implicit def toNonNegInt(v: Int) = NonNegInt(v)
</code></pre>

<p>  }</p>

<p>  implicit def toInt(nn: NonNegInt) = nn.value
}
```</p>

<p>The notable properties and features of <code>NonNegInt</code> are:</p>

<ul>
<li><code>NonNegInt</code> is a value class around an <code>Int</code>, and so invokes no actual object construction or allocation</li>
<li>Its constructor is private, and so is safe from directly constructing around a negative integer</li>
<li>It supplies factory method <code>NonNegInt(v)</code> to construct a non negative integer value</li>
<li>It supplies implicit conversion from <code>Int</code> values to <code>NonNegInt</code></li>
<li>Both factory method and implicit conversion check for negative values.  There is no way to construct a <code>NonNegInt</code> that contains a negative integer value.</li>
<li>It also supplies implicit conversion from <code>NonNegInt</code> back to <code>Int</code>.  Moving back and forth between <code>Int</code> and <code>NonNegInt</code> is effectively transparent.</li>
</ul>


<p>The above properties work to make <code>NonNegInt</code> very lightweight with respect to size and runtime properties, and semantically safe in the sense that it is impossible to construct one with a negative value inside it.</p>

<h5>Application of <code>NonNegInt</code></h5>

<p>I primarily envision <code>NonNegInt</code> as an easy and informative way to declare function parameters that are only well defined for non-negative values, without the need to write any explicit checking code, and yet allowing the programmer to call the function with normal <code>Int</code> values, due to the implicit conversions:</p>

<p>``` scala
object example {
  import nonneg._</p>

<p>  def element<a href="seq:%20Seq[T],%20j:%20NonNegInt">T</a> = seq(j)</p>

<p>  // call element function with a regular Int index
  val e = element(Vector(1,2,3), 1) // e is set to 2
}
```</p>

<p>This short example demonstrates some appealing properties of <code>NonNegInt</code>.  Firstly, the constraint that index <code>j &gt;= 0</code> is enforced via the type definition, and so the programmer does not have to write the usual <code>require(j &gt;= 0, ...)</code> check (or worry about forgetting it).  Secondly, the implicit conversion from <code>Int</code> to <code>NonNegInt</code> means the programmer can just provide a regular integer value for parameter <code>j</code>, instead of having to explicitly say <code>NonNegInt(1)</code>.  Third, the implicit conversion from <code>NonNegInt</code> to <code>Int</code> means that <code>j</code> can easily be used anywhere a regular <code>Int</code> is used.  Last, and very definitely not least, the fact that function <code>element</code> requires a non-negative integer is obvious <strong>right in the function signature</strong>.  There is no need for a programmer to guess whether <code>j</code> can be negative, and no need for the author of <code>element</code> to document that <code>j</code> cannot be negative.  Its type makes that completely clear.</p>

<h5>Conclusions</h5>

<p>In this post I've laid out some advantages of defining lightweight non-negative numeric types, in particular using <code>NonNegInt</code> as a working example.  Clearly, if you want to apply this idea, you'd want to also define <code>NonNegLong</code>, <code>NonNegDouble</code>, <code>NonNegFloat</code> and for that matter <code>PosInt</code>, <code>PosLong</code>, etc.  Happy computing!</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Reservoir Sampling Gap Distribution]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution/"/>
      <updated>2015-08-17T14:35:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/17/the-reservoir-sampling-gap-distribution</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2014/09/11/faster-random-samples-with-gap-sampling/">previous post</a>, I showed that random Bernoulli and Poisson sampling could be made much faster by modeling the <em>sampling gap distribution</em> - that is, directly drawing random samples from the distribution of how many elements would be skipped over between actual samples taken.</p>

<p>Another popular sampling algorithm is <a href="https://en.wikipedia.org/wiki/Reservoir_sampling">Reservoir Sampling</a>.  Its sampling logic is a bit more complicated than Bernoulli or Poisson sampling, in the sense that the probability of sampling any given (jth) element <em>changes</em>. For a sampling reservoir of size R, and all j>R, the probability of choosing element (j) is R/j.  You can see that the potential payoff for gap-sampling is big, particularly as data size becomes large; as (j) approaches infinity, the probability R/j goes to zero, and the corresponding gaps between samples grow without bound.</p>

<p>Modeling a sampling gap distribution is a powerful tool for optimizing a sampling algorithm, but it requires that (1) you actually <em>know</em> the sampling distribution, and (2) that you can effectively draw values from that distribution faster than just applying a random process to drawing each data element.</p>

<p>With that goal in mind, I derived the probability mass function (pmf) and cumulative distribution function (cdf) for the sampling gap distribution of reservoir sampling.  In this post I will show the derivations.</p>

<h3>The Sampling Gap Distribution</h3>

<p>In the interest of making it easy to get at the actual answers, here are the pmf and cdf for the Reservoir Sampling Gap Distribution.  For a sampling reservoir of size (R), starting at data element (j), the probability distribution of the sampling gap is:</p>

<p><img src="/assets/images/reservoir1/figure6.png" title="Figure 6" alt="Figure 6" /></p>

<h3>Conventions</h3>

<p>In the derivations that follow, I will keep to some conventions:</p>

<ul>
<li>R = the sampling reservoir size.  R > 0.</li>
<li>j = the index of a data element being considered for sampling.  j > R.</li>
<li>k = the size of a gap between samples.  k >= 0.</li>
</ul>


<p>P(k) is the probability that the gap between one sample and the next is of size k.  The support for P(k) is over all k>=0.  I will generally assume that j>R, as the first R samples are always loaded into the reservoir and the actual random sampling logic starts at j=R+1.  The constraint j>R will also be relevant to many binomial coefficient expressions, where it ensures the coefficient is well defined.</p>

<h3>Deriving the Probability Mass Function, P(k)</h3>

<p>Suppose we just chose (randomly) to sample data element (j-1).  Now we are interested in the probability distribution of the next sampling gap.  That is, the probability P(k) that we will <em>not</em> sample the next (k) elements {j,j+1,...j+k-1}, and sample element (j+k):</p>

<p><img src="/assets/images/reservoir1/figure1.png" title="Figure 1" alt="Figure 1" /></p>

<p>By arranging the product terms in descending order as above, you can see that they can be written as factorial quotients:</p>

<p><img src="/assets/images/reservoir1/figure2.png" title="Figure 2" alt="Figure 2" /></p>

<p>Now we apply <a href="#LemmaA">Lemma A</a>.  The 2nd case (a&lt;=b) of the Lemma applies, since (j-1-R)&lt;=j, so we have:</p>

<p><img src="/assets/images/reservoir1/figure3.png" title="Figure 3" alt="Figure 3" /></p>

<p>And so we have now derived a compact, closed-form expression for P(k).</p>

<h3>Deriving the Cumulative Distribution Function, F(k)</h3>

<p>Now that we have a derivation for the pmf P(k), we can tackle a derivation for the cdf.  First I will make note of this <a href="https://en.wikipedia.org/wiki/Binomial_coefficient#Series_involving_binomial_coefficients">useful identity</a> that I scraped off of Wikipedia (I substituted (x) => (a) and (k) => (b)):</p>

<p><img src="/assets/images/reservoir1/identity1.png" title="identity 1" alt="identity 1" /></p>

<p>The cumulative distribution function for the sampling gap, F(k), is of course just the sum over P(t), for (t) from 0 up to (k):</p>

<p><img src="/assets/images/reservoir1/figure4.png" title="Figure 4" alt="Figure 4" /></p>

<p>This is a closed-form solution, but we can apply a bit more simplification:</p>

<p><img src="/assets/images/reservoir1/figure5.png" title="Figure 5" alt="Figure 5" /></p>

<h3>Conclusions</h3>

<p>We have derived closed-form expressions for the pmf and cdf of the Reservoir Sampling gap distribution:</p>

<p><img src="/assets/images/reservoir1/figure6.png" title="Figure 6" alt="Figure 6" /></p>

<p>In order to apply these results to a practical gap-sampling implementation of Reservoir Sampling, we would next need a way to efficiently sample from P(k), to obtain gap sizes to skip over.  How to accomplish this is an open question, but knowing a formula for P(k) and F(k) is a start.</p>

<h3>Acknowledgements</h3>

<p>Many thanks to <a href="http://rnowling.github.io/">RJ Nowling</a> and <a href="http://chapeau.freevariable.com/">Will Benton</a> for proof reading and moral support!  Any remaining errors are my own fault.</p>

<p><a name="LemmaA"></a></p>

<h3>Lemma A, And Its Proof</h3>

<p><img src="/assets/images/reservoir1/lemmaA.png" title="Lemma A" alt="Lemma A" /></p>

<p><img src="/assets/images/reservoir1/lemmaAproof.png" title="Lemma A Proof" alt="Lemma A Proof" /></p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Generalizing Kendall's Tau]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/08/14/generalizing-kendalls-tau/"/>
      <updated>2015-08-14T21:35:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/08/14/generalizing-kendalls-tau</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Recently I have been applying <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient">Kendall's Tau</a> as an evaluation metric to assess how well a regression model ranks input samples, with respect to a known correct ranking.</p>

<p>The process of implementing the Kendall's Tau statistic, with my software engineer's hat on, caused me to reflect a bit on how it could be generalized beyond the traditional application of ranking numeric pairs.  In this post I'll discuss the generalization of Kendall's Tau to non-numeric data, and also generalizing from totally ordered data to partial orderings.</p>

<h5>A Review of Kendall's Tau</h5>

<p>I'll start with a brief review of Kendall's Tau.  For more depth, a good place to start is the Wikipedia article at the link above.</p>

<p>Consider a sequence of (n) observations where each observation is a pair (x,y), where we wish to measure how well a ranking by x-values agrees with a ranking by the y-values.  Informally, Kendall's Tau (aka the Kendall Rank Correlation Coefficient) is the difference between number of observation-pairs (pairs of pairs, if you will) whose ordering <em>agrees</em> ("concordant" pairs) and the number of such pairs whose ordering <em>disagrees</em> ("discordant" pairs).  This difference is divided by the total number of observation pairs.</p>

<p>The commonly-used formulation of Kendall's Tau is the "Tau-B" statistic, which accounts for observed pairs having tied values in either x or y as being neither concordant nor discordant:</p>

<h6>Figure 1: Kendall's Tau-B</h6>

<p><img src="/assets/images/kendalls_tau/figure_1.png" title="Kendall's Tau" alt="Kendall's Tau" /></p>

<p>The formulation above has quadratic complexity, with respect to data size (n).  It is possible to rearrange this computation in a way that can be computed in (n)log(n) time[1]:</p>

<h6>Figure 2: An (n)log(n) formulation of Kendall's Tau-B</h6>

<p><img src="/assets/images/kendalls_tau/figure_2.png" title="Kendall's Tau" alt="Kendall's Tau" /></p>

<p>The details of performing this computation can be found at [1] or on the <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient#Algorithms">Wikipedia entry</a>.  For my purposes, I'll note that it requires two (n)log(n) sorts of the data, which becomes relevant below.</p>

<h5>Generalizing to Non-Numeric Values</h5>

<p>Generalizing Kendall's Tau to non-numeric values is mostly just making the observation that the definition of "concordant" and "discordant" pairs is purely based on comparing x-values and y-values (and, in the (n)log(n) formulation, performing sorts on the data).  From the software engineer's perspective this means that the computations are well defined on any data type with an ordering relation, which includes numeric types but also chars, strings, sequences of any element supporting an ordering, etc.  Significantly, most programming languages support the concept of defining ordering relations on arbitrary data types, which means that <em><em>Kendall's Tau can, in principle, be computed on literally any kind of data structure</em></em>, provided you supply it with a well defined ordering.  Furthermore, an examination of the algorithms shows that values of x and y need not even be of the same type, nor do they require the same ordering.</p>

<h5>Generalizing to Partial Orderings</h5>

<p>When I brought this observation up, my colleague <a href="http://chapeau.freevariable.com/">Will Benton</a> asked the very interesting question of whether it's also possible to compute Kendall's Tau on objects that have only a <em>partial ordering</em>.  It turns out that you <em><em>can</em></em> define Kendall's Tau on partially ordered data, by defining the case of two non-comparable x-values, or y-values, as another kind of tie.</p>

<p>The big caveat with this definition is that the (n)log(n) optimization does not apply.  Firstly, the optimized algorithm relies heavily on (n)log(n) sorting, and there is no unique full sorting of elements that are only partially ordered.  Secondly, the formula's definition of the quantities n1, n2 and n3 is founded on the assumption that element equality is transitive; this is why you can count a number of tied values, t, and use t(t-1)/2 as the corresponding number of tied pairs.  But in a partial ordering, this assumption is violated. Consider the case where (a) &lt; (b), but (a) is non-comparable to (c) and (b) is also non-comparable to (c).  By our definition, (a) is tied with (c), and (c) is tied with (b), but transitivity is violated, as (a) &lt; (b).</p>

<p>So how <em>can</em> we compute Tau in this case?  Consider (n1) and (n2), in Figure-1.  These values represent the number of pairs that were tied wrt (x) and (y), respectively.  We can't use the shortcut formulas for (n1) and (n2), but we can count them directly, pair by pair, simply by conducting the traditional quadratic iteration over pairs, and incrementing (n1) whenever two x-values are noncomparable, and incrementing (n2) whenever two y-values are non-comparable, just as we increment (nc) and (nd) to count concordant and discordant pairs.  With this modification, we can apply the formula in Figure-1 as-is.</p>

<h5>Conclusions</h5>

<p>I made these observations without any particular application in mind. However, my instincts as a software engineer tell me that making generalizations in this way often paves the way for new ideas, once the generalized concept is made available.  With luck, it will inspire either me or somebody else to apply Kendall's Tau in interesting new ways.</p>

<h5>References</h5>

<p>[1] Knight, W. (1966). "A Computer Method for Calculating Kendall's Tau with Ungrouped Data". Journal of the American Statistical Association 61 (314): 436–439. doi:10.2307/2282833. JSTOR 2282833.</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.2.9 released! ( August 13, 2015 )]]></title>
      <link href="manual/v8.2.9/10_3Stable_Release.html"/>
      <updated>2015-08-13T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor version 8.2.9.
A stable series release contains significant bug and security fixes.
This version contains:
a mechanism for the preemption of dynamic slots, such that the
partitionable slot may use the dynamic slot in the match of a different job;
default configuration bug fixes for the desktop policy, such that
it can both start jobs and monitor the keyboard.

A complete list of fixed bugs can be found in the
Version History.
HTCondor 8.2.9 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[GPUs and adding new resources types to the HTCondor-CE]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/08/gpus-and-adding-new-resources-types-to.html"/>
      <updated>2015-08-07T21:45:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-6301136022425730449</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The more things change, the more they stay the same]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/07/the-more-things-change-more-they-stay.html"/>
      <updated>2015-07-28T15:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-8394942129716842708</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.7 released! ( July 27, 2015 )]]></title>
      <link href="manual/v8.3.7/10_3Development_Release.html"/>
      <updated>2015-07-27T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.7.
This development series release contains new features that are under
development.

Enhancements in the release include:
default configuration settings have been updated to reflect current usage;
the ability to preempt dynamic slots, such that a job may match with a partitionable slot;
the ability to limit the number of jobs per submission and the number of jobs per owner by setting configuration variables.

Further details can be found in the
Version History.
HTCondor 8.3.7 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.6 released! ( June 23, 2015 )]]></title>
      <link href="manual/v8.3.6/10_3Development_Release.html"/>
      <updated>2015-06-23T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.6.
This development series release contains new features that are under
development.

Enhancements in the release include:
initial Docker universe support;
IPv4/IPv6 mixed mode support.

Further details can be found in the
Version History.
HTCondor 8.3.6 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[fedmsg talk at Spark Summit]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/summit-fedmsg.html"/>
      <updated>2015-06-15T15:05:27Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/summit-fedmsg</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I&rsquo;m speaking at Spark Summit today about using Spark to analyze operational data from the Fedora project.  Here are some links to further resources related to my talk: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Spark ML Pipeline transformers]]></title>
      <link href="http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers.html"/>
      <updated>2015-06-14T00:07:58Z</updated>
      <id>http://chapeau.freevariable.com/2015/06/using-sparks-ml-pipeline-transformers</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In this post, we&rsquo;ll see how to make a simple transformer for <a href="https://spark.apache.org/docs/latest/ml-guide.html">Spark ML Pipelines</a>.  The transformer we&rsquo;ll design will generate a sparse binary feature vector from an array-valued field representing a set. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bokeh plots from Spark]]></title>
      <link href="http://chapeau.freevariable.com/2015/05/bokeh-plots-from-spark.html"/>
      <updated>2015-05-21T16:05:10Z</updated>
      <id>http://chapeau.freevariable.com/2015/05/bokeh-plots-from-spark</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>This post will show you an extremely simple way to make quick-and-dirty <a href="http://bokeh.pydata.org/en/latest/">Bokeh</a> plots from data you&rsquo;ve generated in Spark, but the basic technique is generally applicable to any data that you&rsquo;re generating in some application that doesn&rsquo;t necessarily link in the Bokeh libraries. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Planning your career like a racing season]]></title>
      <link href="http://chapeau.freevariable.com/2015/05/process-goals.html"/>
      <updated>2015-05-14T21:04:20Z</updated>
      <id>http://chapeau.freevariable.com/2015/05/process-goals</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Most people set personal and professional goals.  If you work in software, your near-term professional goals might sound like this: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Parallel K-Medoids Using Scala ParSeq]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/"/>
      <updated>2015-05-06T23:33:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Scala supplies a <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections library</a> that was designed to make it easy for a programmer to add parallel computing over the elements in a collection.  In this post, I will describe a case study of applying Scala's parallel collections to cleanly implement multithreading support for training a K-Medoids clustering model. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Elasticsearch and Spark 1.3]]></title>
      <link href="http://chapeau.freevariable.com/2015/04/elasticsearch-and-spark-1-dot-3.html"/>
      <updated>2015-04-30T20:34:37Z</updated>
      <id>http://chapeau.freevariable.com/2015/04/elasticsearch-and-spark-1-dot-3</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://chapeau.freevariable.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a> has offered Hadoop <code>InputFormat</code> and <code>OutputFormat</code> implementations for quite some time.  These made it possible to process Elasticsearch indices with Spark just as you would any other Hadoop data source.  Here&rsquo;s an example of this in action, taken from <a href="http://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html">Elastic&rsquo;s documentation</a>: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 8.3.5 released! ( April 20, 2015 )]]></title>
      <link href="manual/v8.3.5/10_3Development_Release.html"/>
      <updated>2015-04-20T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 8.3.5.
A development series release contains new features that are under
development. This release contains all of the bug fixes from the 8.2.8
stable release.
A few of the enhancements in this release include:
new features that increase the power of job specification in the
submit description file;
RPMs for Red Hat Enterprise Linux 6 and 7 are modularized and only
distributed via our YUM repository;
The new condor-all RPM requires
the other HTCondor RPMs of a typical HTCondor installation.
Further details can be found in the
Version History.
HTCondor 8.3.5 binaries and source code are available from our
Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Hygienic Closures for Scala Function Serialization]]></title>
      <link href="http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization/"/>
      <updated>2015-03-31T13:06:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In most use cases of Scala closures, what you see is what you get, but there are exceptions where looks can be deceiving and this can have a big impact on closure serialization.  Closure serialization is of more than academic interest.  Tools like Apache Spark cannot operate without serializing functions over the network.  In this post I'll describe some scenarios where closures include more than what is evident in the code, and then a technique for preventing unwanted inclusions. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[HTCondor CacheD: Caching for HTC - Part 2]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/htcondor-cached-caching-for-htc-part-2.html"/>
      <updated>2015-01-25T15:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-5260378956420164105</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Condor CacheD: Caching for HTC - Part 1]]></title>
      <link href="http://derekweitzel.blogspot.com/2015/01/condor-cached-caching-for-htc-part-1.html"/>
      <updated>2015-01-22T16:00:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1889975382858537261</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Getting Started with Mesos on Fedora 21 and CentOS 7]]></title>
      <link href="http://timothysc.github.com/blog/2014/09/08/mesos-breeze/"/>
      <updated>2014-09-08T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2014/09/08/mesos-breeze</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p><img class="left" src="http://timothysc.github.com/images/mesos_logo.png"> [...]</p>
]]></content>
    </entry>
  
</feed>
