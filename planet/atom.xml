<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2013-06-06T11:49:11-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[ HPCwire article highlights running stochastic models on HTCondor ( June 6, 2013 )]]></title>
      <link href="http://www.hpcwire.com/hpcwire/2013-05-30/running_stochastic_models_on_htcondor.html"/>
      <updated>2013-06-06T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[An article published at HPCwire highlights research out of Brigham Young University with a goal to 
demonstrate an alternative model to High Performance Computing (HPC) for water resource stakeholders by leveraging
High Throughput Computing (HTC) with HTCondor.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ Atlas project at CERN describes their computing environment ( May 29, 2013 )]]></title>
      <link href="http://www.hpcwire.com/hpcwire/2013-05-21/cern_google_and_the_future_of_global_science_initiatives.html"/>
      <updated>2013-05-29T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HPCwire: CERN, Google Drive Future of Global Science Initiatives article describes the computing environment of 
the ATLAS project at CERN.  
HTCondor and now Google Compute Engine aid the extensive collision 
analysis effort for ATLAS.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Submitting R jobs with Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/05/submitting-r-jobs-with-bosco.html"/>
      <updated>2013-05-20T14:51:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9067247722276578550</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[The Bosco team has been working on integrating with the <a href="http://www.r-project.org/">R</a> statistics processing language. &nbsp;We have&nbsp;chosen&nbsp;to modify the <a href="http://cran.r-project.org/web/packages/GridR/index.html">GridR</a> package in order to integrate with R.<br /><br /><h3>How will the R user see Bosco?</h3><div>The goal of the integration is to simplify the method of submitting processing, written in the R&nbsp;language, to remote clusters and grids. &nbsp;The expected steps for the integration are:</div><div><ol><li>Install Bosco</li><li>Install the Bosco'ified GridR package into your local R environment.</li></ol></div><div>After installing the 2 pieces of software above, the user creates a R script, which includes the 'function' that is to be executed on the remote cluster. &nbsp;The user can send any data as input, lists, tables, an entire CSV file (already read into a R variable). &nbsp;The function output will be automatically imported into the environment when the remote job has completed.</div><div><br /></div><div>Below is a demo of the GridR package working with Bosco to submit to a campus cluster here at Nebraska.</div><div><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-WJlIyBopEBk/UZo2UDWMOCI/AAAAAAAAB8E/8jP712IKSMQ/s1600/Screen+Shot+2013-05-18+at+12.55.40+AM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="433" src="http://4.bp.blogspot.com/-WJlIyBopEBk/UZo2UDWMOCI/AAAAAAAAB8E/8jP712IKSMQ/s640/Screen+Shot+2013-05-18+at+12.55.40+AM.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><a href="http://www.rstudio.com/">RStudio</a> IDE showing demo of Bosco + GridR integration</td></tr></tbody></table><div>The steps in the demo are:</div><div><ol><li>Load the GridR library</li><li>Create the function, in this case named simply 'a' that doubles the value of the argument.</li><li>Initialize the GridR integration to talk to Bosco</li><li>"Apply" the function. &nbsp;Run the function 'a', with the input 14, and write the result to the variable "x". &nbsp;Also, wait for the remote job to complete.</li><li>Finally, I printed out the value of x, which is 28, double the 14.&nbsp;</li></ol><div>This is a very simple demo. &nbsp;You could imagine the function sent to the remote machine could parse the a CSV file, or more complex operations...</div></div><div><br /></div><div>The Bosco team expects to have this integration done and in production by Mid-July for the <a href="http://161.67.142.97/congresos/useR-2013/%E2%80%8E">R users meeting</a>.</div><br /><center> <a href="http://bosco.opensciencegrid.org/download/">     <img alt="Bosco Download" src="https://raw.github.com/osg-bosco/bosco-download-images/master/images/download-orange.png" style="border-width: 0;" /> </a>   </center>]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTCondor 7.9.6 released! ( May 08, 2013 )]]></title>
      <link href="manual/v7.9/9_3Development_Release.html"/>
      <updated>2013-05-08T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[The HTCondor team is pleased to announce the release of HTCondor 7.9.6.
This is the final release of the 7.9 series. This release contains new
tools, VMware player support, Linux out of memory killer hints, python
bindings, new configuration parameters, and many bug fixes.
A complete list of bugs fixed and features can be found in the
Version History. HTCondor 7.9.6 binaries
and source code are available from our Downloads page.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Configuring a Personal Hadoop Development Environment on Fedora 18]]></title>
      <link href="http://timothysc.github.com/blog/2013/04/22/personalhadoop/"/>
      <updated>2013-04-22T15:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/04/22/personalhadoop</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Installing Spark on Fedora 18]]></title>
      <link href="http://chapeau.freevariable.com/2013/04/installing-spark-on-fedora-18.html"/>
      <updated>2013-04-11T21:37:28Z</updated>
      <id>tag:chapeau.freevariable.com,2013://1.39</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[The Spark project is an actively-developed open-source engine for data analytics on clusters using Scala, Python, or Java. It offers map, filter, and reduce operations over in-memory collections, data from local files, or data taken from HDFS, but unlike standard...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Reprocessing CMS events with Bosco]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/04/reprocessing-cms-events-with-bosco.html"/>
      <updated>2013-04-02T19:38:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-9221383956864186778</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[ HTC deals with big data ( April 1, 2013 )]]></title>
      <link href="http://www.hpcinthecloud.com/ct/uz5597866Biz16505092"/>
      <updated>2013-04-01T05:00:00Z</updated>
      <id></id>
      <author>
        <name><![CDATA[HTCondor Team]]></name>
        <uri>http://research.cs.wisc.edu/htcondor</uri>
      </author>
      <content type="html"><![CDATA[Contributor Miha Ahronovitz traces the history of high throughput computing 
(HTC), noting the particularly enthusiastic response from the 
high energy physics world and the role of HTC in such important discoveries 
as the Higgs boson. As one of the biggest generators of data, 
this community has been dealing with the "big data" deluge long before "big data" assumed its position as the buzzword du jour.
Read more at HPC In the Cloud.
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Impact of Negotiator Cycle Cadence on Slot Loading]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading/"/>
      <updated>2013-03-21T22:10:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_1Introduction.html#8555">HTCondor negotiator</a> assigns jobs (resource requests) to slots (compute resources) at regular intervals, configured by the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#20544">NEGOTIATOR_INTERVAL</a> parameter.  This interval (the cycle <em>cadence</em>) has a fundamental impact on a pool <em>loading factor</em> -- the fraction of time that slots are being productively utilized. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Smooth Gradients for Cubic Hermite Splines]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/"/>
      <updated>2013-03-16T14:39:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, ... m_{n-1} \) at knot-points: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Examining the Modulus of Random Variables]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/"/>
      <updated>2013-03-15T19:03:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h3>Motivation</h3> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Running Quantum Espresso on the OSG]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/03/running-quantum-espresso-on-osg.html"/>
      <updated>2013-03-05T18:53:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-2337400839561942722</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Per-Process Mount Namespaces]]></title>
      <link href="http://timothysc.github.com/blog/2013/02/22/perprocess/"/>
      <updated>2013-02-22T16:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2013/02/22/perprocess</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Statistic changes in HTCondor 7.7]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/12/statistic-changes-in-htcondor-7-7/"/>
      <updated>2013-02-12T11:56:04Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=925</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Notice to HTCondor 7.8 users - Statistics implemented during the 7.5 series that landed in 7.7.0 were rewritten by the time 7.8 was released. If you were using the original statistics for monitoring and/or reporting, here is a table to help you map old (left column) to new (right column). See – 7.6 -&#62; 7.8 [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=925&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Bosco to submit to Amazon EC2]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/02/using-bosco-to-submit-to-amazon-ec2.html"/>
      <updated>2013-02-06T04:27:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-4538100752405939638</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[How accounting group configuration could work with Wallaby]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/05/how-accounting-group-configuration-could-work-with-wallaby/"/>
      <updated>2013-02-05T11:46:28Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=917</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Configuration of accounting groups in HTCondor is too often an expert task that requires coordination between administrators and their tools. Wallaby provides a coordination point, so long as a little convention is employed, and can provide a task specific interface to simplify configuration. Quick background, Wallaby provides semantic configuration for HTCondor. It models a pool [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=917&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Some htcondor-wiki stats]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/29/some-htcondor-wiki-stats/"/>
      <updated>2013-01-29T11:36:06Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=903</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[A few years ago I discovered Web Numbr, a service that will monitor a web page for a number and graph that number over time. I installed a handful of webnumbrs to track things at HTCondor&#8217;s gittrac instance. http://webnumbr.com/search?query=condor Thing such as - Tickets resolved with no destination: tickets that don&#8217;t indicate what version they [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=903&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Introducing the HTCondor-CE]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/introducing-htcondor-ce.html"/>
      <updated>2013-01-28T15:33:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1124494645797252707</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Concurrency Limits: Group defaults]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/21/concurrency-limits-group-defaults/"/>
      <updated>2013-01-21T12:47:07Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=895</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[Concurrency limits allow for protecting resources by providing a way to cap the number of jobs requiring a specific resource that can run at one time. For instance, limit licenses and filer access at four regional data centers. Notice the repetition. In addition to the repetition, every license.* and filer.* must be known and recorded [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=895&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bosco 1.1.1 Release]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/01/bosco-111-release.html"/>
      <updated>2013-01-14T18:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1926902995750303001</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Your API is a feature, give it real resource management]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/14/your-api-is-a-feature-give-it-real-resource-management/"/>
      <updated>2013-01-14T12:17:29Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=872</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[So much these days is about distributed resource management. That&#8217;s anything that can be created and destroyed in the cloud[0]. Proper management is especially important when the resource&#8217;s existence is tied to a real economy, e.g. your user&#8217;s credit card[1]. Above is a state machine required to ensure that resources created in AWS EC2 are [&#8230;]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=872&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Fun with ClassAds]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/fun-with-classads.html"/>
      <updated>2013-01-05T22:58:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1674994974092153801</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Mean of the Modulus Does Not Equal the Modulus of the Mean]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/"/>
      <updated>2013-01-02T15:55:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I've been considering models for the effects of HTCondor negotiation cycle cadence on pool loading and accounting group starvation, which led me to thinking about the effects of taking the modulus of a random variable, for reasons I plan to discuss in future posts. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Demonstration of Negotiator-Side Resource Consumption]]></title>
      <link href="http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption/"/>
      <updated>2012-12-03T15:25:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>HTCondor supports a notion of aggregate compute resources known as partitionable slots (p-slots), which may be consumed by multiple jobs.   Historically, at most one job could be matched against such a slot in a single negotiation cycle, which limited the rate at which partitionable slot resources could be utilized.  More recently, the scheduler has been enhanced with logic to allow it to acquire multiple claims against a partitionable slot, which increases the p-slot utilization rate. However, as this potentially bypasses the negotiator's accounting of global pool resources such as accounting group quotas and concurrency limits, it places some contraints on what jobs can can safely acquire multiple claims against any particular p-slot: for example, only other jobs on the same scheduler can be considered.  Additionally, candidate job requirements must match the requirements of the job that originally matched in the negotiator.  Another significant impact is that the negotiator is still forced to match an entire p-slot, which may have a large match cost (weight): these large match costs cause <a href="https://htcondor-wiki.cs.wisc.edu/index.cgi/tktview?tn=3013">accounting difficulties</a> when submitter shares and/or group quotas drop below the cost of a slot.  This particular problem is growing steadily larger, as machines with ever-larger numbers of cores and other resources appear in HTCondor pools. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Role enforcement in Cumin]]></title>
      <link href="http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin/"/>
      <updated>2012-11-12T20:20:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Roles in Cumin scope activities and content in the UI.  There are currently two roles defined in Cumin, <code>admin</code> and <code>user</code>.  The <code>admin</code> role is a superset of the <code>user</code> role, and every new account has the <code>user</code> role by default. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Override HTCondor installation with sudo]]></title>
      <link href="http://timothysc.github.com/blog/2012/11/12/condor-sudo/"/>
      <updated>2012-11-12T09:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/11/12/condor-sudo</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Best practices for Wallaby's default group]]></title>
      <link href="http://chapeau.freevariable.com/2012/11/best-practices-for-wallabys-default-group.html"/>
      <updated>2012-11-01T20:14:53Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.38</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Recall that Wallaby applies partial configurations to groups of nodes. Groups can be either explicit —- that is, a named subset of nodes created by the user, or special groups that are built-in to Wallaby; each node’s group memberships have...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Welcome To The HTCondor Project Github Site]]></title>
      <link href="http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site/"/>
      <updated>2012-10-29T20:15:00Z</updated>
      <id>http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site</id>
      <author>
        <name><![CDATA[HTCondor Team GitHub]]></name>
        <uri>http://htcondor.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Welcome to the HTCondor Project GitHub website!  This site is the github web and blog presence for the HTCondor project. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Configuring high-availability Condor central managers with Wallaby]]></title>
      <link href="http://chapeau.freevariable.com/2012/10/configuring-high-availability-condor-central-managers-with-wallaby.html"/>
      <updated>2012-10-23T04:34:58Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.37</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Rob Rati and I gave a tutorial on highly-available job queues at Condor Week this year. While it was not a Wallaby-specific tutorial, we did point out that configuring highly-available job queues is easier for users who manage and deploy...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Cluster Suite's GUI to configure High Availability Schedulers ]]></title>
      <link href="http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers/"/>
      <updated>2012-10-18T17:20:00Z</updated>
      <id>http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In an <a href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/">earlier post</a> I talked about using Cluster Suite
to manage high availability schedulers and referenced the command line tools
available perform the configuration.  I'd like to focus on using the GUI that
is part of Cluster Suite to configure an HA schedd.  It's a pretty simple
process but does require you run a wallaby shell command to complete the
configuration. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Credentials in LDAP URLs when Anonymous Search is Disabled]]></title>
      <link href="http://tmckayus.github.com/blog/2012/10/10/ldap-credentials/"/>
      <updated>2012-10-10T20:55:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/10/10/ldap-credentials</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Cumin authenticates logins against LDAP using a two step process: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Cluster Suite to Manage a High Availability Scheduler]]></title>
      <link href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/"/>
      <updated>2012-09-26T19:53:00Z</updated>
      <id>http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Condor provides simple and easy to configure HA functionality for the schedd
that relies upon shared storage (usually NFS).  The shared store is used to
store the job queue log and coordinate which node is running the schedd.  This
means that each node that can run a particular schedd not only have condor
configured but the node needs to be configured to access the shared storage. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Integrating Cumin with LDAP for Authentication]]></title>
      <link href="http://tmckayus.github.com/blog/2012/09/24/ldap-auth/"/>
      <updated>2012-09-24T16:41:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/09/24/ldap-auth</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Past versions of Cumin have relied on a local database for storing user accounts.  However, that solution adds extra maintenance for site administrators who already have or plan to have a central authentication mechanism for their users.  Consequently, development is ongoing to integrate Cumin with common central auth mechanisms.  LDAP integration is available now, with support for other technologies planned for the future. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[So What is Cumin Anyway?]]></title>
      <link href="http://tmckayus.github.com/blog/2012/09/24/new-post/"/>
      <updated>2012-09-24T16:07:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/09/24/new-post</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Cumin is a Python web UI developed in the Fedora community for managing Condor pools and Qpid messaging brokers.  It is packaged for Fedora but may be run from sources and would probably be easy to port to other Linux distributions (or just run Fedora on a node or two in a heterogeneous environment!)  The current development focus for Cumin is on expanding the Condor management facilities. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Elastic Grid with Condor and oVirt Integration]]></title>
      <link href="http://timothysc.github.com/blog/2012/09/21/condor-n-overt/"/>
      <updated>2012-09-21T08:50:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/09/21/condor-n-overt</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Putting It Together]]></title>
      <link href="http://rrati.github.com/blog/2012/09/18/putting-it-together/"/>
      <updated>2012-09-18T12:59:00Z</updated>
      <id>http://rrati.github.com/blog/2012/09/18/putting-it-together</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Authorization for Wallaby clients]]></title>
      <link href="http://getwallaby.com/2012/09/authorization-for-wallaby-clients/"/>
      <updated>2012-09-12T22:30:00Z</updated>
      <id>http://getwallaby.com/2012/09/authorization-for-wallaby-clients</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways.  This post will explain how the authorization support works and show how to get started using it.  If you just want to get started using Wallaby with authorization support as quickly as possible, skip ahead to the section titled &#8220;Getting Started&#8221; below.  Detailed information about which role is required for each Wallaby API method is <a href="http://getwallaby.com/api-roles/">available here</a>. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Authorization for Wallaby clients]]></title>
      <link href="http://chapeau.freevariable.com/2012/09/authorization-for-wallaby-clients.html"/>
      <updated>2012-09-12T22:23:18Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.36</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways. This post will explain how the authorization support works and show how to...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Dust off nuke it from orbit]]></title>
      <link href="http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit/"/>
      <updated>2012-09-12T09:12:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Highly-available configuration data with Wallaby]]></title>
      <link href="http://chapeau.freevariable.com/2012/08/highly-available-configuration-data-with-wallaby.html"/>
      <updated>2012-08-29T21:03:00Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.35</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Many Condor users are interested in high-availability (HA) services: they don't want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon. (See this talk that Rob Rati and...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Highly-available configuration data with Wallaby]]></title>
      <link href="http://getwallaby.com/2012/08/live-backup/"/>
      <updated>2012-08-29T14:40:00Z</updated>
      <id>http://getwallaby.com/2012/08/live-backup</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Many Condor users are interested in <em>high-availability</em> (HA) services:  they don&#8217;t want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon.  (See <a href="http://research.cs.wisc.edu/condor/CondorWeek2012/presentations/rati-benton-condor-ha.pdf">this talk</a> that Rob Rati and I gave at Condor Week this year for a couple of solutions to HA with the Condor <code>schedd</code>.)  So it&#8217;s only natural that Condor users who are interested in configuring their pools with <a href="http://getwallaby.com">Wallaby</a> might wonder how Wallaby responds in the face of failure. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using the skeleton group]]></title>
      <link href="http://getwallaby.com/2012/06/using-the-skeleton-group/"/>
      <updated>2012-06-15T17:46:00Z</updated>
      <id>http://getwallaby.com/2012/06/using-the-skeleton-group</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In Wallaby, Condor nodes are configured by applying <em>features</em> and <em>parameter</em> settings to <em>groups</em>.  In order for the group abstraction to be fully general, <a href="http://getwallaby.com/2011/05/using-wallaby-groups-to-implement-node-tagging/">Wallaby provides two kinds of <em>special groups</em></a>:  the <em>default group</em>, which contains every node (but which is the lowest-priority membership for each node), and a set of <em>identity groups</em>, each of which only contains a single node (and which is always its highest-priority membership, so that special settings applied to a node&#8217;s identity group always take precedence over settings from that node&#8217;s other memberships). [...]</p>
]]></content>
    </entry>
  
</feed>
