<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Planet HTCondor Meta Feed]]></title>
  <link href="http://htcondor.github.com/planet/atom.xml" rel="self"/>
  <link href="http://htcondor.github.com/"/>
  <updated>2013-02-15T09:09:27-07:00</updated>
  <id>http://htcondor.github.com/planet/atom.xml</id>
  <author>
    <name><![CDATA[HTCondor Project]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
    <entry>
      <title type="html"><![CDATA[Statistic changes in HTCondor 7.7]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/12/statistic-changes-in-htcondor-7-7/"/>
      <updated>2013-02-12T11:56:04Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=925</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[<p>Notice to HTCondor 7.8 users -</p>
<p>Statistics implemented during the 7.5 series that landed in 7.7.0 were rewritten by the time 7.8 was released. If you were using the original statistics for monitoring and/or reporting, here is a table to help you map old (left column) to new (right column).</p>
<p>See â€“ <a href="https://gist.github.com/3911872">7.6 -&gt; 7.8 schedd stats</a><br />
<small>(embedding content requires javascript, which is not available on wordpress.com)</small></p>
<p>Note: The *Rate and Mean* attributes require math, and UpdateTime requires memory</p>
<br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/925/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/925/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=925&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Bosco to submit to Amazon EC2]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/02/using-bosco-to-submit-to-amazon-ec2.html"/>
      <updated>2013-02-06T04:27:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-4538100752405939638</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[A homework assignment for my storage class required running ~30 hours of benchmarks of the btrfs and ext4 filesystems. &nbsp;I thought this would be an excellent time to test Bosco's ability to submit to Amazon EC2 to parallelize the benchmarks.<br /><br /><h3>Preparing Submission</h3><div>In order to start instances on Amazon EC2, you first need to sign up. &nbsp;Go to&nbsp;<a href="https://aws.amazon.com/">https://aws.amazon.com/</a>&nbsp;and sign up in the top right. &nbsp;After you sign up, you will need the access and secret key. &nbsp;These can be found in the 'Security Credentials' from the account drop down box. &nbsp;They are in the 'Access Keys' tab under the&nbsp;'Access Key ID' and&nbsp;'Secret Access Key'. &nbsp;Write those values in 2 files, you will need them when you submit EC2 instances.</div><div><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-0l_ddtj9fXc/URHJOTsFD8I/AAAAAAAAB2o/lAp3Yn_RVS8/s1600/amazoncred.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="441" src="http://1.bp.blogspot.com/-0l_ddtj9fXc/URHJOTsFD8I/AAAAAAAAB2o/lAp3Yn_RVS8/s640/amazoncred.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Screenshot of Amazon Security credentials site</td></tr></tbody></table><div><br /></div><div><br /></div><div>Next, you will need a script to run at startup of the Amazon instance. &nbsp;When the instance starts up, a service named <a href="https://help.ubuntu.com/community/CloudInit">CloudInit</a>&nbsp;also start on the instance. &nbsp;It will&nbsp;interpret&nbsp;the user data file as a shell script which can setup and start any other services you would like. &nbsp;My shell script is provided below.</div><div><div class="gistLoad" data-id="4719948" id="gist-4719948">Loading ....</div></div><div><br /></div><div>This shell script will install python-boto (python bindings for S3 storage and ec2) and git onto the instance. &nbsp;Next, it will download the filebenchrunner (Benchmark runner for the homework), and start it. &nbsp;Most people will probably want to shut down the instance after you are done with processing, in that case you can just add to the bottom a 'poweroff'. <br /><br /><h3>Running the Instance</h3></div><div>Running an Amazon instance is as easy as running a Bosco job. &nbsp;First, you must create a Bosco submit file. &nbsp;Below is the one I used:</div><div><div class="gistLoad" data-id="4720141" id="gist-4720141"><br /></div><div><br />Some important things to note. &nbsp;I specified ec2_spot_price, which is the amount I am willing to pay for my m1.medium instance to run per hour. &nbsp;I said $0.04 an hour, which is pretty low, but reasonable for a medium instance. &nbsp;You can find all of the current spot prices either in the AWS console, or on the EC2 <a href="https://aws.amazon.com/ec2/spot-instances/#7">website</a>. &nbsp;As you can see, the spot prices are much, much smaller than the on-demand price of an instance. &nbsp;For example, for the m1.medium instance, which has 1.7 GB of ram and 1 core, the spot price currently is $0.013 per hour. &nbsp;The on-demand price is $0.120 per hour. &nbsp;That's a 90% discount on a m1.medium. &nbsp;Of course, you should always read the <a href="https://aws.amazon.com/ec2/spot-instances/#4">downsides</a> of using a spot instance, such as it can be terminated at any time, without warning, by Amazon. &nbsp;For my benchmarks, I can always re-run benchmarks if my instance is terminated. &nbsp;I needed to run 10 - 10 minute benchmarks, therefore after every benchmark, I uploaded the resulting data to S3&nbsp;immediately so I wouldn't lose any work if the instance was terminated.<br /><br />Also, I used the regular Amazon Linux AMI. &nbsp;They are listed on the Amazon <a href="https://aws.amazon.com/amazon-linux-ami/">website</a>. &nbsp;I could have very well used a CentOS, Ubuntu, or any other linux image for my instance. &nbsp;But, I prefer the official Linux AMI since it provides a very up to date OS which is very similar to the feel of a CentOS 6 instance. &nbsp;For example, it uses yum for repository management, and RPM's to install. &nbsp;And has versions (except for the kernel) similar to CentOS 6.<br /><br />I also added a special command, periodic_remove, in order to terminate the instance if something went wrong inside the instance. &nbsp;Sometimes yum can hang, or the instance may not start up properly. &nbsp;In those cases, amazon will not notify you of the problem, and Bosco will not be able to determine there is an issue. &nbsp;Since my benchmarks should not last longer than 100 minutes, I automatically remove the instance after 150 minutes (a little breathing room) of running.<br /><br />You may submit the instance with the normal 'condor_submit' command. &nbsp;The job will move to the <b>R</b>unning state when the instance has begun running.<br /><br />Once the instance has started, you may ssh into the instance by using the unique ssh key that Bosco generates for you. &nbsp;It is specified in the submit file as&nbsp;ec2_keypair_file. &nbsp;You also need the DNS name for the instance, which is available in the job's classad. <br /><pre>condor_q -run</pre><br />The command will output the hostname of the EC2 host.  You may connect to the EC2 instance with the command, replacing the XXXX with the job number, and hostname with the address you get from the above command:<br /><pre>$ ssh -i keyfile.XXXXX ec2-user@<span style="color: red;">hostname</span></pre><br /><h3>Summary</h3><div>Pros of using Bosco to submit Amazon EC2 Jobs:</div><div><ul><li>Simple management of Amazon instance <b>from your workstation</b>.</li><li>Specify spot price right inside of the job description.</li><li>Ability to bootstrap the instance easily with user data scripts.</li><li>Ability to use HTCondor policies in order to manage the instances, such as periodic remove statement above.</li></ul>Cons:</div><div><ul><li>The EC2 universe is only available on Linux builds of Bosco. &nbsp;You cannot manage EC2 instances on the Mac version of Bosco.</li><li>Amazon EC2 has hundreds and hundreds of features, Bosco only allows you to use the simple submit EC2 instances and spot pricing. &nbsp;You will not be able to use the vast majority when you are using Bosco to manage your instances. &nbsp;But if all you need is to run some processing, Bosco is great!</li></ul></div><br /></div><script src="https://raw.github.com/moski/gist-Blogger/master/public/gistLoader.js" type="text/javascript"></script></div><center><a href="http://bosco.opensciencegrid.org/download/">     <img src="https://raw.github.com/osg-bosco/bosco-download-images/master/images/download-orange.png"       alt="Bosco Download"      style="border-width: 0;" /> </a><br /><a href="http://creativecommons.org/licenses/by/3.0/deed.en_US" rel="license"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by/3.0/88x31.png" style="border-width: 0;" /></a><br />This work is licensed under a <a href="http://creativecommons.org/licenses/by/3.0/deed.en_US" rel="license">Creative Commons Attribution 3.0 Unported License</a>. </center>]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[How accounting group configuration could work with Wallaby]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/02/05/how-accounting-group-configuration-could-work-with-wallaby/"/>
      <updated>2013-02-05T11:46:28Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=917</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[<p>Configuration of accounting groups in HTCondor is too often an expert task that requires coordination between administrators and their tools.</p>
<p>Wallaby provides a coordination point, so long as a little convention is employed, and can provide a task specific interface to simplify configuration.</p>
<p>Quick background, <a href="http://getwallaby.com/">Wallaby</a> provides semantic configuration for HTCondor. It models a pool as parameters aggregated into features and nodes aggregated in groups, with features and individual parameters associated with nodes and groups. It provides semantic validation of configuration before it is distributed, and has expert knowledge for minimal impact configuration changes.</p>
<p>And, accounting group configuration in HTCondor is spread across seven fixed parameters (GROUP_NAMES, GROUP_ACCEPT_SURPLUS, GROUP_SORT_EXPR, GROUP_NAMES, GROUP_QUOTA_ROUND_ROBIN_RATE, GROUP_AUTOREGROUP, GROUP_QUOTA_MAX_ALLOCATION_ROUNDS), and another five dynamic parameters (GROUP_ACCEPT_SURPLUS_groupname, GROUP_AUTOREGROUP_groupname, GROUP_PRIO_FACTOR_groupname, GROUP_QUOTA_groupname, GROUP_QUOTA_DYNAMIC_groupname). These are dynamic because the &#8220;groupname&#8221; in the parameter is any name listed in the GROUP_NAMES parameter.</p>
<p>In addition to its other features, Wallaby has an <a href="http://getwallaby.com/2010/10/extending-the-wallaby-shell/">extensible shell mechanism</a>, which can be used to create task specific porcelain.</p>
<p>For instance, agree that tools and administrators will store accounting group configuration on a feature called AccountingGroups, and the tools can use Wallaby&#8217;s API to manipulate the configuration while the following porcelain can simplify the task for managing that configuration by administrators.</p>
<p>See &#8211; <a href="https://gist.github.com/4074465">wallaby_accounting_group_porcelain.txt</a><br />
<small>(embedding content requires javascript, which is not available on wordpress.com)</small></p>
<br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/917/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/917/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=917&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Some htcondor-wiki stats]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/29/some-htcondor-wiki-stats/"/>
      <updated>2013-01-29T11:36:06Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=903</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[<p>A few years ago I discovered <a href="http://webnumbr.com">Web Numbr</a>, a service that will monitor a web page for a number and graph that number over time.</p>
<p>I installed a handful of webnumbrs to track things at <a href="http://condor-wiki.cs.wisc.edu">HTCondor&#8217;s gittrac instance</a>.</p>
<p><a href="http://webnumbr.com/search?query=condor">http://webnumbr.com/search?query=condor</a></p>
<p>Thing such as -</p>
<ul>
<li><a href="http://webnumbr.com/condor-resolved-tickets-with-no-destination">Tickets resolved with no destination:</a> tickets that don&#8217;t indicate what version they were fixed in. Anyone wanting to know if a bug is fixed or feature was added to their version of HTCodnor and encounters one of these will have to go spelunking in the repository for their answer.</li>
<li><a href="http://webnumbr.com/condor-resolved-and-unassigned-tickets">Tickets resolved but not assigned:</a> tickets that were worked on, completed, but whomever worked on them never claimed ownership.</li>
<li><a href="http://webnumbr.com/condor-action-items-with-commits">Action items with commits:</a> tickets that are marked as Todo/Incident, yet have associated code changes. Once there is a code change the ticket is either a bug fix (ticket type: defect) or feature addition (ticket type: enhancement). Extra work is imposed on whomever comes after the ticket owner who wants to understand what they are looking at. Additionally, these tickets skew information about bugs and features in releases.</li>
<li><a href="http://webnumbr.com/condor-tickets-with-invalid-version-field">Tickets with invalid version fields:</a> tickets that do not follow the, somewhat strict, version field syntax &#8211; vXXYYZZ, e.g. v070901. All the extra 0s are necessary and the v must be lowercase.</li>
</ul>
<p>I wanted to embed the numbers here, but javascript is needed and wordpress.com filters javascript from posts.</p>
<br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/903/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/903/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=903&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Introducing the HTCondor-CE]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/introducing-htcondor-ce.html"/>
      <updated>2013-01-28T15:33:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1124494645797252707</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[At the heart of the OSG Compute Element (CE) is the gatekeeper software. &nbsp;The gatekeeper software anchors three core pieces of functionality:<br /><ol><li><b>Remote access</b>: The gatekeeper provides a network service that remote clients can contact and interact with.</li><li><b>Authentication and authorization</b>: The gatekeeper is responsible for authenticating the client and deciding on what actions it is authorized to perform.</li><li><b>Resource allocation</b>: The gatekeeper accepts an abstract description of a resource to allocate and actualizes the resource request within the local environment.</li></ol><div>The existing software, Globus GRAM, provides a HTTP-like interface over TLS for remote access. &nbsp;The authentication is done using the Grid Security Infrastructure (GSI), using special client certificates. &nbsp;It does authorization by performing a callout to map the client certificate to a Unix account, then performing all further operations as that Unix user. &nbsp;The resource allocation provides an interface which accepts requests in Globus RSL (a job description language) and interact with a local batch system on the CE to run the job.</div><div><br /></div><div>With the HTCondor team, the OSG has been working to provide an alternate gatekeeper implementation, the <i style="font-weight: bold;">HTCondor-CE</i>. &nbsp;The HTCondor-CE is a special configuration of the HTCondor software which provides the three core pieces of functionality described above.</div><div><br /></div><div>HTCondor provides remote access using a custom communication protocol and called CEDAR. &nbsp;CEDAR provides a RPC and messaging mechanism over UDP or TCP, and can provide various levels of integrity or encryption based upon the session parameters. &nbsp;While the HTCondor-CE will ship with the same GSI authentication and authorization as Globus GRAM, it can be reconfigured to provide alternate authentication mechanisms such as Kerberos, SSL, shared secret, or even IP-based authentication.</div><div><br /></div><div>The HTCondor-CE allocates resources via having the client submit HTCondor jobs to a scheduler running on the CE (the schedd daemon). &nbsp;We refer to this as the "<i>grid job</i>". &nbsp;A separate daemon, the JobRouter, is responsible for transforming the <i>grid job</i>&nbsp;to a resource allocation for site. &nbsp;For a site with a HTCondor batch system, it will transform and mirror the <i>grid job</i>&nbsp;into the <i>routed job</i>&nbsp;in the site's batch system. &nbsp;The process is illustrated below:</div><div><br /></div><div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-UbMFNUvwsVs/UQaP3f6n4jI/AAAAAAAACl4/OqW79vo6g4I/s1600/HTCondorCE_Condor.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="306" src="http://2.bp.blogspot.com/-UbMFNUvwsVs/UQaP3f6n4jI/AAAAAAAACl4/OqW79vo6g4I/s320/HTCondorCE_Condor.png" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">The submit workflow for the HTCondor-CE running on a site with the HTCondor batch system. &nbsp;Notice the JobRouter copies the job directly into the site's batch system.</td></tr></tbody></table><span id="goog_33533915"></span><span id="goog_33533916"></span>For sites with the PBS batch system, the <i>routed job</i>&nbsp;stays in the HTCondor-CE schedd (as the JobRouter does not know how to submit directly into the PBS queue), and the job is submitted into PBS using the blahp daemon. &nbsp;See the illustration below:<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-IagX60Tm5WQ/UQaQd7aZNkI/AAAAAAAACmA/OKNIpiTEQ-4/s1600/CondorCE_PBS.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="292" src="http://3.bp.blogspot.com/-IagX60Tm5WQ/UQaQd7aZNkI/AAAAAAAACmA/OKNIpiTEQ-4/s320/CondorCE_PBS.png" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">The HTCondor-CE submit workflow for a PBS site. &nbsp;Notice the blahp, not the JobRouter, does the submission to PBS in this case.</td></tr></tbody></table>The blahp daemon is a common piece of software for interacting with batch systems - in addition to being integrated in the HTCondor grid universe, it also is used by the BOSCO project and the CREAM CE.<br /><br />Note there is no requirement that the job be routed into a batch system - given the appropriate transform logic. the JobRouter could also transform the grid job into VM running in Amazon EC2, an OpenStack instance, or a job for another HTCondor-CE!<br /><br />The CE is quite flexible; it is a configuration of the HTCondor software and leverages all the features available in HTCondor. &nbsp;As another example, we benefit from the fact that HTCondor's security uses sessions; clients do not re-authenticate for each status update. &nbsp;Future features, such as the sandbox size limits in the upcoming 7.9.4, can be used immediately by the CE through a configuration file change.<br /><br />The HTCondor-CE is currently under development, although functionality has been demonstrated using glideinWMS for up to 5,000 running pilots. &nbsp;It requires HTCondor 7.9.2 or later, so we are waiting for the next stable release (due late April) before starting to release the CE more widely. &nbsp;As we near release, I am planning on doing additional updates on specific pieces of this technology.<br /><br />We're looking forward to see how users will put it into action!<br /><br /></div>]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Concurrency Limits: Group defaults]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/21/concurrency-limits-group-defaults/"/>
      <updated>2013-01-21T12:47:07Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=895</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[<p><a href="http://spinningmatt.wordpress.com/2011/06/27/concurrency-limits-protecting-shared-resources/">Concurrency limits</a> allow for protecting resources by providing a way to cap the number of jobs requiring a specific resource that can run at one time.</p>
<p>For instance, limit licenses and filer access at four regional data centers.</p>
<p><pre class="brush: plain; gutter: false;">
CONCURRENCY_LIMIT_DEFAULT = 15
license.north_LIMIT = 30
license.south_LIMIT = 30
license.east_LIMIT = 30
license.west_LIMIT = 45
filer.north_LIMIT = 75
filer.south_LIMIT = 150
filer.east_LIMIT = 75
filer.west_LIMIT = 75
</pre></p>
<p>Notice the repetition.</p>
<p>In addition to the repetition, every license.* and filer.* must be known and recorded in configuration. The set may be small in this example, but imagine imposing a limit on each user or each submission. The set of users is board, dynamic and may differ by region. The set of submissions is a more extreme version of the users case, yet it is still realistic.</p>
<p>To simplify the configuration management for groups of limits, a new feature to <a href="https://htcondor-wiki.cs.wisc.edu/index.cgi/tktview?tn=2863">provide group defaults</a> to limit was added for the Condor 7.8 series.</p>
<p>The feature requires that only the exception to a rule be called out explicitly in configuration. For instance, license.west and filer.south are the exceptions in the configuration above. Simplified configuration available in 7.8,</p>
<p><pre class="brush: plain; gutter: false;">
CONCURRENCY_LIMIT_DEFAULT = 15
CONCURRENCY_LIMIT_DEFAULT_license = 30
CONCURRENCY_LIMIT_DEFAULT_filer = 75
license.west_LIMIT = 45
filer.south_LIMIT = 150
</pre></p>
<p>In action,</p>
<p><pre class="brush: plain; gutter: false;">
$ for limit in license.north license.south license.east license.west filer.north filer.south filer.east filer.west; do echo queue 1000 | condor_submit -a cmd=/bin/sleep -a args=1d -a concurrency_limits=$limit; done

$ condor_q -format '%s\n' ConcurrencyLimits -const 'JobStatus == 2' | sort | uniq -c | sort -n
     30 license.east
     30 license.north
     30 license.south
     45 license.west
     75 filer.east
     75 filer.north
     75 filer.west
    150 filer.south
</pre></p>
<br />  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/spinningmatt.wordpress.com/895/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/spinningmatt.wordpress.com/895/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=895&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bosco 1.1.1 Release]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/01/bosco-111-release.html"/>
      <updated>2013-01-14T18:59:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1926902995750303001</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Your API is a feature, give it real resource management]]></title>
      <link href="http://spinningmatt.wordpress.com/2013/01/14/your-api-is-a-feature-give-it-real-resource-management/"/>
      <updated>2013-01-14T12:17:29Z</updated>
      <id>http://spinningmatt.wordpress.com/?p=872</id>
      <author>
        <name><![CDATA[Matthew Farrellee]]></name>
        <uri>http://spinningmatt.wordpress.com</uri>
      </author>
      <content type="html"><![CDATA[So much these days is about distributed resource management. That&#8217;s anything that can be created and destroyed in the cloud[0]. Proper management is especially important when the resource&#8217;s existence is tied to a real economy, e.g. your user&#8217;s credit card[1]. Above is a state machine required to ensure that resources created in AWS EC2 are [...]<img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=spinningmatt.wordpress.com&#038;blog=6870579&#038;post=872&#038;subd=spinningmatt&#038;ref=&#038;feed=1" width="1" height="1" />]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Bosco 1.1 Release]]></title>
      <link href="http://derekweitzel.blogspot.com/2013/01/bosco-11-release.html"/>
      <updated>2013-01-08T23:01:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-2171189043756995217</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Fun with ClassAds]]></title>
      <link href="http://osgtech.blogspot.com/2013/01/fun-with-classads.html"/>
      <updated>2013-01-05T22:58:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-1674994974092153801</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[The Mean of the Modulus Does Not Equal the Modulus of the Mean]]></title>
      <link href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/"/>
      <updated>2013-01-02T15:55:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>I've been considering models for the effects of HTCondor negotiation cycle cadence on pool loading and accounting group starvation, which led me to thinking about the effects of taking the modulus of a random variable, for reasons I plan to discuss in future posts. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[A Demonstration of Negotiator-Side Resource Consumption]]></title>
      <link href="http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption/"/>
      <updated>2012-12-03T15:25:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>HTCondor supports a notion of aggregate compute resources known as partitionable slots (p-slots), which may be consumed by multiple jobs.   Historically, at most one job could be matched against such a slot in a single negotiation cycle, which limited the rate at which partitionable slot resources could be utilized.  More recently, the scheduler has been enhanced with logic to allow it to acquire multiple claims against a partitionable slot, which increases the p-slot utilization rate. However, as this potentially bypasses the negotiator's accounting of global pool resources such as accounting group quotas and concurrency limits, it places some contraints on what jobs can can safely acquire multiple claims against any particular p-slot: for example, only other jobs on the same scheduler can be considered.  Additionally, candidate job requirements must match the requirements of the job that originally matched in the negotiator.  Another significant impact is that the negotiator is still forced to match an entire p-slot, which may have a large match cost (weight): these large match costs cause <a href="https://htcondor-wiki.cs.wisc.edu/index.cgi/tktview?tn=3013">accounting difficulties</a> when submitter shares and/or group quotas drop below the cost of a slot.  This particular problem is growing steadily larger, as machines with ever-larger numbers of cores and other resources appear in HTCondor pools. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[BOSCO v1.1 Features: Multi-Cluster Support]]></title>
      <link href="http://derekweitzel.blogspot.com/2012/11/bosco-v11-features-multi-cluster-support.html"/>
      <updated>2012-11-29T06:33:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-1512416798236467341</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Rethinking the Semantics of Group Quotas and Slot Weights: Computing Claim Capacity from Consumption Policy]]></title>
      <link href="http://erikerlandson.github.com/blog/2012/11/26/rethinking-the-semantics-of-group-quotas-and-slot-weights-computing-claim-capacity-from-consumption-policy/"/>
      <updated>2012-11-26T20:52:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2012/11/26/rethinking-the-semantics-of-group-quotas-and-slot-weights-computing-claim-capacity-from-consumption-policy</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In two previous posts, I made a case to motivate the need for a better definition of slot weights and group quotas that could accommodate use cases involving aggregate resources (partitionable slots) with heterogeneous consumption policies and also provide a principled unit analysis for weights and quotas.  These previous posts can be viewed here: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Rethinking the Semantics of Group Quotas and Slot Weights: Claim Capacity Model]]></title>
      <link href="http://erikerlandson.github.com/blog/2012/11/15/rethinking-the-semantics-of-group-quotas-and-slot-weights-claim-capacity-model/"/>
      <updated>2012-11-16T00:22:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2012/11/15/rethinking-the-semantics-of-group-quotas-and-slot-weights-claim-capacity-model</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In my previous post about <a href="http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources">Rethinking the Semantics of Group Quotas and Slot Weights</a>, I proposed a concept for unifying the semantics of accounting group quotas and slot weights across arbitrary resource allocation strategies. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Rethinking the Semantics of Group Quotas and Slot Weights for Heterogeneous and Multidimensional Compute Resources]]></title>
      <link href="http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources/"/>
      <updated>2012-11-13T22:31:00Z</updated>
      <id>http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources</id>
      <author>
        <name><![CDATA[Erik Erlandson]]></name>
        <uri>http://erikerlandson.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>The HTCondor semantic for accounting group quotas and slot weights is currently cpu-centric.  This is an artifact of the historic primacy of cpu as the most commonly-considered limiting resource in computations.  For example the <code>SlotWeight</code> attribute is currently defaulted to <code>Cpus</code>, and when slot weights are disabled, there is logic activated in matchmaking to sum the available cpus on slots to avoid 'undercounting' total pool quotas. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Role enforcement in Cumin]]></title>
      <link href="http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin/"/>
      <updated>2012-11-12T20:20:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/11/12/role-enforcement-in-cumin</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Roles in Cumin scope activities and content in the UI.  There are currently two roles defined in Cumin, <code>admin</code> and <code>user</code>.  The <code>admin</code> role is a superset of the <code>user</code> role, and every new account has the <code>user</code> role by default. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Override HTCondor installation with sudo]]></title>
      <link href="http://timothysc.github.com/blog/2012/11/12/condor-sudo/"/>
      <updated>2012-11-12T09:00:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/11/12/condor-sudo</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[BOSCO v1.1 Features: Multi-OS Support]]></title>
      <link href="http://derekweitzel.blogspot.com/2012/11/bosco-v11-features-multi-os-support.html"/>
      <updated>2012-11-06T22:11:00Z</updated>
      <id>tag:blogger.com,1999:blog-3007054864987759910.post-8516182672952525228</id>
      <author>
        <name><![CDATA[Derek Weitzel]]></name>
        <uri>http://derekweitzel.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Best practices for Wallaby's default group]]></title>
      <link href="http://chapeau.freevariable.com/2012/11/best-practices-for-wallabys-default-group.html"/>
      <updated>2012-11-01T20:14:53Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.38</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Recall that Wallaby applies partial configurations to groups of nodes. Groups can be either explicit â€”- that is, a named subset of nodes created by the user, or special groups that are built-in to Wallaby; each nodeâ€™s group memberships have...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Welcome To The HTCondor Project Github Site]]></title>
      <link href="http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site/"/>
      <updated>2012-10-29T20:15:00Z</updated>
      <id>http://htcondor.github.com/blog/2012/10/29/welcome-to-the-condor-project-github-site</id>
      <author>
        <name><![CDATA[HTCondor Team GitHub]]></name>
        <uri>http://htcondor.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Welcome to the HTCondor Project GitHub website!  This site is the github web and blog presence for the HTCondor project. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Configuring high-availability Condor central managers with Wallaby]]></title>
      <link href="http://chapeau.freevariable.com/2012/10/configuring-high-availability-condor-central-managers-with-wallaby.html"/>
      <updated>2012-10-23T04:34:58Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.37</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Rob Rati and I gave a tutorial on highly-available job queues at Condor Week this year. While it was not a Wallaby-specific tutorial, we did point out that configuring highly-available job queues is easier for users who manage and deploy...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Cluster Suite's GUI to configure High Availability Schedulers ]]></title>
      <link href="http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers/"/>
      <updated>2012-10-18T17:20:00Z</updated>
      <id>http://rrati.github.com/blog/2012/10/18/using-cluster-suites-gui-to-configure-high-availability-schedulers</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In an <a href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/">earlier post</a> I talked about using Cluster Suite
to manage high availability schedulers and referenced the command line tools
available perform the configuration.  I'd like to focus on using the GUI that
is part of Cluster Suite to configure an HA schedd.  It's a pretty simple
process but does require you run a wallaby shell command to complete the
configuration. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Credentials in LDAP URLs when Anonymous Search is Disabled]]></title>
      <link href="http://tmckayus.github.com/blog/2012/10/10/ldap-credentials/"/>
      <updated>2012-10-10T20:55:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/10/10/ldap-credentials</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Cumin authenticates logins against LDAP using a two step process: [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Cluster Suite to Manage a High Availability Scheduler]]></title>
      <link href="http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler/"/>
      <updated>2012-09-26T19:53:00Z</updated>
      <id>http://rrati.github.com/blog/2012/09/26/using-cluster-suite-to-manage-a-high-availability-scheduler</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Condor provides simple and easy to configure HA functionality for the schedd
that relies upon shared storage (usually NFS).  The shared store is used to
store the job queue log and coordinate which node is running the schedd.  This
means that each node that can run a particular schedd not only have condor
configured but the node needs to be configured to access the shared storage. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Integrating Cumin with LDAP for Authentication]]></title>
      <link href="http://tmckayus.github.com/blog/2012/09/24/ldap-auth/"/>
      <updated>2012-09-24T16:41:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/09/24/ldap-auth</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Past versions of Cumin have relied on a local database for storing user accounts.  However, that solution adds extra maintenance for site administrators who already have or plan to have a central authentication mechanism for their users.  Consequently, development is ongoing to integrate Cumin with common central auth mechanisms.  LDAP integration is available now, with support for other technologies planned for the future. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[So What is Cumin Anyway?]]></title>
      <link href="http://tmckayus.github.com/blog/2012/09/24/new-post/"/>
      <updated>2012-09-24T16:07:00Z</updated>
      <id>http://tmckayus.github.com/blog/2012/09/24/new-post</id>
      <author>
        <name><![CDATA[Trevor McKay]]></name>
        <uri>http://tmckayus.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Cumin is a Python web UI developed in the Fedora community for managing Condor pools and Qpid messaging brokers.  It is packaged for Fedora but may be run from sources and would probably be easy to port to other Linux distributions (or just run Fedora on a node or two in a heterogeneous environment!)  The current development focus for Cumin is on expanding the Condor management facilities. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Elastic Grid with Condor and oVirt Integration]]></title>
      <link href="http://timothysc.github.com/blog/2012/09/21/condor-n-overt/"/>
      <updated>2012-09-21T08:50:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/09/21/condor-n-overt</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[<h2>Background</h2> [...]
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Putting It Together]]></title>
      <link href="http://rrati.github.com/blog/2012/09/18/putting-it-together/"/>
      <updated>2012-09-18T12:59:00Z</updated>
      <id>http://rrati.github.com/blog/2012/09/18/putting-it-together</id>
      <author>
        <name><![CDATA[Robert Rati]]></name>
        <uri>http://rrati.github.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Authorization for Wallaby clients]]></title>
      <link href="http://getwallaby.com/2012/09/authorization-for-wallaby-clients/"/>
      <updated>2012-09-12T22:30:00Z</updated>
      <id>http://getwallaby.com/2012/09/authorization-for-wallaby-clients</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways.  This post will explain how the authorization support works and show how to get started using it.  If you just want to get started using Wallaby with authorization support as quickly as possible, skip ahead to the section titled &#8220;Getting Started&#8221; below.  Detailed information about which role is required for each Wallaby API method is <a href="http://getwallaby.com/api-roles/">available here</a>. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Authorization for Wallaby clients]]></title>
      <link href="http://chapeau.freevariable.com/2012/09/authorization-for-wallaby-clients.html"/>
      <updated>2012-09-12T22:23:18Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.36</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Wallaby 0.16.0, which updates the Wallaby API version to 20101031.6, includes support for authorizing broker users with various roles that can interact with Wallaby in different ways. This post will explain how the authorization support works and show how to...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Dust off nuke it from orbit]]></title>
      <link href="http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit/"/>
      <updated>2012-09-12T09:12:00Z</updated>
      <id>http://timothysc.github.com/blog/2012/09/12/dust-off-nuke-it-from-orbit</id>
      <author>
        <name><![CDATA[Timothy St. Clair]]></name>
        <uri>http://timothysc.github.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Highly-available configuration data with Wallaby]]></title>
      <link href="http://chapeau.freevariable.com/2012/08/highly-available-configuration-data-with-wallaby.html"/>
      <updated>2012-08-29T21:03:00Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.35</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Many Condor users are interested in high-availability (HA) services: they don't want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon. (See this talk that Rob Rati and...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Highly-available configuration data with Wallaby]]></title>
      <link href="http://getwallaby.com/2012/08/live-backup/"/>
      <updated>2012-08-29T14:40:00Z</updated>
      <id>http://getwallaby.com/2012/08/live-backup</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Many Condor users are interested in <em>high-availability</em> (HA) services:  they don&#8217;t want their compute resources to become unavailable due to the failure of a single machine that is running an important Condor daemon.  (See <a href="http://research.cs.wisc.edu/condor/CondorWeek2012/presentations/rati-benton-condor-ha.pdf">this talk</a> that Rob Rati and I gave at Condor Week this year for a couple of solutions to HA with the Condor <code>schedd</code>.)  So it&#8217;s only natural that Condor users who are interested in configuring their pools with <a href="http://getwallaby.com">Wallaby</a> might wonder how Wallaby responds in the face of failure. [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using Wallaby's skeleton group]]></title>
      <link href="http://chapeau.freevariable.com/2012/06/using-wallabys-skeleton-group.html"/>
      <updated>2012-06-15T21:04:21Z</updated>
      <id>tag:chapeau.freevariable.com,2012://1.34</id>
      <author>
        <name><![CDATA[Will Benton]]></name>
        <uri>http://willbenton.com</uri>
      </author>
      <content type="html"><![CDATA[Wallaby 0.15.0 includes a new feature called the skeleton group. (This feature was available in earlier versions of Wallaby, too, but it was experimental and had some rough edges.) Find out how the skeleton group makes configuration more flexible by...]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Using the skeleton group]]></title>
      <link href="http://getwallaby.com/2012/06/using-the-skeleton-group/"/>
      <updated>2012-06-15T17:46:00Z</updated>
      <id>http://getwallaby.com/2012/06/using-the-skeleton-group</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>In Wallaby, Condor nodes are configured by applying <em>features</em> and <em>parameter</em> settings to <em>groups</em>.  In order for the group abstraction to be fully general, <a href="http://getwallaby.com/2011/05/using-wallaby-groups-to-implement-node-tagging/">Wallaby provides two kinds of <em>special groups</em></a>:  the <em>default group</em>, which contains every node (but which is the lowest-priority membership for each node), and a set of <em>identity groups</em>, each of which only contains a single node (and which is always its highest-priority membership, so that special settings applied to a node&#8217;s identity group always take precedence over settings from that node&#8217;s other memberships). [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Troubleshooting Condor with Wallaby]]></title>
      <link href="http://getwallaby.com/2012/06/troubleshooting/"/>
      <updated>2012-06-01T17:27:00Z</updated>
      <id>http://getwallaby.com/2012/06/troubleshooting</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[<p>Often, if you&#8217;re trying to reproduce a problem someone else is having with Condor, you&#8217;ll need their configuration.  Likewise, if you&#8217;re trying to help someone reproduce a problem you&#8217;re having, you&#8217;ll want to send along your configuration to aid them in replicating your setup.  For installations that use legacy flat-file configurations (optionally with a local configuration directory), this can be a pain, since you&#8217;ll need to copy several files from site to site (ensuring that you&#8217;ve included all the files necessary to replicate your configuration, perhaps across multiple machines on the site experiencing the problem). [...]</p>
]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Now powered by OctoPress]]></title>
      <link href="http://getwallaby.com/2012/03/getwallaby-dot-com-is-now-powered-by-octopress/"/>
      <updated>2012-03-16T17:27:00Z</updated>
      <id>http://getwallaby.com/2012/03/getwallaby-dot-com-is-now-powered-by-octopress</id>
      <author>
        <name><![CDATA[William Benton]]></name>
        <uri>http://getwallaby.com/</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Resource Isolation in Condor using cgroups]]></title>
      <link href="http://osgtech.blogspot.com/2012/03/resource-isolation-in-condor-using.html"/>
      <updated>2012-03-10T19:28:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-2804145841486035015</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[Improving File Isolation with chroot]]></title>
      <link href="http://osgtech.blogspot.com/2012/02/improving-file-isolation-with-chroot.html"/>
      <updated>2012-02-27T19:33:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-4833728643726960817</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
    <entry>
      <title type="html"><![CDATA[File Isolation using bind mounts and chroots]]></title>
      <link href="http://osgtech.blogspot.com/2012/02/file-isolation-using-bind-mounts-and.html"/>
      <updated>2012-02-20T16:03:00Z</updated>
      <id>tag:blogger.com,1999:blog-8803173202887660937.post-5734694593802146494</id>
      <author>
        <name><![CDATA[Brian Bockelman]]></name>
        <uri>http://osgtech.blogspot.com</uri>
      </author>
      <content type="html"><![CDATA[]]></content>
    </entry>
  
</feed>
